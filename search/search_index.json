{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"api/","title":"Flame Python API Reference","text":"<p>Welcome to the automatically generated API reference for Autodesk Flame.</p>"},{"location":"api/#core-modules","title":"Core Modules","text":"<ul> <li>Classes: Detailed reference for all Flame Python classes (e.g., <code>PyClip</code>, <code>PyBatch</code>).</li> <li>Functions: Global utility functions (e.g., <code>execute_command</code>, <code>import_clips</code>).</li> <li>Global Objects: Singleton instances available in the global scope (e.g., <code>project</code>, <code>timeline</code>).</li> </ul>"},{"location":"api/#how-this-was-generated","title":"How this was generated","text":"<p>This documentation was generated by introspecting a running instance of Autodesk Flame 2027. See How to Generate API Reports for details.</p>"},{"location":"api/TODO/","title":"API Documentation TODO","text":"<p>This TODO tracks the work items for building a comprehensive Flame Python API knowledge base.</p> <ul> <li>[x] API-0001 (partial): Create the overall plan and infrastructure for per-symbol docs (scripts + basic output)</li> <li>[x] API-0002: Add symbol cross-links from <code>flame.md</code> and index.json (initial links present)</li> <li>[x] API-0003 (partial): Add class methods capture (collector captures methods)</li> <li>[x] API-0004 (partial): Implement safe probing (<code>--probe-safe</code> implemented, opt-in)</li> <li>[x] API-0005 (partial): Improve <code>stubs/*.pyi</code> with signatures (done for many symbols)</li> <li>[x] API-0006: Add stub parsing tests (planned)</li> <li>[x] API-0007: Add example hooks (startup/menu/asset-sync) and smoke tests \u2705</li> <li>[x] API-0008: Add snippets for Project/Timeline/Clip and smoke tests \u2705</li> <li>[x] API-0009: Add mkdocs + CI publishing (CI workflow added; deploy on push) \u2705</li> <li>[x] API-0016: Remove generated <code>site/</code> from the repository and publish site from CI (site is now untracked; <code>.github/workflows/docs.yml</code> publishes the site) \u2705</li> <li> <p>[x] API-0010: Generate per-symbol Markdown pages: <code>docs/api/classes/&lt;Class&gt;.md</code>, <code>docs/api/functions/&lt;fn&gt;.md</code> (Completed Jan 2026).</p> <ul> <li>Implemented <code>collect_flame_api.py</code> for systematic crawling.</li> <li>Implemented <code>generate_api_docs.py</code> for JSON-to-Markdown conversion.</li> </ul> </li> <li> <p>[ ] API-0011: Add instance attribute probes via allowlist and document safety</p> </li> <li>[ ] API-0012: Improve stub return-type population from probe results</li> <li>[ ] API-0013: Add mkdocs nav entries for symbol directories and symbol index pages</li> <li>[ ] API-0014: Add CI job to optionally run <code>--probe-safe</code> and store results as artifacts</li> <li>[ ] API-0015: Add a probe dashboard and flagged warnings page</li> </ul> <p>Notes: - Items marked \"partial\" mean scaffold/implementation exists but further work is needed.</p>"},{"location":"api/batch/","title":"Object: batch","text":"<p>Type: <code>PyBatch</code></p>"},{"location":"api/batch/#description","title":"Description","text":"<p>Class derived from PyFlameObject. This class represents a Batch Group.</p>"},{"location":"api/browser/","title":"Object: browser","text":"<p>Type: <code>PyBrowser</code></p>"},{"location":"api/browser/#description","title":"Description","text":"<p>This class represents the file browser.</p>"},{"location":"api/clear_graphics_memory/","title":"Object: clear_graphics_memory","text":"<p>Type: <code>function</code></p>"},{"location":"api/clear_graphics_memory/#description","title":"Description","text":"<p>clear_graphics_memory() -&gt; None :</p> <pre><code>Free as much graphics memory as possible.  Note that clearing the undo buffer beforehand can increase the amount of releasable graphics memory.\n</code></pre>"},{"location":"api/clear_unreferenced_cache/","title":"Object: clear_unreferenced_cache","text":"<p>Type: <code>function</code></p>"},{"location":"api/clear_unreferenced_cache/#description","title":"Description","text":"<p>clear_unreferenced_cache([  (bool)all_projects=False]) -&gt; None :</p> <pre><code>Clear cached media that is no longer referenced by any clip in eitherthe current project or any other project.\n\n\n\nall_projects -- If True, will also clear unreferenced cached media from all other accessible projects.\n\n                Default is False, which will only clear unreferenced cached media from the current project.\n</code></pre>"},{"location":"api/delete/","title":"Object: delete","text":"<p>Type: <code>function</code></p>"},{"location":"api/delete/#description","title":"Description","text":"<p>delete( (PyFlameObject)object [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the target object.\n</code></pre>"},{"location":"api/duplicate/","title":"Object: duplicate","text":"<p>Type: <code>function</code></p>"},{"location":"api/duplicate/#description","title":"Description","text":"<p>duplicate( (PyFlameObject)object [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the target object.\n</code></pre>"},{"location":"api/duplicate_many/","title":"Object: duplicate_many","text":"<p>Type: <code>function</code></p>"},{"location":"api/duplicate_many/#description","title":"Description","text":"<p>duplicate_many( (list)object_list [, (bool)keep_node_connections=False]) -&gt; list :</p> <pre><code>Duplicate the target objects.\n</code></pre>"},{"location":"api/execute_command/","title":"Object: execute_command","text":"<p>Type: <code>function</code></p>"},{"location":"api/execute_command/#description","title":"Description","text":"<p>execute_command( (str)command [, (bool)blocking=True [, (bool)shell=False [, (bool)capture_stdout=False [, (bool)capture_stderr=False]]]]) -&gt; tuple :</p> <pre><code>Execute command line through the Autodesk Flame Multi-Purpose Daemon.\n\nThis way of starting new processes is better since any native python\n\nsubprocess command (os.system, subprocess, Popen, etc) will call fork()\n\nwhich will duplicate the process memory before calling exec().\n\nThis can be costly especially for a process like Flame.\n\n\n\ncommand -- Command line to execute.\n\nblocking -- If True, will not return until the command line has completed.\n\nshell -- Should the command be executed in a sh shell.\n\n         WARNING Using shell=True can be a security hazard.\n\ncapture_stdout -- If True, stdout of the command will be captured and\n\n                  returned instead of forwarded to the application stdout.\n\n                  Requires blocking=True\n\ncapture_stderr -- If True, stdout of the command will be captured and\n\n                  returned instead of forwarded to the application stderr.\n\n                  Requires blocking=True\n\n\n\nNote: Environment variables will not be forwarded to the executed command.\n</code></pre>"},{"location":"api/execute_shortcut/","title":"Object: execute_shortcut","text":"<p>Type: <code>function</code></p>"},{"location":"api/execute_shortcut/#description","title":"Description","text":"<p>execute_shortcut( (str)description [, (bool)update_list=True]) -&gt; bool :</p> <pre><code>Execute the Flame shortcut.\n\ndescription  -- The description in the Keyboard Shortcut editor.\n</code></pre>"},{"location":"api/exit/","title":"Object: exit","text":"<p>Type: <code>function</code></p>"},{"location":"api/exit/#description","title":"Description","text":"<p>exit() -&gt; None :</p> <pre><code>Exit the application.\n</code></pre>"},{"location":"api/find_by_name/","title":"Object: find_by_name","text":"<p>Type: <code>function</code></p>"},{"location":"api/find_by_name/#description","title":"Description","text":"<p>find_by_name( (str)name [, (object)parent=None]) -&gt; list :</p> <pre><code>Find a Flame object in the Media Panel by name.\n</code></pre>"},{"location":"api/find_by_uid/","title":"Object: find_by_uid","text":"<p>Type: <code>function</code></p>"},{"location":"api/find_by_uid/#description","title":"Description","text":"<p>find_by_uid( (str)uid) -&gt; object :</p> <pre><code>Find a Flame object in the Media Panel by UID.\n</code></pre>"},{"location":"api/find_by_wiretap_node_id/","title":"Object: find_by_wiretap_node_id","text":"<p>Type: <code>function</code></p>"},{"location":"api/find_by_wiretap_node_id/#description","title":"Description","text":"<p>find_by_wiretap_node_id( (str)node_id) -&gt; object :</p> <pre><code>Find a Flame object in the Media Panel by Wiretap Node ID.\n</code></pre>"},{"location":"api/flush_graphics_memory/","title":"Object: flush_graphics_memory","text":"<p>Type: <code>function</code></p>"},{"location":"api/flush_graphics_memory/#description","title":"Description","text":"<p>flush_graphics_memory() -&gt; None :</p> <pre><code>Free as much graphics memory as possible.  Note that clearing the undo buffer beforehand can increase the amount of releasable graphics memory.\n\n(Deprecated: use clear_graphics_memory instead)\n</code></pre>"},{"location":"api/get_current_tab/","title":"Object: get_current_tab","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_current_tab/#description","title":"Description","text":"<p>get_current_tab() -&gt; str :</p> <pre><code>Get the current tab name.\n</code></pre>"},{"location":"api/get_home_directory/","title":"Object: get_home_directory","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_home_directory/#description","title":"Description","text":"<p>get_home_directory() -&gt; str :</p> <pre><code>Get the application home directory.\n</code></pre>"},{"location":"api/get_init_cfg_path/","title":"Object: get_init_cfg_path","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_init_cfg_path/#description","title":"Description","text":"<p>get_init_cfg_path() -&gt; str :</p> <pre><code>Get the application init configuration file.\n</code></pre>"},{"location":"api/get_version/","title":"Object: get_version","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_version/#description","title":"Description","text":"<p>get_version() -&gt; str :</p> <pre><code>Get the application version.\n</code></pre>"},{"location":"api/get_version_major/","title":"Object: get_version_major","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_version_major/#description","title":"Description","text":"<p>get_version_major() -&gt; str :</p> <pre><code>Get the application major version.\n</code></pre>"},{"location":"api/get_version_minor/","title":"Object: get_version_minor","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_version_minor/#description","title":"Description","text":"<p>get_version_minor() -&gt; str :</p> <pre><code>Get the application minor version.\n</code></pre>"},{"location":"api/get_version_patch/","title":"Object: get_version_patch","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_version_patch/#description","title":"Description","text":"<p>get_version_patch() -&gt; str :</p> <pre><code>Get the application patch version.\n</code></pre>"},{"location":"api/get_version_stamp/","title":"Object: get_version_stamp","text":"<p>Type: <code>function</code></p>"},{"location":"api/get_version_stamp/#description","title":"Description","text":"<p>get_version_stamp() -&gt; str :</p> <pre><code>Get the application version stamp.\n</code></pre>"},{"location":"api/go_to/","title":"Object: go_to","text":"<p>Type: <code>function</code></p>"},{"location":"api/go_to/#description","title":"Description","text":"<p>go_to( (str)tab) -&gt; bool :</p> <pre><code>Deprecated / use set_current_tab() instead.\n</code></pre>"},{"location":"api/import_clips/","title":"Object: import_clips","text":"<p>Type: <code>function</code></p>"},{"location":"api/import_clips/#description","title":"Description","text":"<p>import_clips( (object)path [, (object)destination=None]) -&gt; list :</p> <pre><code>Import one or many clips from a path.\n\nKeyword arguments:\n\npath -- The path to the media can be:\n\n - A path to a single media file.\n\n - A path to a sequence of media files (ie \"/dir/clip.[100-2000].dpx\").\n\n - A folder containing media files.\n\n - A pattern to media files (ie \"/dir/{name}_v{version}.{frame}.{extension}\").\n\n - A list of paths.\n\ndestination -- Flame object containing a clip like a reel or a folder object.\n</code></pre>"},{"location":"api/media_panel/","title":"Object: media_panel","text":"<p>Type: <code>PyMediaPanel</code></p>"},{"location":"api/media_panel/#description","title":"Description","text":"<p>This class represents the media panel.</p>"},{"location":"api/mediahub/","title":"Object: mediahub","text":"<p>Type: <code>PyMediaHub</code></p>"},{"location":"api/mediahub/#description","title":"Description","text":"<p>This class represents the MediaHub.</p>"},{"location":"api/messages/","title":"Object: messages","text":"<p>Type: <code>PyMessages</code></p>"},{"location":"api/messages/#description","title":"Description","text":"<p>Module handling message bar in application UI.</p>"},{"location":"api/project/","title":"Object: project","text":"<p>Type: <code>PyProjectSelector</code></p>"},{"location":"api/project/#description","title":"Description","text":"<p>Object representing the Project manager.</p>"},{"location":"api/projects/","title":"Object: projects","text":"<p>Type: <code>PyProjectSelector</code></p>"},{"location":"api/projects/#description","title":"Description","text":"<p>Object representing the Project manager.</p>"},{"location":"api/pybox/","title":"Pybox API Reference (<code>pybox_v1</code>)","text":"<p>This document provides a technical reference for the <code>pybox_v1</code> module, which is used to create handlers for Autodesk Flame's Pybox nodes.</p> <p>Module: <code>pybox_v1</code> Location: <code>/opt/Autodesk/presets/&lt;version&gt;/shared/pybox/pybox_v1.py</code></p>"},{"location":"api/pybox/#ui-creation-functions","title":"UI Creation Functions","text":"<p>These functions are used to define the user interface of the Pybox node. Elements created with these functions must be added to the node using <code>BaseClass.add_render_elements()</code> or <code>BaseClass.add_global_elements()</code>.</p>"},{"location":"api/pybox/#create_pagename-cols","title":"<code>create_page(name, *cols)</code>","text":"<p>Creates a new page definition for the node UI. - name (str): Display name of the tab. - cols (str, optional): Names of the columns in the page. - Returns: A page definition dictionary.</p>"},{"location":"api/pybox/#create_float_numericname-value00-default00-min00-max1000-inc10-row0-col0-page0-channel_namenone-tooltip","title":"<code>create_float_numeric(name, value=0.0, default=0.0, min=0.0, max=100.0, inc=1.0, row=0, col=0, page=0, channel_name=None, tooltip=\"\")</code>","text":"<p>Creates a floating-point numeric field. - name (str): Label displayed in the UI. - value (float): Current value. - default (float): Default value on load. - min (float): Minimum allowed value. - max (float): Maximum allowed value. - inc (float): Increment step when dragging. - row (int): Y position (0-4). - col (int): X position (0-3). - page (int): Page index (0-5). - channel_name (str, optional): Animation channel name. Defaults to <code>name + \"_chn\"</code>. - tooltip (str): Tooltip text.</p>"},{"location":"api/pybox/#create_vector_numericname-size3-valuesnone-numeric_infonone-default00-min00-max1000-inc10-row0-col0-page0-channel_namenone-tooltip","title":"<code>create_vector_numeric(name, size=3, values=None, numeric_info=None, default=0.0, min=0.0, max=100.0, inc=1.0, row=0, col=0, page=0, channel_name=None, tooltip=\"\")</code>","text":"<p>Creates a 2D or 3D vector numeric field. - name (str): Label displayed in the UI. - size (int): Vector dimension (2 or 3). - values (list[float]): Initial values. - numeric_info (list): Optional list of per-component info (see <code>create_numeric_info</code>). - default (float): Default value for all components. - min, max, inc: Constraints for all components.</p>"},{"location":"api/pybox/#create_popupname-items-value0-default0-row0-col0-page0-tooltip","title":"<code>create_popup(name, items, value=0, default=0, row=0, col=0, page=0, tooltip=\"\")</code>","text":"<p>Creates a dropdown menu. - name (str): Label. - items (list[str]): List of menu options. - value (int): Index of current selection. - default (int): Index of default selection.</p>"},{"location":"api/pybox/#create_colorname-defaultnone-valuesnone-row0-col0-page0-channel_name0-tooltip","title":"<code>create_color(name, default=None, values=None, row=0, col=0, page=0, channel_name=0, tooltip=\"\")</code>","text":"<p>Creates a color pot. - name (str): Label. - default (list[float]): Default RGB values [0.0-1.0]. - values (list[float]): Current RGB values.</p>"},{"location":"api/pybox/#create_toggle_buttonname-value-defaultfalse-row0-col0-page0-tooltip","title":"<code>create_toggle_button(name, value, default=False, row=0, col=0, page=0, tooltip=\"\")</code>","text":"<p>Creates a toggle button. - name (str): Label. - value (bool): Current state (True/False). - default (bool): Default state.</p>"},{"location":"api/pybox/#create_file_browsername-value-extension-home-row0-col0-page0-tooltip-isfileselectortrue","title":"<code>create_file_browser(name, value, extension, home, row=0, col=0, page=0, tooltip=\"\", isFileSelector=True)</code>","text":"<p>Creates a file browser widget. - name (str): Label. - value (str): Current path. - extension (str): File extension filter (e.g., \"jpg\", \"exr\"). - home (str): Default \"Home\" directory path. - isFileSelector (bool): True for file selection, False for directory.</p>"},{"location":"api/pybox/#create_text_fieldname-value-row0-col0-page0-tooltip-isfieldtrue","title":"<code>create_text_field(name, value=\"\", row=0, col=0, page=0, tooltip=\"\", isField=True)</code>","text":"<p>Creates a string input field. - name (str): Label. - value (str): Current text.</p>"},{"location":"api/pybox/#baseclass","title":"BaseClass","text":"<p>The <code>BaseClass</code> is the parent class for all Pybox handlers. Your handler must inherit from this class and override specific lifecycle methods.</p>"},{"location":"api/pybox/#lifecycle-methods-override-these","title":"Lifecycle Methods (Override these)","text":""},{"location":"api/pybox/#initializeself","title":"<code>initialize(self)</code>","text":"<p>Called when the Pybox is first loaded. Use this to: - Set image format (<code>set_img_format</code>). - Define input/output sockets (<code>set_in_socket</code>, <code>set_out_socket</code>). - Transition state: <code>self.set_state_id(\"setup_ui\")</code> followed by <code>self.setup_ui()</code>.</p>"},{"location":"api/pybox/#setup_uiself","title":"<code>setup_ui(self)</code>","text":"<p>Called to define the UI. Use this to: - Create UI elements using the <code>create_*</code> functions. - Add elements to pools: <code>add_global_elements()</code>, <code>add_render_elements()</code>. - Set pages: <code>set_ui_pages()</code>. - Transition state: <code>self.set_state_id(\"execute\")</code> followed by <code>self.execute()</code>.</p>"},{"location":"api/pybox/#executeself","title":"<code>execute(self)</code>","text":"<p>Called when processing is required. Use this to: - Read input sockets/parameters. - Run external processes (e.g., call Nuke, Maya, ImageMagick). - Write to output sockets. - Transition state: <code>self.set_state_id(\"teardown\")</code> followed by <code>self.teardown()</code>.</p>"},{"location":"api/pybox/#teardownself","title":"<code>teardown(self)</code>","text":"<p>Called when the Pybox is destroyed or the handler is changed. Clean up resources here.</p>"},{"location":"api/pybox/#state-management","title":"State Management","text":""},{"location":"api/pybox/#set_state_idself-state_id","title":"<code>set_state_id(self, state_id)</code>","text":"<p>Sets the next state for the Pybox. - state_id (str): One of <code>\"initialize\"</code>, <code>\"setup_ui\"</code>, <code>\"execute\"</code>, <code>\"teardown\"</code>.</p>"},{"location":"api/pybox/#dispatchself","title":"<code>dispatch(self)</code>","text":"<p>Executes the method corresponding to the current <code>state_id</code>.</p>"},{"location":"api/pybox/#socket-management","title":"Socket Management","text":""},{"location":"api/pybox/#set_in_socketself-idx-socket_type-path","title":"<code>set_in_socket(self, idx, socket_type, path)</code>","text":"<p>Defines an input socket at a specific index. - idx (int): 0-based index. - socket_type (str): \"Front\", \"Matte\", \"Back\", \"3DMotion\", \"Background\", \"MotionVector\", \"Normal\", \"Position\", \"Uv\", \"ZDepth\", \"undefined\". - path (str): File path where Flame writes the input image.</p>"},{"location":"api/pybox/#set_out_socketself-idx-socket_type-path","title":"<code>set_out_socket(self, idx, socket_type, path)</code>","text":"<p>Defines an output socket at a specific index. - socket_type (str): \"Result\", \"OutMatte\", \"Out3DMotion\", etc. - path (str): File path where Flame expects the result image.</p>"},{"location":"api/pybox/#add_in_socketself-socket_type-path","title":"<code>add_in_socket(self, socket_type, path)</code>","text":"<p>Appends a new input socket.</p>"},{"location":"api/pybox/#add_out_socketself-socket_type-path","title":"<code>add_out_socket(self, socket_type, path)</code>","text":"<p>Appends a new output socket.</p>"},{"location":"api/pybox/#ui-management","title":"UI Management","text":""},{"location":"api/pybox/#add_global_elementsself-elements","title":"<code>add_global_elements(self, *elements)</code>","text":"<p>Adds UI elements that trigger an immediate Python callback when changed (e.g., browsers, setup buttons).</p>"},{"location":"api/pybox/#add_render_elementsself-elements","title":"<code>add_render_elements(self, *elements)</code>","text":"<p>Adds UI elements that only update parameters for the render pass (e.g., blur amount, color correction).</p>"},{"location":"api/pybox/#set_ui_pagesself-pages","title":"<code>set_ui_pages(self, *pages)</code>","text":"<p>Sets the visible pages (tabs) in the node UI.</p>"},{"location":"api/pybox/#get_global_element_valueself-name-set_global_element_valueself-name-value","title":"<code>get_global_element_value(self, name)</code> / <code>set_global_element_value(self, name, value)</code>","text":"<p>Get/Set values for global elements.</p>"},{"location":"api/pybox/#get_render_element_valueself-name-set_render_element_valueself-name-value","title":"<code>get_render_element_value(self, name)</code> / <code>set_render_element_value(self, name, value)</code>","text":"<p>Get/Set values for render elements.</p>"},{"location":"api/pybox/#metadata-access-getters","title":"Metadata Access (Getters)","text":"<ul> <li><code>get_bit_depth()</code></li> <li><code>get_colour_space()</code></li> <li><code>get_date()</code>, <code>get_date_day()</code>, <code>get_date_month()</code>, <code>get_date_year()</code></li> <li><code>get_frame()</code> (Current Batch frame)</li> <li><code>get_frame_ratio()</code></li> <li><code>get_framerate()</code></li> <li><code>get_height()</code>, <code>get_width()</code> (Resolution)</li> <li><code>get_img_format()</code></li> <li><code>get_nickname()</code>, <code>get_user()</code></li> <li><code>get_node_name()</code></li> <li><code>get_project()</code>, <code>get_project_nickname()</code></li> <li><code>get_record_time_code()</code>, <code>get_source_time_code()</code></li> <li><code>get_shot_name()</code>, <code>get_tape_name()</code></li> <li><code>get_workstation()</code></li> </ul>"},{"location":"api/pybox/#messaging-logging","title":"Messaging / Logging","text":"<ul> <li><code>set_error_msg(msg)</code></li> <li><code>set_warning_msg(msg)</code></li> <li><code>set_notice_msg(msg)</code></li> <li><code>set_debug_msg(msg)</code></li> </ul>"},{"location":"api/schedule_idle_event/","title":"Object: schedule_idle_event","text":"<p>Type: <code>function</code></p>"},{"location":"api/schedule_idle_event/#description","title":"Description","text":"<p>schedule_idle_event( (object)function [, (int)delay=0]) -&gt; None :</p> <pre><code>Register a function callback that will be called eventually when the application is idle. The function must not block and be quick since it will be executed in the main application thread.\n\nKeyword arguments:\n\nfunction -- Callable object to be called.\n\ndelay -- Minimum time (in seconds) to wait before calling function.\n</code></pre>"},{"location":"api/set_current_tab/","title":"Object: set_current_tab","text":"<p>Type: <code>function</code></p>"},{"location":"api/set_current_tab/#description","title":"Description","text":"<p>set_current_tab( (str)arg1) -&gt; bool :</p> <pre><code>Set the given tab as the active environment.\n\nKeyword arguments:\n\ntab -- The tab to set active (MediaHub, Conform, Timeline, Effects, Batch, Tools)\n</code></pre>"},{"location":"api/set_render_option/","title":"Object: set_render_option","text":"<p>Type: <code>function</code></p>"},{"location":"api/set_render_option/#description","title":"Description","text":"<p>set_render_option( (str)render_option [, (str)render_context='']) -&gt; bool :</p> <pre><code>Set the default render option.\n\nKeyword arguments:\n\nrender_option -- Defines the rendering method used. (Foreground)\n\nrender_context -- Defines the rendering context. (Timeline, Conform, Effects, BFX, Batch). None for all of them.\n</code></pre>"},{"location":"api/timeline/","title":"Object: timeline","text":"<p>Type: <code>PyTimeline</code></p>"},{"location":"api/timeline/#description","title":"Description","text":"<p>This class represents the Timeline.</p>"},{"location":"api/users/","title":"Object: users","text":"<p>Type: <code>PyUsers</code></p>"},{"location":"api/users/#description","title":"Description","text":"<p>Object representing the User manager.</p>"},{"location":"api/classes/PyActionFamilyNode/","title":"Class: PyActionFamilyNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyActionFamilyNode/#description","title":"Description","text":"<p>Class derived from PyNode. Represents an Action Family node object.</p>"},{"location":"api/classes/PyActionFamilyNode/#properties","title":"Properties","text":"Name Description <code>all_tabs</code> Return a list of the object tabs. <code>attributes</code> The attributes of a python object. <code>cursor_position</code> Return a tuple that provides the cursor position in the Action/Image/GMaskTracer schematic. <code>input_sockets</code> Return a list of the node input sockets names. <code>left_tabs</code> Return a list of the object left tabs. <code>media_layers</code> Return a list of the Media layers of the Action/Image/GMaskTracer node. <code>node_types</code> Return a list of the node types available in the Action/Image/GMaskTracer schematic. <code>nodes</code> Return a list of Action/Image/GMaskTracer nodes used in the the Action/Image/GMaskTracer schematic. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>right_tabs</code> Return a list of the object right tabs. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyActionFamilyNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyActionFamilyNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#clear_schematic","title":"<code>clear_schematic</code>","text":"<pre><code>clear_schematic\n</code></pre> <p>clear_schematic( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clear the Action/Image/GMaskTracer schematic of all nodes.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#connect_nodes","title":"<code>connect_nodes</code>","text":"<pre><code>connect_nodes\n</code></pre> <p>connect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Connect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#create_node","title":"<code>create_node</code>","text":"<pre><code>create_node\n</code></pre> <p>create_node( (PyActionFamilyNode)arg1, (str)node_type [, (str)file_path='' [, (bool)is_udim=False [, (int)tile_resolution=0 [, (str)input_colour_space='']]]]) -&gt; object :</p> <pre><code>Add an Action/Image/GMaskTracer object node to the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\nfile_path -- Required by nodes that load an asset, such as Matchbox.\n\ninput_colour_space -- Optional for nodes that load external media, such as IBL.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#disconnect_nodes","title":"<code>disconnect_nodes</code>","text":"<pre><code>disconnect_nodes\n</code></pre> <p>disconnect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Disconnect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#encompass_nodes","title":"<code>encompass_nodes</code>","text":"<pre><code>encompass_nodes\n</code></pre> <p>encompass_nodes( (PyActionFamilyNode)arg1, (list)node_list) -&gt; object :</p> <pre><code>Create a compass including the node list given as argument\n\nKeyword argument:\n\nnode_list -- a list of nodes (either string or node objects)\n\noutput_type -- the created compass node\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#get_node","title":"<code>get_node</code>","text":"<pre><code>get_node\n</code></pre> <p>get_node( (PyActionFamilyNode)arg1, (str)node_name) -&gt; object :</p> <pre><code>Get a node by node name. Doesn't select it in the UI.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#organize","title":"<code>organize</code>","text":"<pre><code>organize\n</code></pre> <p>organize( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clean up the Action/Image/GMaskTracer schematic.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyActionFamilyNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyActionNode/","title":"Class: PyActionNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyActionFamilyNode, PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyActionNode/#description","title":"Description","text":"<p>Class derived from PyActionFamilyNode. Represents an Action node object.</p>"},{"location":"api/classes/PyActionNode/#properties","title":"Properties","text":"Name Description <code>all_tabs</code> Return a list of the object tabs. <code>attributes</code> The attributes of a python object. <code>cursor_position</code> Return a tuple that provides the cursor position in the Action/Image/GMaskTracer schematic. <code>input_sockets</code> Return a list of the node input sockets names. <code>left_tabs</code> Return a list of the object left tabs. <code>media_layers</code> Return a list of the Media layers of the Action/Image/GMaskTracer node. <code>media_nodes</code> Return a list of the Media nodes attached to the Action node. <code>node_types</code> Return a list of the node types available in the Action/Image/GMaskTracer schematic. <code>nodes</code> Return a list of Action/Image/GMaskTracer nodes used in the the Action/Image/GMaskTracer schematic. <code>output_sockets</code> Return a list of the node output sockets names. <code>output_types</code> Return a list of the output types available to the Action node. <code>parent</code> The parent object of this object. <code>right_tabs</code> Return a list of the object right tabs. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyActionNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyActionNode/#add_media","title":"<code>add_media</code>","text":"<pre><code>add_media\n</code></pre> <p>add_media( (PyActionFamilyNode)arg1) -&gt; object :</p> <pre><code>Add a Media layer to the Batch Action node.\n\nAlso instantiates a matching Surface node (and Axis) in the Action node schematic.\n</code></pre>"},{"location":"api/classes/PyActionNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyActionNode/#clear_schematic","title":"<code>clear_schematic</code>","text":"<pre><code>clear_schematic\n</code></pre> <p>clear_schematic( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clear the Action/Image/GMaskTracer schematic of all nodes.\n</code></pre>"},{"location":"api/classes/PyActionNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyActionNode/#connect_nodes","title":"<code>connect_nodes</code>","text":"<pre><code>connect_nodes\n</code></pre> <p>connect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Connect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyActionNode/#create_node","title":"<code>create_node</code>","text":"<pre><code>create_node\n</code></pre> <p>create_node( (PyActionFamilyNode)arg1, (str)node_type [, (str)file_path='' [, (bool)is_udim=False [, (int)tile_resolution=0 [, (str)input_colour_space='']]]]) -&gt; object :</p> <pre><code>Add an Action/Image/GMaskTracer object node to the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\nfile_path -- Required by nodes that load an asset, such as Matchbox.\n\ninput_colour_space -- Optional for nodes that load external media, such as IBL.\n</code></pre>"},{"location":"api/classes/PyActionNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyActionNode/#disable_output","title":"<code>disable_output</code>","text":"<pre><code>disable_output\n</code></pre> <p>disable_output( (PyActionFamilyNode)arg1, (str)output_type) -&gt; bool :</p> <pre><code>Disable the render output_type for the Action node.\n\nKeyword argument:\n\noutput_type -- The output to enable. (Comp, Matte, 3D Motion, Albedo, AO, Background, Emissive, GMask, Lens Flare, Motion Vectors, Normals, Object ID, Occluder, Position, Projectors Matte, Reflection, Roughness, Shadow, Specular, UV, Z-Depth HQ, Z-Depth)\n</code></pre>"},{"location":"api/classes/PyActionNode/#disconnect_nodes","title":"<code>disconnect_nodes</code>","text":"<pre><code>disconnect_nodes\n</code></pre> <p>disconnect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Disconnect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyActionNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyActionNode/#enable_output","title":"<code>enable_output</code>","text":"<pre><code>enable_output\n</code></pre> <p>enable_output( (PyActionFamilyNode)arg1, (str)output_type) -&gt; bool :</p> <pre><code>Enable the render output_type for the Action node.\n\nKeyword argument:\n\noutput_type -- The output to enable. (Comp, Matte, 3D Motion, Albedo, AO, Background, Emissive, GMask, Lens Flare, Motion Vectors, Normals, Object ID, Occluder, Position, Projectoars Matte, Reflection, Roughness, Shadow, Specular, UV, Z-Depth HQ, Z-Depth)\n</code></pre>"},{"location":"api/classes/PyActionNode/#encompass_nodes","title":"<code>encompass_nodes</code>","text":"<pre><code>encompass_nodes\n</code></pre> <p>encompass_nodes( (PyActionFamilyNode)arg1, (list)node_list) -&gt; object :</p> <pre><code>Create a compass including the node list given as argument\n\nKeyword argument:\n\nnode_list -- a list of nodes (either string or node objects)\n\noutput_type -- the created compass node\n</code></pre>"},{"location":"api/classes/PyActionNode/#export_fbx","title":"<code>export_fbx</code>","text":"<pre><code>export_fbx\n</code></pre> <p>export_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)only_selected_nodes=False [, (float)pixel_to_units=0.10000000149011612 [, (str)frame_rate='23.976 fps' [, (bool)bake_animation=False [, (bool)export_axes=True [, (bool)export_point_locators=False [, (bool)combine_material=True [, (bool)duplicate_material=False]]]]]]]]) -&gt; bool :</p> <pre><code>Export Action nodes to an FBX file.\n\nKeyword argument:\n\nfile_path -- Path to the output FBX file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyActionNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyActionNode/#get_node","title":"<code>get_node</code>","text":"<pre><code>get_node\n</code></pre> <p>get_node( (PyActionFamilyNode)arg1, (str)node_name) -&gt; object :</p> <pre><code>Get a node by node name. Doesn't select it in the UI.\n</code></pre>"},{"location":"api/classes/PyActionNode/#import_abc","title":"<code>import_abc</code>","text":"<pre><code>import_abc\n</code></pre> <p>import_abc( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (str)frame_rate='23.976 fps' [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)consolidate_geometry=True [, (bool)create_object_group=False]]]]]]]]]]) -&gt; list :</p> <pre><code>Import an Alembic (ABC) file into the Action schematic using the Action Objects mode.\n\nKeyword argument:\n\nfile_path -- Path to the ABC file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyActionNode/#import_fbx","title":"<code>import_fbx</code>","text":"<pre><code>import_fbx\n</code></pre> <p>import_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (bool)keep_frame_rate=True [, (bool)bake_animation=False [, (bool)object_properties=True [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)create_media=True [, (bool)is_udim=False [, (bool)relink_material=True [, (str)input_colour_space='']]]]]]]]]]]]]]) -&gt; list :</p> <pre><code>Import an FBX file into the Action schematic using the Action Objects mode.\n\nKeyword argument:\n\nfile_path -- Path to the FBX file. Mandatory.\n\ninput_colour_space -- Colour space name used as input for textures. Optional.\n</code></pre>"},{"location":"api/classes/PyActionNode/#import_psd","title":"<code>import_psd</code>","text":"<pre><code>import_psd\n</code></pre> <p>import_psd( (PyActionFamilyNode)arg1, (str)file_path [, (str)input_colour_space='']) -&gt; list :</p> <pre><code>Import a PSD file into the Action schematic.\n\nKeyword arguments:\n\nfile_path -- Path to the PSD file. Mandatory.\n\ninput_colour_space -- The colour space used as input. Optional.\n</code></pre>"},{"location":"api/classes/PyActionNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyActionNode/#organize","title":"<code>organize</code>","text":"<pre><code>organize\n</code></pre> <p>organize( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clean up the Action/Image/GMaskTracer schematic.\n</code></pre>"},{"location":"api/classes/PyActionNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyActionNode/#read_abc","title":"<code>read_abc</code>","text":"<pre><code>read_abc\n</code></pre> <p>read_abc( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (str)frame_rate='23.976 fps' [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)consolidate_geometry=True [, (bool)create_object_group=False]]]]]]]]]]) -&gt; object :</p> <pre><code>Import an Alembic (ABC) file into the Action schematic using the Read File mode.\n\nKeyword argument:\n\nfile_path -- Path to the ABC file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyActionNode/#read_fbx","title":"<code>read_fbx</code>","text":"<pre><code>read_fbx\n</code></pre> <p>read_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (bool)keep_frame_rate=True [, (bool)bake_animation=False [, (bool)object_properties=True [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)is_udim=False [, (bool)relink_material=True [, (str)input_colour_space='']]]]]]]]]]]]]) -&gt; object :</p> <pre><code>Import an FBX file into the Action schematic using the Read File mode.\n\nKeyword argument:\n\nfile_path -- Path to the FBX file. Mandatory.\n\ninput_colour_space -- Colour space name used as input for textures. Optional.\n</code></pre>"},{"location":"api/classes/PyActionNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyActionNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyArchiveEntry/","title":"Class: PyArchiveEntry","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyArchiveEntry/#description","title":"Description","text":"<p>Class derived from PyFlameObject. Base class for any object displayed in the Media Panel.</p>"},{"location":"api/classes/PyArchiveEntry/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object."},{"location":"api/classes/PyArchiveEntry/#methods","title":"Methods","text":""},{"location":"api/classes/PyArchiveEntry/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyArchiveEntry/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyArchiveEntry/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyArchiveEntry/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyAttribute/","title":"Class: PyAttribute","text":"<p>Module: <code>flame</code></p>"},{"location":"api/classes/PyAudioTrack/","title":"Class: PyAudioTrack","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyAudioTrack/#description","title":"Description","text":"<p>Object representing an Audio Track.</p>"},{"location":"api/classes/PyAudioTrack/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>channels</code> Return a list of the Audio Track's channels. <code>parent</code> The parent object of this object. <code>stereo</code> Return whether or not the Audio Track is stereo."},{"location":"api/classes/PyAudioTrack/#methods","title":"Methods","text":""},{"location":"api/classes/PyAudioTrack/#copy_to_media_panel","title":"<code>copy_to_media_panel</code>","text":"<pre><code>copy_to_media_panel\n</code></pre> <p>copy_to_media_panel( (PyAudioTrack)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip with a copy of the PyObject.\n</code></pre>"},{"location":"api/classes/PyBatch/","title":"Class: PyBatch","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyBatch/#description","title":"Description","text":"<p>Class derived from PyFlameObject. This class represents a Batch Group.</p>"},{"location":"api/classes/PyBatch/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>batch_iterations</code> Return a list of Batch Iteration objects of the Batch Group. <code>contexts</code> Return a dictionary of Context views registered in the Batch Group. Dictionary {key:value} -- {Context ID : {Batch node name:socket name} } <code>current_iteration</code> Return the current Batch Iteration object of the Batch Group. <code>current_iteration_number</code> Return the iteration number of the current Batch Iteration. <code>cursor_position</code> Return a tuple that provides the cursor position in the Batch Schematic. <code>node_types</code> Return a list of the names of the Batch node types available to the Batch schematic. <code>nodes</code> Return the list of Batch node objects from the Batch schematic. <code>opened</code> Return True if the Batch Group is loaded in memory. <code>parent</code> The parent object of this object. <code>reels</code> Return the list of reel objects (as Schematic Reels) for the Batch Group. <code>shelf_reels</code> Return the list of reel objects (as Shelf Reels) for the Batch Group."},{"location":"api/classes/PyBatch/#methods","title":"Methods","text":""},{"location":"api/classes/PyBatch/#append_setup","title":"<code>append_setup</code>","text":"<pre><code>append_setup\n</code></pre> <p>append_setup( (PyBatch)arg1, (str)setup_path [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Append a Batch setup file to the existing Batch setup.\n\nKeywords arguments:\n\nsetup_path -- A path and a filename must be defined as arguments.\n\nconfirm -- Set to True (default) to display a dialogue box in case of\n</code></pre>"},{"location":"api/classes/PyBatch/#append_to_batch","title":"<code>append_to_batch</code>","text":"<pre><code>append_to_batch\n</code></pre> <p>append_to_batch( (PyBatch)arg1, (PyBatchIteration)batch_iteration) -&gt; bool :</p> <pre><code>Append a Batch Iteration object to the current Batch Group. A duplicate Batch Iteration object is renamed to the next available *vDD*. Batch Iteration objects are displayed in the Iterations folder. Iterations folder is a UI construction, not accessible directly.\n</code></pre>"},{"location":"api/classes/PyBatch/#append_to_setup","title":"<code>append_to_setup</code>","text":"<pre><code>append_to_setup\n</code></pre> <p>append_to_setup( (PyBatch)arg1, (PyBatchIteration)batch_iteration) -&gt; bool :</p> <pre><code>Append a Batch Iteration object to the Batch Group's setup.\n</code></pre>"},{"location":"api/classes/PyBatch/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyBatch)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Clear the Batch Group.\n</code></pre>"},{"location":"api/classes/PyBatch/#clear_all_contexts","title":"<code>clear_all_contexts</code>","text":"<pre><code>clear_all_contexts\n</code></pre> <p>clear_all_contexts( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Clear all registered Context views in the Batch Group.\n</code></pre>"},{"location":"api/classes/PyBatch/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyBatch)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyBatch/#clear_context","title":"<code>clear_context</code>","text":"<pre><code>clear_context\n</code></pre> <p>clear_context( (PyBatch)arg1, (int)index) -&gt; bool :</p> <pre><code>Clear a specific Context view in the Batch Group.\n</code></pre>"},{"location":"api/classes/PyBatch/#clear_setup","title":"<code>clear_setup</code>","text":"<pre><code>clear_setup\n</code></pre> <p>clear_setup( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Clear the Batch Group's setup.\n</code></pre>"},{"location":"api/classes/PyBatch/#close","title":"<code>close</code>","text":"<pre><code>close\n</code></pre> <p>close( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Close the Batch Group. You cannot close the Batch Group currently selected.\n\nClosing a Batch Group frees up the application it occupies when open. The size of the used memory is significant if in Batch Group schematic hosts many Action nodes with textures or 3D geoms.\n</code></pre>"},{"location":"api/classes/PyBatch/#connect_nodes","title":"<code>connect_nodes</code>","text":"<pre><code>connect_nodes\n</code></pre> <p>connect_nodes( (PyBatch)arg1, (PyNode)output_node, (str)output_socket_name='Default', (PyNode)input_node [, (str)input_socket_name='Default']) -&gt; bool :</p> <pre><code>Connect two nodes in the Batch schematic.\n\nKeyword arguments:\n\noutput_node -- The Batch node object, the origin of the connection.\n\noutput_socket_name -- The name of the output socket where the connector starts; use *Default* to use the first output socket, usually *Result*.\n\ninput_node -- The child Batch node object, the target of the connection.\n\ninput_socket_name -- The name of the input socket where the connector ends; use *Default* to use the first input socket, usually *Front*. Using *Default* on an Action node connects to the Background socket. To connect to an Action media node, use &lt;ActionNode&gt;.media_nodes[].\n</code></pre>"},{"location":"api/classes/PyBatch/#create_batch_group","title":"<code>create_batch_group</code>","text":"<pre><code>create_batch_group\n</code></pre> <p>create_batch_group( (PyBatch)arg1, (str)name [, (object)nb_reels=None [, (object)nb_shelf_reels=None [, (list)reels=[] [, (list)shelf_reels=[] [, (int)start_frame=1 [, (object)duration=None]]]]]]) -&gt; object :</p> <pre><code>Create a new Batch Group object in the Desktop catalogue.\n\nKeyword arguments:\n\nname -- Name of the Batch Group.\n\nnb_reels -- Number of reels created. *reels* overrides *nb_reels*.\n\nnb_shelf_reels -- Number of shelf reels. The first shelf reel created is named Batch Renders. *shelf_reels* ovverides *nb_shelf_reels*.\n\nreels -- A list of reel names. Overrides *nb_reels*.\n\nshelf_reels -- A list of shelf reel names. Overrides *nb_shelf_reels*.\n\nstart_frame -- The Batch Group's start frame. No timecodes, only a frame value.\n\nduration -- The number of frames. Sets the Duration field in the Batch UI. Will be set to the first clip duration when not specified.\n</code></pre>"},{"location":"api/classes/PyBatch/#create_node","title":"<code>create_node</code>","text":"<pre><code>create_node\n</code></pre> <p>create_node( (PyBatch)arg1, (str)node_type [, (str)file_path='']) -&gt; object :</p> <pre><code>Create a Batch node object in the Batch schematic.\n\n Keyword argument:\n\nnode_type -- Must be a value from the PyBatch.node_types or the name of a node in the User, Project, or Shared bin.\n</code></pre>"},{"location":"api/classes/PyBatch/#create_reel","title":"<code>create_reel</code>","text":"<pre><code>create_reel\n</code></pre> <p>create_reel( (PyBatch)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Schematic Reel in the Batch Gtroup.\n</code></pre>"},{"location":"api/classes/PyBatch/#create_shelf_reel","title":"<code>create_shelf_reel</code>","text":"<pre><code>create_shelf_reel\n</code></pre> <p>create_shelf_reel( (PyBatch)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Shelf Reel in the Batch Group.\n</code></pre>"},{"location":"api/classes/PyBatch/#disconnect_node","title":"<code>disconnect_node</code>","text":"<pre><code>disconnect_node\n</code></pre> <p>disconnect_node( (PyBatch)arg1, (PyNode)node [, (str)input_socket_name='']) -&gt; bool :</p> <pre><code>Disconnect the input links of a given node, given an input socket.\n\nKeyword arguments:\n\nnode -- The Batch node object, the origin of the connection.\n\ninput_socket_name -- The name of the input socket to disconnect.\n</code></pre>"},{"location":"api/classes/PyBatch/#encompass_nodes","title":"<code>encompass_nodes</code>","text":"<pre><code>encompass_nodes\n</code></pre> <p>encompass_nodes( (PyBatch)arg1, (list)nodes) -&gt; object :</p> <pre><code>Create a Compass around a list of nodes in the Batch schematic.\n\n Keyword argument:\n\nnodes -- List of strings of node names.\n</code></pre>"},{"location":"api/classes/PyBatch/#frame_all","title":"<code>frame_all</code>","text":"<pre><code>frame_all\n</code></pre> <p>frame_all( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Set the Batch schematic view to frame all the nodes in the Batch schematic.\n</code></pre>"},{"location":"api/classes/PyBatch/#frame_selected","title":"<code>frame_selected</code>","text":"<pre><code>frame_selected\n</code></pre> <p>frame_selected( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Set the Batch schematic view to frame the nodes selected in the Batch schematic.\n</code></pre>"},{"location":"api/classes/PyBatch/#get_node","title":"<code>get_node</code>","text":"<pre><code>get_node\n</code></pre> <p>get_node( (PyBatch)arg1, (str)node_name) -&gt; object :</p> <pre><code>Return a Batch node object with a name matching the parameter. Every node in a Batch schematic has a unique name: no duplicates allowed.\n\nKeyword argument:\n\nnode_name -- Node name.\n</code></pre>"},{"location":"api/classes/PyBatch/#go_to","title":"<code>go_to</code>","text":"<pre><code>go_to\n</code></pre> <p>go_to( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Display and set the Batch tab as the active environment.\n</code></pre>"},{"location":"api/classes/PyBatch/#import_clip","title":"<code>import_clip</code>","text":"<pre><code>import_clip\n</code></pre> <p>import_clip( (PyBatch)arg1, (str)file_path, (str)reel_name) -&gt; object :</p> <pre><code>Import a clip using the Import node, and create a Clip node.\n\nKeyword arguments:\n\nfile_path -- The path to the media can be:\n\n - A path to a single media file.\n\n - A path to a sequence of media files (ie \"/dir/clip.[100-2000].dpx\").\n\n - A pattern to media files (ie \"/dir/name_v{version}.{frame}.{extension}\").reel_name -- The name of the destination Schematic Reel.\n</code></pre>"},{"location":"api/classes/PyBatch/#import_clips","title":"<code>import_clips</code>","text":"<pre><code>import_clips\n</code></pre> <p>import_clips( (PyBatch)arg1, (object)file_paths, (str)reel_name) -&gt; object :</p> <pre><code>Import clips using the Import node, and then create Clip nodes in the Schematic Reel.\n\nKeyword arguments:\n\nfile_paths -- A path, or a list of paths, to the media that can be:\n\n - A path to a single media file.\n\n - A path to a sequence of media files (ie \"/dir/clip.[100-2000].dpx\").\n\n - A pattern to media files (ie \"/dir/name_v{version}.{frame}.{extension}\").reel_name -- The name of the destination Schematic Reel.\n</code></pre>"},{"location":"api/classes/PyBatch/#iterate","title":"<code>iterate</code>","text":"<pre><code>iterate\n</code></pre> <p>iterate( (PyBatch)arg1 [, (int)index=-1]) -&gt; object :</p> <pre><code>Iterate the current Batch Setup, creating a new iteration named BatchSetupName_X, where X is the Batch Iteration's index, and starts at 001.\n\n Keyword argument:\n\nindex -- Specifies the iteration's index. If none is specified, the iteration is assigned the next available index (max index + 1). If the index matches that of an existing Batch Iteration, its overwrites the iteration without warning.\n</code></pre>"},{"location":"api/classes/PyBatch/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyBatch)arg1, (str)setup_path) -&gt; bool :</p> <pre><code>Load a Batch setup from disk and replace the current Batch Group's setup.\n\n Keyword argument:\n\nsetup_path -- Filepath + Batch Setup filename.\n</code></pre>"},{"location":"api/classes/PyBatch/#mimic_link","title":"<code>mimic_link</code>","text":"<pre><code>mimic_link\n</code></pre> <p>mimic_link( (PyBatch)arg1, (PyNode)leader_node, (PyNode)follower_node) -&gt; bool :</p> <pre><code>Create a Mimic Link between two Batch nodes. They must be of the same node_type.\n\nKeyword arguments:\n\nleader_node -- The node being mimicked.\n\nfollower_node -- The node doing the mimicking.\n</code></pre>"},{"location":"api/classes/PyBatch/#open","title":"<code>open</code>","text":"<pre><code>open\n</code></pre> <p>open( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Open the Batch Group and display it in the Batch view.\n</code></pre>"},{"location":"api/classes/PyBatch/#open_as_batch_group","title":"<code>open_as_batch_group</code>","text":"<pre><code>open_as_batch_group\n</code></pre> <p>open_as_batch_group( (PyBatch)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Open a Batch Group as a new Batch Group, adding it to PyDesktop.batch_groups. Can only be called from a Library.\n</code></pre>"},{"location":"api/classes/PyBatch/#organize","title":"<code>organize</code>","text":"<pre><code>organize\n</code></pre> <p>organize( (PyBatch)arg1) -&gt; bool :</p> <pre><code>Clean up the nodes layout in the Batch schematic.\n</code></pre>"},{"location":"api/classes/PyBatch/#render","title":"<code>render</code>","text":"<pre><code>render\n</code></pre> <p>render( (PyBatch)arg1 [, (str)render_option='Foreground' [, (bool)generate_proxies=False [, (bool)include_history=False]]]) -&gt; bool :</p> <pre><code>Trigger the rendering of the Batch Group setup. Every active Render and Write File nodes render. If specified render_option is not supported by the workstation, returns an error.\n\nKeyword arguments:\n\nrender_option -- Defines the rendering method used. (Foreground, Background Reactor, Burn)\n\ngenerate_proxies -- Set to True to render at proxy resolution. (Default: False)\n\ninclude_history -- Set to True to create History with the rendering. (Default:False)\n</code></pre>"},{"location":"api/classes/PyBatch/#replace_setup","title":"<code>replace_setup</code>","text":"<pre><code>replace_setup\n</code></pre> <p>replace_setup( (PyBatch)arg1, (PyBatchIteration)batch_iteration [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Replace the Batch Group setup with the specified Batch Iteration. Cannot be called on the Batch Group currently selected and displayed in the Batch view.\n</code></pre>"},{"location":"api/classes/PyBatch/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyBatch)arg1) -&gt; object :</p> <pre><code>Save the Batch Group to the location defined by PyDesktop.destination.\n</code></pre>"},{"location":"api/classes/PyBatch/#save_current_iteration","title":"<code>save_current_iteration</code>","text":"<pre><code>save_current_iteration\n</code></pre> <p>save_current_iteration( (PyBatch)arg1) -&gt; object :</p> <pre><code>Save the current Batch Group setup to the location defined by PyDesktop.destination.\n</code></pre>"},{"location":"api/classes/PyBatch/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyBatch)arg1, (str)setup_path) -&gt; bool :</p> <pre><code>Save the Batch Group setup to disk. Includes media paths for clip node object, but not the media files themselves.\n\nKeyword argument:\n\nsetup_path -- The filepath includes the filename. File extension must be .batch.\n</code></pre>"},{"location":"api/classes/PyBatch/#select_nodes","title":"<code>select_nodes</code>","text":"<pre><code>select_nodes\n</code></pre> <p>select_nodes( (PyBatch)arg1, (object)nodes) -&gt; bool :</p> <pre><code>Select nodes.\n\nKeyword argument:\n\nnodes -- A list of the names of Batch node objects.\n</code></pre>"},{"location":"api/classes/PyBatch/#set_viewport_layout","title":"<code>set_viewport_layout</code>","text":"<pre><code>set_viewport_layout\n</code></pre> <p>set_viewport_layout( (PyBatch)arg1, (object)num_views) -&gt; bool :</p> <pre><code>Set the viewport layout for Batch.\n\nKeyword argument:\n\nnum_views -- The layout used. (1-Up, 2-Up, 3-Up, 3-Up Split Top, 3-Up Split Left, 3-Up Split Right, 3-Up Split Bottom, 4-Up Split, 4-Up)\n</code></pre>"},{"location":"api/classes/PyBatchIteration/","title":"Class: PyBatchIteration","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyBatchIteration/#description","title":"Description","text":"<p>Class derived from PyArchiveEntry. This class represents a Batch Iteration.</p>"},{"location":"api/classes/PyBatchIteration/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>iteration_number</code> Return the iteration number of the Batch Iteration. <code>parent</code> The parent object of this object."},{"location":"api/classes/PyBatchIteration/#methods","title":"Methods","text":""},{"location":"api/classes/PyBatchIteration/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyBatchIteration/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyBatchIteration/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyBatchIteration/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyBatchIteration/#open_as_batch_group","title":"<code>open_as_batch_group</code>","text":"<pre><code>open_as_batch_group\n</code></pre> <p>open_as_batch_group( (PyBatchIteration)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Open a Batch Iteration as a new Batch Group, adding it to PyDesktop.batch_groups. Can only be called from a Library.\n</code></pre>"},{"location":"api/classes/PyBrowser/","title":"Class: PyBrowser","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyBrowser/#description","title":"Description","text":"<p>This class represents the file browser.</p>"},{"location":"api/classes/PyBrowser/#properties","title":"Properties","text":"Name Description <code>bit_depth</code> Return the bit depth. <code>colour_space</code> Return the colour space. <code>frame_ratio</code> Return the frame ratio. Returns None when resolution is set to Same As Source. <code>height</code> Return the height. Returns None when resolution is set to Same As Source. <code>resize_filter</code> Return the resize filter. <code>resize_mode</code> Return the resize mode. <code>resolution</code> Return the name of the resolution preset. <code>scaling_presets_value</code> Return the scaling presets value. Returns None when resolution is not set to Scaling Presets. <code>scan_mode</code> Return the scan mode. <code>selection</code> Get the selected files/directories. <code>sequence_mode</code> Return the sequence mode. <code>width</code> Return the width. Returns None when resolution is set to Same As Source."},{"location":"api/classes/PyBrowser/#methods","title":"Methods","text":""},{"location":"api/classes/PyBrowser/#show","title":"<code>show</code>","text":"<pre><code>show\n</code></pre> <p>show( (PyBrowser)arg1, (str)default_path [, (object)extension='' [, (bool)select_directory=False [, (bool)multi_selection=False [, (object)include_resolution=False [, (str)title='Load']]]]]) -&gt; None :</p> <pre><code>Show the file browser.Keyword arguments:\n\ndefault_path -- Set the path.\n\nextension -- Set the extension filter. Can be a single extension or a list of extensions.Leave empty to see all files.\n\nselect_directory -- Only show directories.\n\nmulti_selection -- Allow the user to select multiple files.\n\ninclude_resolution -- Display the resolution controls. Possible values are False, True, or \"Full\". The Full mode includes the new adaptive and scaling presets modes.\n\ntitle -- Set the window title.\n</code></pre>"},{"location":"api/classes/PyClip/","title":"Class: PyClip","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyClip/#description","title":"Description","text":"<p>CLass derived from PyArchiveEntry. This class represents a Clip.</p>"},{"location":"api/classes/PyClip/#properties","title":"Properties","text":"Name Description <code>archive_date</code> Return the Clip's last archive date. <code>archive_error</code> Return the Clip's last archive error. <code>attributes</code> The attributes of a python object. <code>audio_tracks</code> Return a list of the Clip's Audio Tracks. <code>bit_depth</code> Return the Clip's bit depth. <code>cached</code> Return the Clip's cache status. <code>colour_primaries</code> Deduce the Clip's 'colour primaries' export attribute. <code>creation_date</code> Return the Clip's creation date. <code>duration</code> Return the Clip's duration. <code>essence_uid</code> Return the Clip's essence uid. <code>frame_rate</code> Return the Clip's frame rate. <code>has_deliverables</code> Return the existence of deliverables on the Clip. <code>has_history</code> Return the existence of history inside the Clip. <code>height</code> Return the Clip's height. <code>markers</code> Return a list of the Clip's Markers. <code>matrix_coefficients</code> Deduce the Clip's 'matrix coefficients' export attribute. <code>original_source_uid</code> Return the Clip's original source UID. <code>parent</code> The parent object of this object. <code>proxy_resolution</code> Return the Clip's proxy resolution if it has proxies. <code>ratio</code> Return the Clip's frame ratio. <code>sample_rate</code> Return the Clip's audio sample rate. <code>scan_mode</code> Return the Clip's scan mode. <code>source_uid</code> Return the Clip's source uid. <code>start_frame</code> Return the Clip's start frame. <code>subtitles</code> Return a list of the Clip's Subtitles Tracks. <code>transfer_characteristics</code> Deduce the Clip's 'transfer characteristics' export attribute. <code>unlinked</code> Return the Clip's unlinked status. <code>versions</code> Return a list of the Clip's versions. <code>width</code> Return the Clip's width."},{"location":"api/classes/PyClip/#methods","title":"Methods","text":""},{"location":"api/classes/PyClip/#cache_media","title":"<code>cache_media</code>","text":"<pre><code>cache_media\n</code></pre> <p>cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Cache the Clip's linked media.\n\nKeyword argument:\n\nmode -- Determine the version to cache (currently selected or all versions). All Versions is only useful with to multi-version clips (Current, All Versions)\n</code></pre>"},{"location":"api/classes/PyClip/#change_dominance","title":"<code>change_dominance</code>","text":"<pre><code>change_dominance\n</code></pre> <p>change_dominance( (PyClip)arg1, (str)scan_mode) -&gt; None :</p> <pre><code>Change the Clip's dominance. Changes only the clip's metadata.\n\nKeyword argument:\n\nscan_mode -- Field dominance. (P, F1, F2)\n</code></pre>"},{"location":"api/classes/PyClip/#change_start_frame","title":"<code>change_start_frame</code>","text":"<pre><code>change_start_frame\n</code></pre> <p>change_start_frame( (PyClip)arg1, (int)start_frame [, (bool)use_segment_connections=True]) -&gt; None :</p> <pre><code>Modify the start frame of a source Clip.\n\nKeywords argument:\n\nstart_frame -- New start frame of the clip.\n\nuse_segment_connections -- Sync the start frame of connected segments.\n</code></pre>"},{"location":"api/classes/PyClip/#clear_cache_media","title":"<code>clear_cache_media</code>","text":"<pre><code>clear_cache_media\n</code></pre> <p>clear_cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Clear the Clip's media cache.\n\nKeyword argument:\n\nmode -- Determine the version's cache to clear. (Current, All Versions, All But Current)\n</code></pre>"},{"location":"api/classes/PyClip/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyClip/#clear_renders","title":"<code>clear_renders</code>","text":"<pre><code>clear_renders\n</code></pre> <p>clear_renders( (PyClip)arg1) -&gt; None :</p> <pre><code>Clear the Clip's Timeline FX renders.\n</code></pre>"},{"location":"api/classes/PyClip/#close_container","title":"<code>close_container</code>","text":"<pre><code>close_container\n</code></pre> <p>close_container( (PyClip)arg1) -&gt; None :</p> <pre><code>Close the container timeline if the Clip is inside a container.\n</code></pre>"},{"location":"api/classes/PyClip/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyClip/#create_marker","title":"<code>create_marker</code>","text":"<pre><code>create_marker\n</code></pre> <p>create_marker( (PyClip)arg1, (object)location) -&gt; object :</p> <pre><code>Add a Marker to the Clip.Keyword argument:\n\nlocation -- The frame where the marker gets created.\n</code></pre>"},{"location":"api/classes/PyClip/#cut","title":"<code>cut</code>","text":"<pre><code>cut\n</code></pre> <p>cut( (PyClip)arg1, (PyTime)cut_time) -&gt; None :</p> <pre><code>Cut all tracks of the Clip.\n</code></pre>"},{"location":"api/classes/PyClip/#flush_cache_media","title":"<code>flush_cache_media</code>","text":"<pre><code>flush_cache_media\n</code></pre> <p>flush_cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Clear the Clip's media cache.\n\nKeyword argument:\n\nmode -- Determine the version's cache to clear. (Current, All Versions, All But Current)(Deprecated: use 'clear_cache_media' instead.)\n</code></pre>"},{"location":"api/classes/PyClip/#flush_renders","title":"<code>flush_renders</code>","text":"<pre><code>flush_renders\n</code></pre> <p>flush_renders( (PyClip)arg1) -&gt; None :</p> <pre><code>Clear the Clip's Timeline FX renders.(Deprecated: use 'clear_renders' instead.)\n</code></pre>"},{"location":"api/classes/PyClip/#get_colour_space","title":"<code>get_colour_space</code>","text":"<pre><code>get_colour_space\n</code></pre> <p>get_colour_space( (PyClip)arg1 [, (PyTime)time=None]) -&gt; str :</p> <pre><code>Return the colour space at the requested time. Use current_time when no time is supplied.\n</code></pre>"},{"location":"api/classes/PyClip/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyClip)arg1 [, (str)key='' [, (PyTime)time=None]]) -&gt; object :</p> <pre><code>Return the metadata of the clip.\n\nKeywords argument:\n\nkey -- Key of the requested metadata. All metadata is returned when not specified.\n\ntime -- Must be a PyTime. If not specified, the current clip time is used.\n</code></pre>"},{"location":"api/classes/PyClip/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyClip/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyClip/#is_rendered","title":"<code>is_rendered</code>","text":"<pre><code>is_rendered\n</code></pre> <p>is_rendered( (PyClip)arg1 [, (bool)top_only=False [, (str)render_quality='Full Resolution']]) -&gt; bool :</p> <pre><code>Return if a Clip is rendered.\n\nThe following attributes can be defined: top_only, render_quality.\n</code></pre>"},{"location":"api/classes/PyClip/#open_as_sequence","title":"<code>open_as_sequence</code>","text":"<pre><code>open_as_sequence\n</code></pre> <p>open_as_sequence( (PyClip)arg1) -&gt; object :</p> <pre><code>Open the Clip as a Sequence. Mutates the PyClip object into a PySequence object.\n</code></pre>"},{"location":"api/classes/PyClip/#open_container","title":"<code>open_container</code>","text":"<pre><code>open_container\n</code></pre> <p>open_container( (PyClip)arg1) -&gt; bool :</p> <pre><code>Open the container timeline if the Clip is inside a container.\n</code></pre>"},{"location":"api/classes/PyClip/#reformat","title":"<code>reformat</code>","text":"<pre><code>reformat\n</code></pre> <p>reformat( (PyClip)arg1 [, (int)width=0 [, (int)height=0 [, (float)ratio=0.0 [, (int)bit_depth=0 [, (str)scan_mode='' [, (str)frame_rate='' [, (str)resize_mode='Letterbox']]]]]]]) -&gt; None :</p> <pre><code>Reformat the Clip to the specified format.\n\nKeywords arguments:\n\nwidth -- Integer between 24 and 16384.\n\nheight -- Integer between 24 and 16384.\n\nratio -- Frame aspect ratio. Float between 0.01 and 100.\n\nbit_depth -- Bit depth. (8, 10, 12, 16 or 32)\n\nscan_mode -- Scan mode of the sequence. (F1, F2, P)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps)\n\nresize_mode -- Resize mode. (Letterbox, Crop Edges, Fill, Centre)\n</code></pre>"},{"location":"api/classes/PyClip/#render","title":"<code>render</code>","text":"<pre><code>render\n</code></pre> <p>render( (PyClip)arg1 [, (str)render_mode='All' [, (str)render_option='Foreground' [, (str)render_quality='Full Resolution' [, (str)effect_type='' [, (str)effect_caching_mode='Current' [, (bool)include_handles=False]]]]]]) -&gt; bool :</p> <pre><code>Trigger a render of the Clip\n\nThe following attributes can be defined: render_mode, render_option, render_quality, effect_type, effect_caching_mode and include_handles.\n</code></pre>"},{"location":"api/classes/PyClip/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyClip)arg1) -&gt; bool :</p> <pre><code>Save the Clip to the defined save destination.\n</code></pre>"},{"location":"api/classes/PyClipNode/","title":"Class: PyClipNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyClipNode/#description","title":"Description","text":"<p>Class derived from PyNode. This class represents a Clip node.</p>"},{"location":"api/classes/PyClipNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>clip</code> The associated PyClip or PySequence of the clip node. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections. <code>version_uid</code> The clip node's list of available version unique IDs. <code>version_uids</code> The clip node's list of available version unique IDs."},{"location":"api/classes/PyClipNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyClipNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyClipNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyClipNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyClipNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyClipNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyClipNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClipNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyClipNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClipNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClipNode/#set_metadata_discarded","title":"<code>set_metadata_discarded</code>","text":"<pre><code>set_metadata_discarded\n</code></pre> <p>set_metadata_discarded( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (bool)discarded=True]]]) -&gt; None :</p> <pre><code>Discard key from the Node's metadata output.\n\nKeyword arguments:\n\nsocket_name -- The socket on which the discarded status of the metadata must be changed.\n\nkey -- Metadata key to be discarded or restored.\n\ndiscarded -- True to discard the key from the node metadata output, False to restore the key.\n</code></pre>"},{"location":"api/classes/PyClipNode/#set_metadata_key","title":"<code>set_metadata_key</code>","text":"<pre><code>set_metadata_key\n</code></pre> <p>set_metadata_key( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)name=None]]]) -&gt; None :</p> <pre><code>Rename a metadata key on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to rename the key. The default output is used when not specified.\n\nkey -- The current metadata key name to be renamed.\n\nname -- The new metadata key name. If None, the current key name will revert to its original value.\n</code></pre>"},{"location":"api/classes/PyClipNode/#set_metadata_value","title":"<code>set_metadata_value</code>","text":"<pre><code>set_metadata_value\n</code></pre> <p>set_metadata_value( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)value=None]]]) -&gt; None :</p> <pre><code>Set the metadata on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to set the metadata. The default output is used when not specified.\n\nkey -- Metadata key to be set or added.\n\nvalue -- Metadata value to be set or edited for the specified key. If None is specified, the current value will revert to the original value.\n</code></pre>"},{"location":"api/classes/PyClipNode/#set_version_uid","title":"<code>set_version_uid</code>","text":"<pre><code>set_version_uid\n</code></pre> <p>set_version_uid( (PyClipNode)arg1, (str)version_uid) -&gt; bool :</p> <pre><code>Set the clip node's current version unique ID.\n\nKeywords argument:\n\nversion_uid -- version unique ID.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/","title":"Class: PyClrMgmtNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyClrMgmtNode/#description","title":"Description","text":"<p>Object representing a Colour Mgmt node.</p>"},{"location":"api/classes/PyClrMgmtNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyClrMgmtNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyClrMgmtNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#get_context_variables","title":"<code>get_context_variables</code>","text":"<pre><code>get_context_variables\n</code></pre> <p>get_context_variables( (PyClrMgmtNode)arg1) -&gt; dict :</p> <pre><code>Get the context variables in a dictionary.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#import_transform","title":"<code>import_transform</code>","text":"<pre><code>import_transform\n</code></pre> <p>import_transform( (PyClrMgmtNode)arg1, (str)file_path) -&gt; None :</p> <pre><code>Import a transform from a file.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#reset_context_variables","title":"<code>reset_context_variables</code>","text":"<pre><code>reset_context_variables\n</code></pre> <p>reset_context_variables( (PyClrMgmtNode)arg1) -&gt; None :</p> <pre><code>Reset the context variables to their initial state from the ocio config.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyClrMgmtNode/#set_context_variable","title":"<code>set_context_variable</code>","text":"<pre><code>set_context_variable\n</code></pre> <p>set_context_variable( (PyClrMgmtNode)arg1, (str)name, (str)value) -&gt; None :</p> <pre><code>Set the value for the specified context variable.\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/","title":"Class: PyCoCameraAnalysis","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyCoNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyCoCameraAnalysis/#description","title":"Description","text":"<p>Class derived from PyCoNode. This class represents the camera analysis node in the Action schematic.</p>"},{"location":"api/classes/PyCoCameraAnalysis/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Action node."},{"location":"api/classes/PyCoCameraAnalysis/#methods","title":"Methods","text":""},{"location":"api/classes/PyCoCameraAnalysis/#add_reference","title":"<code>add_reference</code>","text":"<pre><code>add_reference\n</code></pre> <p>add_reference( (PyCoNode)arg1, (object)frame) -&gt; bool :</p> <pre><code>Add a Motion Warp map's reference frame at specified index.\n\nKeyword argument\n\nframe -- The reference frame's index. An integer.\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#analyserange","title":"<code>analyseRange</code>","text":"<pre><code>analyseRange\n</code></pre> <p>analyseRange( (PyCoCameraAnalysis)arg1, (object)arg2, (object)start) -&gt; bool :</p> <pre><code>Run the analysis for the given frame range using the first frame as a reference if none has been already set.\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#assign_media","title":"<code>assign_media</code>","text":"<pre><code>assign_media\n</code></pre> <p>assign_media( (PyCoNode)arg1, (object)media_name) -&gt; bool :</p> <pre><code>Assign a media layer to the node.\n\nKeyword argument\n\nmedia_name -- The index of the media layer from Actions' *media_layers*; or the name of the media layer.\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyCoNode)arg1, (object)arg2, (object)start) -&gt; bool :</p> <pre><code>Cache the selected Map Analysis over the specified range.\n\nKeyword arguments\n\nstart -- The first frame of the range. An integer.\n\nend -- The last frame of the range. An integer.\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#children","title":"<code>children</code>","text":"<pre><code>children\n</code></pre> <p>children( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the children of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#parents","title":"<code>parents</code>","text":"<pre><code>parents\n</code></pre> <p>parents( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the parents of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyCoCameraAnalysis/#resetanalysis","title":"<code>resetAnalysis</code>","text":"<pre><code>resetAnalysis\n</code></pre> <p>resetAnalysis( (PyCoCameraAnalysis)arg1) -&gt; bool :</p> <pre><code>Reset the current analysis.\n</code></pre>"},{"location":"api/classes/PyCoCompass/","title":"Class: PyCoCompass","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyCoNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyCoCompass/#description","title":"Description","text":"<p>Class derived from PyCoNode. This class represents the compass node in the Action schematic.</p>"},{"location":"api/classes/PyCoCompass/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>nodes</code> Return a list of PyCoNode objects enclosed by the Compass node. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Action node."},{"location":"api/classes/PyCoCompass/#methods","title":"Methods","text":""},{"location":"api/classes/PyCoCompass/#add_reference","title":"<code>add_reference</code>","text":"<pre><code>add_reference\n</code></pre> <p>add_reference( (PyCoNode)arg1, (object)frame) -&gt; bool :</p> <pre><code>Add a Motion Warp map's reference frame at specified index.\n\nKeyword argument\n\nframe -- The reference frame's index. An integer.\n</code></pre>"},{"location":"api/classes/PyCoCompass/#assign_media","title":"<code>assign_media</code>","text":"<pre><code>assign_media\n</code></pre> <p>assign_media( (PyCoNode)arg1, (object)media_name) -&gt; bool :</p> <pre><code>Assign a media layer to the node.\n\nKeyword argument\n\nmedia_name -- The index of the media layer from Actions' *media_layers*; or the name of the media layer.\n</code></pre>"},{"location":"api/classes/PyCoCompass/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyCoNode)arg1, (object)arg2, (object)start) -&gt; bool :</p> <pre><code>Cache the selected Map Analysis over the specified range.\n\nKeyword arguments\n\nstart -- The first frame of the range. An integer.\n\nend -- The last frame of the range. An integer.\n</code></pre>"},{"location":"api/classes/PyCoCompass/#children","title":"<code>children</code>","text":"<pre><code>children\n</code></pre> <p>children( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the children of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyCoCompass/#parents","title":"<code>parents</code>","text":"<pre><code>parents\n</code></pre> <p>parents( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the parents of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyCoNode/","title":"Class: PyCoNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyCoNode/#description","title":"Description","text":"<p>Class derived from PyFlameObject. This class represents an Action node in the Action schematic.</p>"},{"location":"api/classes/PyCoNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Action node."},{"location":"api/classes/PyCoNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyCoNode/#add_reference","title":"<code>add_reference</code>","text":"<pre><code>add_reference\n</code></pre> <p>add_reference( (PyCoNode)arg1, (object)frame) -&gt; bool :</p> <pre><code>Add a Motion Warp map's reference frame at specified index.\n\nKeyword argument\n\nframe -- The reference frame's index. An integer.\n</code></pre>"},{"location":"api/classes/PyCoNode/#assign_media","title":"<code>assign_media</code>","text":"<pre><code>assign_media\n</code></pre> <p>assign_media( (PyCoNode)arg1, (object)media_name) -&gt; bool :</p> <pre><code>Assign a media layer to the node.\n\nKeyword argument\n\nmedia_name -- The index of the media layer from Actions' *media_layers*; or the name of the media layer.\n</code></pre>"},{"location":"api/classes/PyCoNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyCoNode)arg1, (object)arg2, (object)start) -&gt; bool :</p> <pre><code>Cache the selected Map Analysis over the specified range.\n\nKeyword arguments\n\nstart -- The first frame of the range. An integer.\n\nend -- The last frame of the range. An integer.\n</code></pre>"},{"location":"api/classes/PyCoNode/#children","title":"<code>children</code>","text":"<pre><code>children\n</code></pre> <p>children( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the children of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyCoNode/#parents","title":"<code>parents</code>","text":"<pre><code>parents\n</code></pre> <p>parents( (PyCoNode)arg1 [, (str)link_type='Default']) -&gt; list :</p> <pre><code>Return a list of PyCoNode objects that are the parents of the action node.\n\nKeyword argument:\n\nlink_type -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/","title":"Class: PyColourMgtTimelineFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTimelineFX, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyColourMgtTimelineFX/#description","title":"Description","text":"<p>Object representing a Colour Mgmt Timeline FX.</p>"},{"location":"api/classes/PyColourMgtTimelineFX/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyColourMgtTimelineFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyColourMgtTimelineFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#get_context_variables","title":"<code>get_context_variables</code>","text":"<pre><code>get_context_variables\n</code></pre> <p>get_context_variables( (PyColourMgtTimelineFX)arg1) -&gt; dict :</p> <pre><code>Get the context variables in a dictionary.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#import_transform","title":"<code>import_transform</code>","text":"<pre><code>import_transform\n</code></pre> <p>import_transform( (PyColourMgtTimelineFX)arg1, (str)file_path) -&gt; None :</p> <pre><code>Import a transform from a file.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#reset_context_variables","title":"<code>reset_context_variables</code>","text":"<pre><code>reset_context_variables\n</code></pre> <p>reset_context_variables( (PyColourMgtTimelineFX)arg1) -&gt; None :</p> <pre><code>Reset the context variables to their initial state from the ocio config.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#set_context_variable","title":"<code>set_context_variable</code>","text":"<pre><code>set_context_variable\n</code></pre> <p>set_context_variable( (PyColourMgtTimelineFX)arg1, (str)name, (str)value) -&gt; None :</p> <pre><code>Set the value for the specified context variable.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyColourMgtTimelineFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyCompassNode/","title":"Class: PyCompassNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyCompassNode/#description","title":"Description","text":"<p>Class derived from PyNode. This class represents a Compass node.</p>"},{"location":"api/classes/PyCompassNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>nodes</code> Return a list of PyNode objects enclosed by the Compass node. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyCompassNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyCompassNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyCompassNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyDesktop/","title":"Class: PyDesktop","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyDesktop/#description","title":"Description","text":"<p>Class derived from PyArchiveEntry. This class represents a Desktop.</p>"},{"location":"api/classes/PyDesktop/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>batch_groups</code> Return a list of Batch Group objects that are immediate children of the current object. <code>children</code> Return a list of the immediate children of the current object. <code>parent</code> The parent object of this object. <code>reel_groups</code> Return a list of Reel Group objects that are immediate children of the current object."},{"location":"api/classes/PyDesktop/#methods","title":"Methods","text":""},{"location":"api/classes/PyDesktop/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyDesktop)arg1) -&gt; bool :</p> <pre><code>Clear the Desktop.\n</code></pre>"},{"location":"api/classes/PyDesktop/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyDesktop/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyDesktop/#create_batch_group","title":"<code>create_batch_group</code>","text":"<pre><code>create_batch_group\n</code></pre> <p>create_batch_group( (PyDesktop)arg1, (str)name [, (object)nb_reels=None [, (object)nb_shelf_reels=None [, (list)reels=[] [, (list)shelf_reels=[] [, (int)start_frame=1 [, (object)duration=None]]]]]]) -&gt; object :</p> <pre><code>Create a new Batch Group object in the Desktop catalogue.\n\nKeyword arguments:\n\nname -- Name of the Batch Group.\n\nnb_reels -- Number of reels created. *reels* overrides *nb_reels*.\n\nnb_shelf_reels -- Number of shelf reels. The first shelf reel created is named Batch Renders. *shelf_reels* ovverides *nb_shelf_reels*.\n\nreels -- A list of reel names. Overrides *nb_reels*.\n\nshelf_reels -- A list of shelf reel names. Overrides *nb_shelf_reels*.\n\nstart_frame -- The Batch Group's start frame. No timecodes, only a frame value.\n\nduration -- The number of frames. Sets the Duration field in the Batch UI. Will be set to the first clip duration when not specified.\n</code></pre>"},{"location":"api/classes/PyDesktop/#create_reel_group","title":"<code>create_reel_group</code>","text":"<pre><code>create_reel_group\n</code></pre> <p>create_reel_group( (PyDesktop)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Reel Group object in the Desktop catalogue.\n</code></pre>"},{"location":"api/classes/PyDesktop/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyDesktop/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyDesktop/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyDesktop)arg1) -&gt; bool :</p> <pre><code>Save the Desktop to the location defined by the *destination* attribute.\n</code></pre>"},{"location":"api/classes/PyExporter/","title":"Class: PyExporter","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyExporter/#description","title":"Description","text":"<p>Object holding export settings.</p>"},{"location":"api/classes/PyExporter/#properties","title":"Properties","text":"Name Description <code>Audio</code> <code>Autodesk</code> <code>Distribution_Package</code> <code>Flow_Production_Tracking</code> <code>Image_Sequence</code> <code>Movie</code> <code>Project</code> <code>Sequence_Publish</code> <code>Shared</code> <code>Shotgun</code> <code>User</code> <code>export_all_subtitles</code> Set export option 'All Subtitles Tracks'. <code>export_between_marks</code> Set export option 'Export between marks'. <code>export_subtitles_as_files</code> Set subtitles export option 'Export As Files. <code>foreground</code> Set export option 'Foreground export'. <code>include_subtitles</code> Set export option 'Include Subtitles'. <code>keep_timeline_fx_renders</code> Set export option 'Keep Timeline FX Renders'. <code>use_top_video_track</code> Set export option 'Use top video track'. <code>warn_on_mixed_colour_space</code> Set export option 'Warn on mixed colour space'. <code>warn_on_no_media</code> Set export option 'Warn on no media'. <code>warn_on_pending_render</code> Set export option 'Warn on pending render'. <code>warn_on_reimport_unsupported</code> Set export option 'Warn on reimport unsupported'. <code>warn_on_unlinked</code> Set export option 'Warn on unlinked'. <code>warn_on_unrendered</code> Set export option 'Warn on unrendered'."},{"location":"api/classes/PyExporter/#methods","title":"Methods","text":""},{"location":"api/classes/PyExporter/#backgroundjobsettings","title":"<code>BackgroundJobSettings</code>","text":"<pre><code>BackgroundJobSettings\n</code></pre> <p>Object holding background export job settings. These settings refer to the Backburner job, server and manager.</p>"},{"location":"api/classes/PyExporter/#presettype","title":"<code>PresetType</code>","text":"<pre><code>PresetType\n</code></pre>"},{"location":"api/classes/PyExporter/#presetvisibility","title":"<code>PresetVisibility</code>","text":"<pre><code>PresetVisibility\n</code></pre>"},{"location":"api/classes/PyExporter/#export","title":"<code>export</code>","text":"<pre><code>export\n</code></pre> <p>export( (PyExporter)arg1, (object)sources, (str)preset_path, (str)output_directory [, (PyExporter.BackgroundJobSettings)background_job_settings=None [, (object)hooks=None [, (object)hooks_user_data=None]]]) -&gt; None :</p> <pre><code>Perform export.\n\nKeyword arguments:\n\nsources -- Flame clip object, a Flame container object or a list of either first. If a container is passed, a multi-export will be done and structure will be respected as much as possible.\n\npreset_path -- Absolute path to the export preset to use.\n\noutput_directory -- Absolute path to the output directory root.\n\nbackground_job_settings -- Settings of background job(s) created if any.\n\nhooks -- Export python hooks override. If passed, regular export python hooks implemented in exportHooks.py will be bypassed for this export and methods in the passed object with matching name will be called.\n\n    Instance of object passed should implement the following signature:\n\n\n\n        class PythonHookOverride(object):\n\n            def preExport(self, info, userData, *args, **kwargs)\n\n                pass\n\n\n\n            def postExport(self, info, userData, *args, **kwargs):\n\n                pass\n\n\n\n            def preExportSequence(self, info, userData, *args, **kwargs):\n\n                pass\n\n\n\n            def postExportSequence(self, info, userData, *args, **kwargs):\n\n                pass\n\n\n\n            def preExportAsset(self, info, userData, *args, **kwargs):\n\n                pass\n\n\n\n            def postExportAsset(self, info, userData, *args, **kwargs):\n\n                pass\n\n\n\n            def exportOverwriteFile(self, path, *args, **kwargs):\n\n                return \"ask\" # or \"overwrite\"\n\n\n\nhooks_user_data -- User data object passed to the export python hooks. This object can be modified by the PythonHookOverride methods but cannot be re-assigned\n</code></pre>"},{"location":"api/classes/PyExporter/#get_presets_base_dir","title":"<code>get_presets_base_dir</code>","text":"<pre><code>get_presets_base_dir\n</code></pre> <p>get_presets_base_dir( (PyExporter.PresetVisibility)preset_visibility) -&gt; str :</p> <pre><code>Get a presets base directory.\n</code></pre>"},{"location":"api/classes/PyExporter/#get_presets_dir","title":"<code>get_presets_dir</code>","text":"<pre><code>get_presets_dir\n</code></pre> <p>get_presets_dir( (PyExporter.PresetVisibility)preset_visibility, (PyExporter.PresetType)preset_type) -&gt; str :</p> <pre><code>Get a presets directory.\n</code></pre>"},{"location":"api/classes/PyFlameObject/","title":"Class: PyFlameObject","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyFlameObject/#description","title":"Description","text":"<p>The basic type of all accessible Flame objects from the python API.</p>"},{"location":"api/classes/PyFlameObject/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object."},{"location":"api/classes/PyFolder/","title":"Class: PyFolder","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyFolder/#description","title":"Description","text":"<p>Class derived from PyArchiveEntry. This class represents a Folder.</p>"},{"location":"api/classes/PyFolder/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>batch_groups</code> Return a list of Batch Group objects that are immediate children of the current object. <code>batch_iterations</code> Return a list of Batch Iteration objects that are immediate children of the current object. <code>children</code> Return a list of the immediate children of the current object. <code>clips</code> Return a list of Clip objects that are immediate children of the current object. <code>desktops</code> Return a list Desktop objects that are immediate children of the current object. <code>folders</code> Return a list of the Folder objects that are immediate children of the current object. <code>parent</code> The parent object of this object. <code>reel_groups</code> Return a list of Reel Group objects that are immediate children of the current object. <code>reels</code> Return a list of Reel objects that are immediate children of the current object. <code>sequences</code> Return a list of Sequence objects that are immediate children of the current object."},{"location":"api/classes/PyFolder/#methods","title":"Methods","text":""},{"location":"api/classes/PyFolder/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyFolder)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Clear the contents of the Folder object.\n</code></pre>"},{"location":"api/classes/PyFolder/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyFolder/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyFolder/#create_folder","title":"<code>create_folder</code>","text":"<pre><code>create_folder\n</code></pre> <p>create_folder( (PyFolder)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Folder object inside the Folder.\n</code></pre>"},{"location":"api/classes/PyFolder/#create_reel","title":"<code>create_reel</code>","text":"<pre><code>create_reel\n</code></pre> <p>create_reel( (PyFolder)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Reel object inside the Folder.\n</code></pre>"},{"location":"api/classes/PyFolder/#create_reel_group","title":"<code>create_reel_group</code>","text":"<pre><code>create_reel_group\n</code></pre> <p>create_reel_group( (PyFolder)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Reel Group object inside the Folder.\n</code></pre>"},{"location":"api/classes/PyFolder/#create_sequence","title":"<code>create_sequence</code>","text":"<pre><code>create_sequence\n</code></pre> <p>create_sequence( (PyFolder)arg1 [, (str)name='Untitled Sequence' [, (int)video_tracks=1 [, (bool)video_stereo=False [, (object)width=None [, (object)height=None [, (object)ratio=None [, (object)bit_depth=None [, (object)scan_mode=None [, (object)frame_rate=None [, (object)start_at=00:00:00+00 [, (object)duration=00:00:00+01 [, (int)audio_tracks=1 [, (bool)audio_stereo=True]]]]]]]]]]]]]) -&gt; object :</p> <pre><code>Create a Sequence in a PyReel, PyLibrary, PyFolder.\n\nKeywords arguments:\n\nvideo_tracks -- Number of video tracks. Integer between 1 and 8.\n\nvideo_stereo -- Stereoscopy. False for mono, True for stereo.\n\nwidth -- Integer between 24 and 16384.\n\nheight -- Integer between 24 and 16384.\n\nratio -- Frame aspect ratio. Float between 0.01 and 100.\n\nscan_mode -- Scan mode of the sequence. (F1, F2, P)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps)\n\nstart_at -- Start timecode. The timecode format must be of the format specified by *frame_rate*.\n\nduration -- Can be an end timecode or an integer. If an end timecode, format must be of the format specified by *frame_rate*. If an integer, it represents a number of frames.\n\naudio_tracks -- Number of audio tracks. (0, 1, 2, 4, 8, 12, 16)\n\naudio_stereo -- Stereophony, apply to all *audio_tracks*. False for mono tracks, True for stereo.\n</code></pre>"},{"location":"api/classes/PyFolder/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyFolder/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/","title":"Class: PyGMaskTracerNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyActionFamilyNode, PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyGMaskTracerNode/#description","title":"Description","text":"<p>Class derived from PyActionFamilyNode. Represents a GMask Tracer node object.</p>"},{"location":"api/classes/PyGMaskTracerNode/#properties","title":"Properties","text":"Name Description <code>all_tabs</code> Return a list of the object tabs. <code>attributes</code> The attributes of a python object. <code>cursor_position</code> Return a tuple that provides the cursor position in the Action/Image/GMaskTracer schematic. <code>input_sockets</code> Return a list of the node input sockets names. <code>left_tabs</code> Return a list of the object left tabs. <code>media_layers</code> Return a list of the Media layers of the Action/Image/GMaskTracer node. <code>node_types</code> Return a list of the node types available in the Action/Image/GMaskTracer schematic. <code>nodes</code> Return a list of Action/Image/GMaskTracer nodes used in the the Action/Image/GMaskTracer schematic. <code>output_sockets</code> Return a list of the node output sockets names. <code>output_types</code> Return a list of the output types available to the GMask Tracer node. <code>parent</code> The parent object of this object. <code>right_tabs</code> Return a list of the object right tabs. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyGMaskTracerNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyGMaskTracerNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#clear_schematic","title":"<code>clear_schematic</code>","text":"<pre><code>clear_schematic\n</code></pre> <p>clear_schematic( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clear the Action/Image/GMaskTracer schematic of all nodes.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#connect_nodes","title":"<code>connect_nodes</code>","text":"<pre><code>connect_nodes\n</code></pre> <p>connect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Connect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#create_node","title":"<code>create_node</code>","text":"<pre><code>create_node\n</code></pre> <p>create_node( (PyActionFamilyNode)arg1, (str)node_type [, (str)file_path='' [, (bool)is_udim=False [, (int)tile_resolution=0 [, (str)input_colour_space='']]]]) -&gt; object :</p> <pre><code>Add an Action/Image/GMaskTracer object node to the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\nfile_path -- Required by nodes that load an asset, such as Matchbox.\n\ninput_colour_space -- Optional for nodes that load external media, such as IBL.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#disable_output","title":"<code>disable_output</code>","text":"<pre><code>disable_output\n</code></pre> <p>disable_output( (PyActionFamilyNode)arg1, (str)output_type) -&gt; bool :</p> <pre><code>Disable the render output_type for the GMask Tracer node.\n\nKeyword argument:\n\noutput_type -- The output to enable. (Comp, Matte, 3D Motion, Albedo, AO, Background, Emissive, GMask, Lens Flare, Motion Vectors, Normals, Object ID, Occluder, Position, Projectors Matte, Reflection, Roughness, Shadow, Specular, UV, Z-Depth HQ, Z-Depth)\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#disconnect_nodes","title":"<code>disconnect_nodes</code>","text":"<pre><code>disconnect_nodes\n</code></pre> <p>disconnect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Disconnect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#enable_output","title":"<code>enable_output</code>","text":"<pre><code>enable_output\n</code></pre> <p>enable_output( (PyActionFamilyNode)arg1, (str)output_type) -&gt; bool :</p> <pre><code>Enable the render output_type for the GMask Tracer node.\n\nKeyword argument:\n\noutput_type -- The output to enable. (Comp, Matte, 3D Motion, Albedo, AO, Background, Emissive, GMask, Lens Flare, Motion Vectors, Normals, Object ID, Occluder, Position, Projectoars Matte, Reflection, Roughness, Shadow, Specular, UV, Z-Depth HQ, Z-Depth)\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#encompass_nodes","title":"<code>encompass_nodes</code>","text":"<pre><code>encompass_nodes\n</code></pre> <p>encompass_nodes( (PyActionFamilyNode)arg1, (list)node_list) -&gt; object :</p> <pre><code>Create a compass including the node list given as argument\n\nKeyword argument:\n\nnode_list -- a list of nodes (either string or node objects)\n\noutput_type -- the created compass node\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#export_fbx","title":"<code>export_fbx</code>","text":"<pre><code>export_fbx\n</code></pre> <p>export_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)only_selected_nodes=False [, (float)pixel_to_units=0.10000000149011612 [, (str)frame_rate='23.976 fps' [, (bool)bake_animation=False [, (bool)export_axes=True [, (bool)export_point_locators=False [, (bool)combine_material=True [, (bool)duplicate_material=False]]]]]]]]) -&gt; bool :</p> <pre><code>Export GMask Tracer nodes to an FBX file.\n\nKeyword argument:\n\nfile_path -- Path to the output FBX file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#get_node","title":"<code>get_node</code>","text":"<pre><code>get_node\n</code></pre> <p>get_node( (PyActionFamilyNode)arg1, (str)node_name) -&gt; object :</p> <pre><code>Get a node by node name. Doesn't select it in the UI.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#import_abc","title":"<code>import_abc</code>","text":"<pre><code>import_abc\n</code></pre> <p>import_abc( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (str)frame_rate='23.976 fps' [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)consolidate_geometry=True [, (bool)create_object_group=False]]]]]]]]]]) -&gt; list :</p> <pre><code>Import an Alembic (ABC) file into the GMask Tracer schematic using the GMask Tracer Objects mode.\n\nKeyword argument:\n\nfile_path -- Path to the ABC file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#import_fbx","title":"<code>import_fbx</code>","text":"<pre><code>import_fbx\n</code></pre> <p>import_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (bool)keep_frame_rate=True [, (bool)bake_animation=False [, (bool)object_properties=True [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)create_media=True [, (bool)is_udim=False [, (bool)relink_material=True [, (str)input_colour_space='']]]]]]]]]]]]]]) -&gt; list :</p> <pre><code>Import an FBX file into the GMask Tracer schematic using the GMask Tracer Objects mode.\n\nKeyword argument:\n\nfile_path -- Path to the FBX file. Mandatory.\n\ninput_colour_space -- Colour space name used as input for textures. Optional.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#import_psd","title":"<code>import_psd</code>","text":"<pre><code>import_psd\n</code></pre> <p>import_psd( (PyActionFamilyNode)arg1, (str)file_path [, (str)input_colour_space='']) -&gt; list :</p> <pre><code>Import a PSD file into the GMask Tracer schematic.\n\nKeyword arguments:\n\nfile_path -- Path to the PSD file. Mandatory.\n\ninput_colour_space -- The colour space used as input. Optional.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#organize","title":"<code>organize</code>","text":"<pre><code>organize\n</code></pre> <p>organize( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clean up the Action/Image/GMaskTracer schematic.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#read_abc","title":"<code>read_abc</code>","text":"<pre><code>read_abc\n</code></pre> <p>read_abc( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (str)frame_rate='23.976 fps' [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)consolidate_geometry=True [, (bool)create_object_group=False]]]]]]]]]]) -&gt; object :</p> <pre><code>Import an Alembic (ABC) file into the GMask Tracer schematic using the Read File mode.\n\nKeyword argument:\n\nfile_path -- Path to the ABC file. Mandatory.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#read_fbx","title":"<code>read_fbx</code>","text":"<pre><code>read_fbx\n</code></pre> <p>read_fbx( (PyActionFamilyNode)arg1, (str)file_path [, (bool)lights=True [, (bool)cameras=True [, (bool)models=True [, (bool)normals=True [, (bool)mesh_animations=True [, (bool)keep_frame_rate=True [, (bool)bake_animation=False [, (bool)object_properties=True [, (bool)auto_fit=False [, (float)unit_to_pixels=10.0 [, (bool)is_udim=False [, (bool)relink_material=True [, (str)input_colour_space='']]]]]]]]]]]]]) -&gt; object :</p> <pre><code>Import an FBX file into the GMask Tracer schematic using the Read File mode.\n\nKeyword argument:\n\nfile_path -- Path to the FBX file. Mandatory.\n\ninput_colour_space -- Colour space name used as input for textures. Optional.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyGMaskTracerNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRNode/","title":"Class: PyHDRNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyHDRNode/#description","title":"Description","text":"<p>Object representing a HDR node.</p>"},{"location":"api/classes/PyHDRNode/#properties","title":"Properties","text":"Name Description <code>analysis_status</code> Return the current state of the HDR analysis. <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>mastering_display_ids</code> List of available Mastering Display Ids. <code>mastering_display_info</code> Dictionary containing Mastering Display information. Returned object is a copy. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections. <code>target_display_ids</code> List of available Target Display Ids. <code>target_display_info</code> Dictionary containing Target Display information. Returned object is a copy."},{"location":"api/classes/PyHDRNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyHDRNode/#analyze","title":"<code>analyze</code>","text":"<pre><code>analyze\n</code></pre> <p>analyze( (PyHDRNode)arg1 [, (str)analyze_mode='Current Shot']) -&gt; None :</p> <pre><code>Perform HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#export_dolbyvision_xml","title":"<code>export_DolbyVision_xml</code>","text":"<pre><code>export_DolbyVision_xml\n</code></pre> <p>export_DolbyVision_xml( (PyHDRNode)arg1, (str)file_name [, (str)comment='']) -&gt; None :</p> <pre><code>Export the current HDR to a Dolby Vision XML file.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#has_trim","title":"<code>has_trim</code>","text":"<pre><code>has_trim\n</code></pre> <p>has_trim( (PyHDRNode)arg1, (int)target_display_id) -&gt; bool :</p> <pre><code>Returns True if the given Target Display ID has trims.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#import_dolbyvision_xml","title":"<code>import_DolbyVision_xml</code>","text":"<pre><code>import_DolbyVision_xml\n</code></pre> <p>import_DolbyVision_xml( (PyHDRNode)arg1, (str)file_name [, (str)mode='Include Frame Based Transitions Trims' [, (int)shot_idx=0]]) -&gt; None :</p> <pre><code>Import the current HDR from a Dolby Vision XML file.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#interpolate_trims","title":"<code>interpolate_trims</code>","text":"<pre><code>interpolate_trims\n</code></pre> <p>interpolate_trims( (PyHDRNode)arg1) -&gt; None :</p> <pre><code>Interpolate the current HDR trims.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#keep_analysis","title":"<code>keep_analysis</code>","text":"<pre><code>keep_analysis\n</code></pre> <p>keep_analysis( (PyHDRNode)arg1) -&gt; None :</p> <pre><code>Remove the dirty flag from the HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#l2_from_l8","title":"<code>l2_from_l8</code>","text":"<pre><code>l2_from_l8\n</code></pre> <p>l2_from_l8( (PyHDRNode)arg1) -&gt; object :</p> <pre><code>Dictionary containing the L2 values based on L8 values. Not valid in Dolby Vision 2.9.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#reset_analysis","title":"<code>reset_analysis</code>","text":"<pre><code>reset_analysis\n</code></pre> <p>reset_analysis( (PyHDRNode)arg1) -&gt; None :</p> <pre><code>Reset the current HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#reset_trims","title":"<code>reset_trims</code>","text":"<pre><code>reset_trims\n</code></pre> <p>reset_trims( (PyHDRNode)arg1) -&gt; None :</p> <pre><code>Reset the current HDR trims.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/","title":"Class: PyHDRTimelineFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTimelineFX, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyHDRTimelineFX/#description","title":"Description","text":"<p>Object representing a HDR Timeline FX.</p>"},{"location":"api/classes/PyHDRTimelineFX/#properties","title":"Properties","text":"Name Description <code>analysis_status</code> Return the current state of the HDR analysis. <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>mastering_display_ids</code> List of available Mastering Display Ids. <code>mastering_display_info</code> Dictionary containing Mastering Display information. Returned object is a copy. <code>parent</code> The parent object of this object. <code>target_display_ids</code> List of available Target Display Ids. <code>target_display_info</code> Dictionary containing Target Display information. Returned object is a copy. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyHDRTimelineFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyHDRTimelineFX/#analyze","title":"<code>analyze</code>","text":"<pre><code>analyze\n</code></pre> <p>analyze( (PyHDRTimelineFX)arg1 [, (str)analyze_mode='Current Shot']) -&gt; None :</p> <pre><code>Perform HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#export_dolbyvision_xml","title":"<code>export_DolbyVision_xml</code>","text":"<pre><code>export_DolbyVision_xml\n</code></pre> <p>export_DolbyVision_xml( (PyHDRTimelineFX)arg1, (str)file_name [, (bool)shot_only=False [, (str)comment='']]) -&gt; None :</p> <pre><code>Export the current HDR to a Dolby Vision XML file.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#has_trim","title":"<code>has_trim</code>","text":"<pre><code>has_trim\n</code></pre> <p>has_trim( (PyHDRTimelineFX)arg1, (int)target_display_id) -&gt; bool :</p> <pre><code>Returns True if the given Target Display ID has trims.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#import_dolbyvision_xml","title":"<code>import_DolbyVision_xml</code>","text":"<pre><code>import_DolbyVision_xml\n</code></pre> <p>import_DolbyVision_xml( (PyHDRTimelineFX)arg1, (str)file_name [, (str)mode='Include Frame Based Transitions Trims' [, (int)shot_idx=0]]) -&gt; None :</p> <pre><code>Import the current HDR from a Dolby Vision XML file.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#interpolate_trims","title":"<code>interpolate_trims</code>","text":"<pre><code>interpolate_trims\n</code></pre> <p>interpolate_trims( (PyHDRTimelineFX)arg1, (str)arg2) -&gt; None :</p> <pre><code>Interpolate the current HDR trims.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#keep_analysis","title":"<code>keep_analysis</code>","text":"<pre><code>keep_analysis\n</code></pre> <p>keep_analysis( (PyHDRTimelineFX)arg1) -&gt; None :</p> <pre><code>Remove the dirty flag from the HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#l2_from_l8","title":"<code>l2_from_l8</code>","text":"<pre><code>l2_from_l8\n</code></pre> <p>l2_from_l8( (PyHDRTimelineFX)arg1) -&gt; object :</p> <pre><code>Dictionary containing the L2 values based on L8 values. Not valid in Dolby Vision 2.9.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#reset_analysis","title":"<code>reset_analysis</code>","text":"<pre><code>reset_analysis\n</code></pre> <p>reset_analysis( (PyHDRTimelineFX)arg1) -&gt; None :</p> <pre><code>Reset the current HDR analysis.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#reset_trims","title":"<code>reset_trims</code>","text":"<pre><code>reset_trims\n</code></pre> <p>reset_trims( (PyHDRTimelineFX)arg1) -&gt; None :</p> <pre><code>Reset the current HDR trims.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyHDRTimelineFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyImageNode/","title":"Class: PyImageNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyActionFamilyNode, PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyImageNode/#description","title":"Description","text":"<p>Class derived from PyActionFamilyNode. Represents an Image node object.</p>"},{"location":"api/classes/PyImageNode/#properties","title":"Properties","text":"Name Description <code>all_tabs</code> Return a list of the object tabs. <code>attributes</code> The attributes of a python object. <code>cursor_position</code> Return a tuple that provides the cursor position in the Action/Image/GMaskTracer schematic. <code>input_sockets</code> Return a list of the node input sockets names. <code>left_tabs</code> Return a list of the object left tabs. <code>media_layers</code> Return a list of the Media layers of the Action/Image/GMaskTracer node. <code>media_nodes</code> Return a list of the Media nodes attached to the Image node. <code>node_types</code> Return a list of the node types available in the Action/Image/GMaskTracer schematic. <code>nodes</code> Return a list of Action/Image/GMaskTracer nodes used in the the Action/Image/GMaskTracer schematic. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>right_tabs</code> Return a list of the object right tabs. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyImageNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyImageNode/#add_media","title":"<code>add_media</code>","text":"<pre><code>add_media\n</code></pre> <p>add_media( (PyActionFamilyNode)arg1) -&gt; object :</p> <pre><code>Add a Media layer to the Batch Image node.\n</code></pre>"},{"location":"api/classes/PyImageNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyImageNode/#clear_schematic","title":"<code>clear_schematic</code>","text":"<pre><code>clear_schematic\n</code></pre> <p>clear_schematic( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clear the Action/Image/GMaskTracer schematic of all nodes.\n</code></pre>"},{"location":"api/classes/PyImageNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyImageNode/#connect_nodes","title":"<code>connect_nodes</code>","text":"<pre><code>connect_nodes\n</code></pre> <p>connect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Connect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyImageNode/#create_node","title":"<code>create_node</code>","text":"<pre><code>create_node\n</code></pre> <p>create_node( (PyActionFamilyNode)arg1, (str)node_type [, (str)file_path='' [, (bool)is_udim=False [, (int)tile_resolution=0 [, (str)input_colour_space='']]]]) -&gt; object :</p> <pre><code>Add an Action/Image/GMaskTracer object node to the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\nfile_path -- Required by nodes that load an asset, such as Matchbox.\n\ninput_colour_space -- Optional for nodes that load external media, such as IBL.\n</code></pre>"},{"location":"api/classes/PyImageNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyImageNode/#disconnect_nodes","title":"<code>disconnect_nodes</code>","text":"<pre><code>disconnect_nodes\n</code></pre> <p>disconnect_nodes( (PyActionFamilyNode)arg1, (PyFlameObject)parent_node, (PyFlameObject)child_node [, (str)link_type='Default']) -&gt; bool :</p> <pre><code>Disconnect two nodes in the Action/Image/GMaskTracer schematic.\n\nKeyword argument:\n\ntype -- The type of link used to connect the nodes (default, look at, gmask, gmask exclusive, light, light exclusive, mimic)\n</code></pre>"},{"location":"api/classes/PyImageNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyImageNode/#encompass_nodes","title":"<code>encompass_nodes</code>","text":"<pre><code>encompass_nodes\n</code></pre> <p>encompass_nodes( (PyActionFamilyNode)arg1, (list)node_list) -&gt; object :</p> <pre><code>Create a compass including the node list given as argument\n\nKeyword argument:\n\nnode_list -- a list of nodes (either string or node objects)\n\noutput_type -- the created compass node\n</code></pre>"},{"location":"api/classes/PyImageNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyImageNode/#get_node","title":"<code>get_node</code>","text":"<pre><code>get_node\n</code></pre> <p>get_node( (PyActionFamilyNode)arg1, (str)node_name) -&gt; object :</p> <pre><code>Get a node by node name. Doesn't select it in the UI.\n</code></pre>"},{"location":"api/classes/PyImageNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyImageNode/#organize","title":"<code>organize</code>","text":"<pre><code>organize\n</code></pre> <p>organize( (PyActionFamilyNode)arg1) -&gt; bool :</p> <pre><code>Clean up the Action/Image/GMaskTracer schematic.\n</code></pre>"},{"location":"api/classes/PyImageNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyImageNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyImageNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/","title":"Class: PyLensDistortionNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyLensDistortionNode/#description","title":"Description","text":"<p>Object representing a Lens Distortion node.</p>"},{"location":"api/classes/PyLensDistortionNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyLensDistortionNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyLensDistortionNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#calculate","title":"<code>calculate</code>","text":"<pre><code>calculate\n</code></pre> <p>calculate( (PyLensDistortionNode)arg1) -&gt; None :</p> <pre><code>Calculate the amount of distorsion based on the position of vertices.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#import_lens_distortion","title":"<code>import_lens_distortion</code>","text":"<pre><code>import_lens_distortion\n</code></pre> <p>import_lens_distortion( (PyLensDistortionNode)arg1, (str)filename) -&gt; None :</p> <pre><code>Import the Lens Distortion file.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyLensDistortionNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyLibrary/","title":"Class: PyLibrary","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyLibrary/#description","title":"Description","text":"<p>Class derived from PyArchiveEntry. This class represents a Library.</p>"},{"location":"api/classes/PyLibrary/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>batch_groups</code> Return a list of Batch Group objects that are immediate children of the current object. <code>batch_iterations</code> Return a list of Batch Iteration objects that are immediate children of the current object. <code>children</code> Return a list of the immediate children of the current object. <code>clips</code> Return a list of Clip objects that are immediate children of the current object. <code>desktops</code> Return a list Desktop objects that are immediate children of the current object. <code>folders</code> Return a list of the Folder objects that are immediate children of the current object. <code>opened</code> Return True if the Library is in the open state. <code>parent</code> The parent object of this object. <code>reel_groups</code> Return a list of Reel Group objects that are immediate children of the current object. <code>reels</code> Return a list of Reel objects that are immediate children of the current object. <code>sequences</code> Return a list of Sequence objects that are immediate children of the current object."},{"location":"api/classes/PyLibrary/#methods","title":"Methods","text":""},{"location":"api/classes/PyLibrary/#acquire_exclusive_access","title":"<code>acquire_exclusive_access</code>","text":"<pre><code>acquire_exclusive_access\n</code></pre> <p>acquire_exclusive_access( (PyLibrary)arg1) -&gt; bool :</p> <pre><code>Acquire exclusive access to the Shared Library. Shared Libraries are created locked. Only use with Shared Libraries.\n</code></pre>"},{"location":"api/classes/PyLibrary/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyLibrary)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Clear the Library's contents.\n</code></pre>"},{"location":"api/classes/PyLibrary/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyLibrary/#close","title":"<code>close</code>","text":"<pre><code>close\n</code></pre> <p>close( (PyLibrary)arg1) -&gt; bool :</p> <pre><code>Close a Library to release it from the application memory.\n</code></pre>"},{"location":"api/classes/PyLibrary/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyLibrary/#create_folder","title":"<code>create_folder</code>","text":"<pre><code>create_folder\n</code></pre> <p>create_folder( (PyLibrary)arg1, (str)name) -&gt; object :</p> <pre><code>Create a Folder inside a Library.\n</code></pre>"},{"location":"api/classes/PyLibrary/#create_reel","title":"<code>create_reel</code>","text":"<pre><code>create_reel\n</code></pre> <p>create_reel( (PyLibrary)arg1, (str)name) -&gt; object :</p> <pre><code>Create a Reel inside a Library.\n</code></pre>"},{"location":"api/classes/PyLibrary/#create_reel_group","title":"<code>create_reel_group</code>","text":"<pre><code>create_reel_group\n</code></pre> <p>create_reel_group( (PyLibrary)arg1, (str)name) -&gt; object :</p> <pre><code>Create a Reel Group inside a Library.\n</code></pre>"},{"location":"api/classes/PyLibrary/#create_sequence","title":"<code>create_sequence</code>","text":"<pre><code>create_sequence\n</code></pre> <p>create_sequence( (PyLibrary)arg1 [, (str)name='Untitled Sequence' [, (int)video_tracks=1 [, (bool)video_stereo=False [, (object)width=None [, (object)height=None [, (object)ratio=None [, (object)bit_depth=None [, (object)scan_mode=None [, (object)frame_rate=None [, (object)start_at=00:00:00+00 [, (object)duration=00:00:00+01 [, (int)audio_tracks=1 [, (bool)audio_stereo=True]]]]]]]]]]]]]) -&gt; object :</p> <pre><code>Create a Sequence in a PyReel, PyLibrary, PyFolder.\n\nKeywords arguments:\n\nvideo_tracks -- Number of video tracks. Integer between 1 and 8.\n\nvideo_stereo -- Stereoscopy. False for mono, True for stereo.\n\nwidth -- Integer between 24 and 16384.\n\nheight -- Integer between 24 and 16384.\n\nratio -- Frame aspect ratio. Float between 0.01 and 100.\n\nscan_mode -- Scan mode of the sequence. (F1, F2, P)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps)\n\nstart_at -- Start timecode. The timecode format must be of the format specified by *frame_rate*.\n\nduration -- Can be an end timecode or an integer. If an end timecode, format must be of the format specified by *frame_rate*. If an integer, it represents a number of frames.\n\naudio_tracks -- Number of audio tracks. (0, 1, 2, 4, 8, 12, 16)\n\naudio_stereo -- Stereophony, apply to all *audio_tracks*. False for mono tracks, True for stereo.\n</code></pre>"},{"location":"api/classes/PyLibrary/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyLibrary/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyLibrary/#open","title":"<code>open</code>","text":"<pre><code>open\n</code></pre> <p>open( (PyLibrary)arg1) -&gt; bool :</p> <pre><code>Open a Library and load it in the application memory. Until a Library is open, it cannot be accessed. Libraries are created open.\n</code></pre>"},{"location":"api/classes/PyLibrary/#release_exclusive_access","title":"<code>release_exclusive_access</code>","text":"<pre><code>release_exclusive_access\n</code></pre> <p>release_exclusive_access( (PyLibrary)arg1) -&gt; bool :</p> <pre><code>Release exclusive access to the Shared Library. Only used for Shared Libraries. Only use with Shared Libraries.\n</code></pre>"},{"location":"api/classes/PyMarker/","title":"Class: PyMarker","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMarker/#description","title":"Description","text":"<p>Object representing a Marker.</p>"},{"location":"api/classes/PyMarker/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_annotations</code> Returns True when the Marker contains at least one annotation. <code>parent</code> The parent object of this object."},{"location":"api/classes/PyMarker/#methods","title":"Methods","text":""},{"location":"api/classes/PyMarker/#clear_annotations","title":"<code>clear_annotations</code>","text":"<pre><code>clear_annotations\n</code></pre> <p>clear_annotations( (PyMarker)arg1) -&gt; None :</p> <pre><code>Clear all the annotations from the Marker.\n</code></pre>"},{"location":"api/classes/PyMarker/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyMarker)arg1) -&gt; None :</p> <pre><code>Push the Segment Marker to connected segments.\n</code></pre>"},{"location":"api/classes/PyMediaHub/","title":"Class: PyMediaHub","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMediaHub/#description","title":"Description","text":"<p>This class represents the MediaHub.</p>"},{"location":"api/classes/PyMediaHub/#properties","title":"Properties","text":"Name Description <code>archives</code> None( (flame.PyMediaHub)arg1) -&gt; flame.PyMediaHubTab <code>files</code> None( (flame.PyMediaHub)arg1) -&gt; flame.PyMediaHubFilesTab"},{"location":"api/classes/PyMediaHubFilesEntry/","title":"Class: PyMediaHubFilesEntry","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMediaHubFilesEntry/#description","title":"Description","text":"<p>Object representing a clip in the MediaHub Files tabs</p>"},{"location":"api/classes/PyMediaHubFilesEntry/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>path</code> Returns the absolute path of the clip"},{"location":"api/classes/PyMediaHubFilesEntry/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubFilesEntry/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesEntry/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesEntry/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesEntry/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesFolder/","title":"Class: PyMediaHubFilesFolder","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMediaHubFilesFolder/#description","title":"Description","text":"<p>Object representing a folder in the MediaHub Files tabs</p>"},{"location":"api/classes/PyMediaHubFilesFolder/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>path</code> Returns the absolute path of the folder"},{"location":"api/classes/PyMediaHubFilesFolder/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubFilesFolder/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesFolder/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesFolder/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesFolder/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesTab/","title":"Class: PyMediaHubFilesTab","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyMediaHubTab, instance, object</p>"},{"location":"api/classes/PyMediaHubFilesTab/#description","title":"Description","text":"<p>This class represents the MediaHub Files tab.</p>"},{"location":"api/classes/PyMediaHubFilesTab/#properties","title":"Properties","text":"Name Description <code>options</code> None( (flame.PyMediaHubFilesTab)arg1) -&gt; object"},{"location":"api/classes/PyMediaHubFilesTab/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubFilesTab/#get_path","title":"<code>get_path</code>","text":"<pre><code>get_path\n</code></pre> <p>get_path( (PyMediaHubTab)arg1) -&gt; str :</p> <pre><code>Return the MediaHub tab current path.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesTab/#set_path","title":"<code>set_path</code>","text":"<pre><code>set_path\n</code></pre> <p>set_path( (PyMediaHubTab)arg1, (str)arg2 [, (bool)allow_partial_success=False]) -&gt; bool :</p> <pre><code>Set the MediaHub tab current path. If allow_partial_success is True, the path will be set to the last valid folder in the path.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesTabOptions/","title":"Class: PyMediaHubFilesTabOptions","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMediaHubFilesTabOptions/#description","title":"Description","text":"<p>This class represents the MediaHub Files tab options.</p>"},{"location":"api/classes/PyMediaHubFilesTabOptions/#properties","title":"Properties","text":"Name Description <code>bit_depth</code> Import bit depth value. Possible values are 8, 10, 12, 16, 32, and From Source. <code>cache_and_proxies_all_versions</code> Generate caches and proxies for all versions instead of the current one on import. <code>cache_mode</code> Cache media on import. <code>colour_mgmt_display</code> Import colour management Display name. Can only be set while in View Transform mode. <code>colour_mgmt_invert</code> Import colour management Invert status. Can only be set while in View Transform mode. <code>colour_mgmt_mode</code> Import colour management Mode value. Possible values are Tag Only, Auto Convert, View Transform, and Use LUT. <code>colour_mgmt_view</code> Import colour management View name. Can only be set while in View Transform mode. <code>colour_mgmt_working_space</code> Import colour management Working Space name. Can only be set while in Auto Convert mode. <code>frame_ratio</code> Import frame ratio value. Returns None when resolution mode is not set to Resolution List. <code>height</code> Import height value. Returns None when resolution is set to Same as Source, Scaling Presets or Adaptive when based on width. <code>multi_channel_mode</code> Multi-Channel Mode to use upon import. <code>pixel_ratio</code> Import pixel ratio value. Returns None when resolution is not set to Same As Source. <code>proxies_mode</code> Generate proxies on import. <code>resize_filter</code> Import resizing filter value. Possible values are Lanczos, Shannon, Gaussian, Quadratic, Bicubic, Mitchell, Triangle, and Impulse. <code>resize_mode</code> Import resizing mode value. Possible values are Letterbox, Crop Edges, Fill, and Centre. <code>resolution</code> Set the resolution based on the name. Possible values are Custom Resolution, Project Res, Adaptive, Scaling Presets, Same as Source or a resolution with this format: HD 720 16:9 (1280 x 720) <code>scaling_presets_value</code> Import scaling presets value. Returns None when the resolution selector is not Scaling Presets. <code>scan_mode</code> Import scan mode value. Possible values are P, F1, F2, and From Source. <code>sequence_mode</code> Use the sequence mode to import a range of files. <code>tagged_colour_space</code> Import colour management Tagged Colour Space name in Tag Only, View Transform and Use LUT modes. It also represents the Input Colour Space name in Auto Convert mode. <code>width</code> Import width value. Returns None when resolution is set to Same as Source, Scaling Presets or Adaptive when based on height."},{"location":"api/classes/PyMediaHubFilesTabOptions/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubFilesTabOptions/#import_transform","title":"<code>import_transform</code>","text":"<pre><code>import_transform\n</code></pre> <p>import_transform( (PyMediaHubFilesTabOptions)arg1, (str)file_path) -&gt; None :</p> <pre><code>Import a transform from a file.\n</code></pre>"},{"location":"api/classes/PyMediaHubFilesTabOptions/#set_tagged_colour_space","title":"<code>set_tagged_colour_space</code>","text":"<pre><code>set_tagged_colour_space\n</code></pre> <p>set_tagged_colour_space( (PyMediaHubFilesTabOptions)arg1, (str)colour_space) -&gt; None :</p> <pre><code>Set the tagged colour space to use upon import.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsEntry/","title":"Class: PyMediaHubProjectsEntry","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMediaHubProjectsEntry/#description","title":"Description","text":"<p>Object representing a clip in the MediaHub Projects tabs</p>"},{"location":"api/classes/PyMediaHubProjectsEntry/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>path</code> Returns the path of the clip <code>uid</code> Returns the Unique ID of the clip"},{"location":"api/classes/PyMediaHubProjectsEntry/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubProjectsEntry/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsEntry/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsEntry/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsEntry/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsFolder/","title":"Class: PyMediaHubProjectsFolder","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMediaHubProjectsFolder/#description","title":"Description","text":"<p>Object representing a folder in the MediaHub Projects tabs</p>"},{"location":"api/classes/PyMediaHubProjectsFolder/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>path</code> Returns the path of the folder <code>uid</code> Returns the Unique ID of the folder"},{"location":"api/classes/PyMediaHubProjectsFolder/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubProjectsFolder/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsFolder/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsFolder/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubProjectsFolder/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyMediaHubTab/","title":"Class: PyMediaHubTab","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMediaHubTab/#description","title":"Description","text":"<p>This class represents a MediaHub tab.</p>"},{"location":"api/classes/PyMediaHubTab/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaHubTab/#get_path","title":"<code>get_path</code>","text":"<pre><code>get_path\n</code></pre> <p>get_path( (PyMediaHubTab)arg1) -&gt; str :</p> <pre><code>Return the MediaHub tab current path.\n</code></pre>"},{"location":"api/classes/PyMediaHubTab/#set_path","title":"<code>set_path</code>","text":"<pre><code>set_path\n</code></pre> <p>set_path( (PyMediaHubTab)arg1, (str)arg2 [, (bool)allow_partial_success=False]) -&gt; bool :</p> <pre><code>Set the MediaHub tab current path. If allow_partial_success is True, the path will be set to the last valid folder in the path.\n</code></pre>"},{"location":"api/classes/PyMediaPanel/","title":"Class: PyMediaPanel","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMediaPanel/#description","title":"Description","text":"<p>This class represents the media panel.</p>"},{"location":"api/classes/PyMediaPanel/#properties","title":"Properties","text":"Name Description <code>dual</code> The dual view status of the media panel. <code>full_height</code> The full height status of the media panel. <code>full_width</code> The full width status of the media panel. <code>selected_entries</code> A list of PyObject currently selected. <code>visible</code> The visible status of the media panel."},{"location":"api/classes/PyMediaPanel/#methods","title":"Methods","text":""},{"location":"api/classes/PyMediaPanel/#copy","title":"<code>copy</code>","text":"<pre><code>copy\n</code></pre> <p>copy( (PyMediaPanel)arg1, (object)source_entries, (object)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Copy a PyObject or a list of PyObjects from the Media Panel to a destination inside the Media Panel.Return a list of the copied PyObjects.Keyword arguments:\n\nsource_entries -- The PyObject or list of PyObjects to copy.\n\ndestination -- The PyObject that acts as destination.\n\nduplicate_action -- Action to take when finding an object with the same name (add or replace).\n</code></pre>"},{"location":"api/classes/PyMediaPanel/#move","title":"<code>move</code>","text":"<pre><code>move\n</code></pre> <p>move( (PyMediaPanel)arg1, (object)source_entries, (object)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Move a PyObject or a list of PyObjects from the Media Panel to a destination inside the Media Panel.\n\nReturn a list of the moved PyObjects.\n\nKeyword arguments:\n\nsource_entries -- The PyObject or list of PyObjects to move.\n\ndestination -- The PyObject that acts as destination.\n\nduplicate_action -- Action to take when finding an object with the same name (add or replace).\n</code></pre>"},{"location":"api/classes/PyMessages/","title":"Class: PyMessages","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMessages/#description","title":"Description","text":"<p>Module handling message bar in application UI.</p>"},{"location":"api/classes/PyMessages/#methods","title":"Methods","text":""},{"location":"api/classes/PyMessages/#clear_console","title":"<code>clear_console</code>","text":"<pre><code>clear_console\n</code></pre> <p>clear_console( (PyMessages)arg1) -&gt; None :</p> <pre><code>Remove currently displayed message in the message bar.\n</code></pre>"},{"location":"api/classes/PyMessages/#show_in_console","title":"<code>show_in_console</code>","text":"<pre><code>show_in_console\n</code></pre> <p>show_in_console( (PyMessages)arg1, (str)message [, (str)type='info' [, (int)duration=-1]]) -&gt; None :</p> <pre><code>Display an informative message in application message bar.\n\nmessage -- Message string to display.\n\ntype -- Message type can be info, warning, or error.\n\nduration -- An optional time in seconds to keep message on screen.\n</code></pre>"},{"location":"api/classes/PyMessages/#show_in_dialog","title":"<code>show_in_dialog</code>","text":"<pre><code>show_in_dialog\n</code></pre> <p>show_in_dialog( (PyMessages)arg1, (str)title, (str)message, (str)type, (list)buttons [, (str)cancel_button='']) -&gt; str :</p> <pre><code>Display a custom dialog with a selection of options.\n\nKeywords argument:\n\ntitle -- The title of the dialog.\n\nmessage -- The message displayed in the centre of the dialog.\n\ntype -- The type of dialog. Can be error, info, question, or warning.\n\nbuttons -- The list of titles used to refer to the options\n\ncancel_button -- The text displayed in the cancel option\n</code></pre>"},{"location":"api/classes/PyMetadataNode/","title":"Class: PyMetadataNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMetadataNode/#description","title":"Description","text":"<p>Class derived from PyNode. This class represents a Metadata node.</p>"},{"location":"api/classes/PyMetadataNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyMetadataNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyMetadataNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyMetadataNode)arg1, (str)file_name [, (bool)edited_keys=True [, (bool)discarded_keys=True [, (bool)added_keys=True [, (bool)replaced_keys=True [, (bool)update_tokens=True]]]]]) -&gt; bool :</p> <pre><code>Load a Metadata Node setup.\n\nKeywords argument:\n\nfile_name -- the path and file name of the setup.\n\nedited_keys -- apply edited keys from the setup.\n\ndiscarded_keys -- apply discarded keys from the setup.\n\nadded_keys -- apply added keys from the setup.\n\nreplaced_keys -- apply replaced keys from the setup.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#set_metadata_discarded","title":"<code>set_metadata_discarded</code>","text":"<pre><code>set_metadata_discarded\n</code></pre> <p>set_metadata_discarded( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (bool)discarded=True]]]) -&gt; None :</p> <pre><code>Discard key from the Node's metadata output.\n\nKeyword arguments:\n\nsocket_name -- The socket on which the discarded status of the metadata must be changed.\n\nkey -- Metadata key to be discarded or restored.\n\ndiscarded -- True to discard the key from the node metadata output, False to restore the key.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#set_metadata_key","title":"<code>set_metadata_key</code>","text":"<pre><code>set_metadata_key\n</code></pre> <p>set_metadata_key( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)name=None]]]) -&gt; None :</p> <pre><code>Rename a metadata key on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to rename the key. The default output is used when not specified.\n\nkey -- The current metadata key name to be renamed.\n\nname -- The new metadata key name. If None, the current key name will revert to its original value.\n</code></pre>"},{"location":"api/classes/PyMetadataNode/#set_metadata_value","title":"<code>set_metadata_value</code>","text":"<pre><code>set_metadata_value\n</code></pre> <p>set_metadata_value( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)value=None]]]) -&gt; None :</p> <pre><code>Set the metadata on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to set the metadata. The default output is used when not specified.\n\nkey -- Metadata key to be set or added.\n\nvalue -- Metadata value to be set or edited for the specified key. If None is specified, the current value will revert to the original value.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/","title":"Class: PyMetadataTimelineFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTimelineFX, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMetadataTimelineFX/#description","title":"Description","text":"<p>Object representing a Metadata Timeline FX.</p>"},{"location":"api/classes/PyMetadataTimelineFX/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyMetadataTimelineFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyMetadataTimelineFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyMetadataTimelineFX)arg1 [, (str)key='' [, (int)frame=1]]) -&gt; object :</p> <pre><code>Return the metadata of a Metadata Timeline FX.\n\nKeywords argument:\n\nkey -- Key of the requested metadata. All metadata is returned when not specified.\n\nframe -- Frame number. The first exposed frame being 1. If not specified, the current frame is used.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyMetadataTimelineFX)arg1, (str)file_name [, (bool)edited_keys=True [, (bool)discarded_keys=True [, (bool)added_keys=True [, (bool)update_tokens=True]]]]) -&gt; bool :</p> <pre><code>Load a Metadata Timeline FX setup.\n\nKeywords argument:\n\nfile_name -- the path and file name of the setup.\n\nedited_keys -- apply edited keys from the setup.\n\ndiscarded_keys -- apply discarded keys from the setup.\n\nadded_keys -- apply added keys from the setup.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#set_metadata_discarded","title":"<code>set_metadata_discarded</code>","text":"<pre><code>set_metadata_discarded\n</code></pre> <p>set_metadata_discarded( (PyMetadataTimelineFX)arg1 [, (str)key='' [, (bool)discarded=True]]) -&gt; None :</p> <pre><code>Discard key from the metadata output of a Metadata Timeline FX.\n\nKeywords argument:\n\nkey -- Metadata key to be discarded or restored.\n\ndiscarded -- True to discard the key from the Metadata Timeline FX output, False to restore the key.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#set_metadata_key","title":"<code>set_metadata_key</code>","text":"<pre><code>set_metadata_key\n</code></pre> <p>set_metadata_key( (PyMetadataTimelineFX)arg1 [, (str)key='' [, (object)name=None]]) -&gt; None :</p> <pre><code>Rename a metadata key on a Metadata Timeline FX.\n\nKeyword arguments:\n\nkey -- The current metadata key name to be renamed.\n\nname -- The new metadata key name. If None, the current key name will revert to its original value.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#set_metadata_value","title":"<code>set_metadata_value</code>","text":"<pre><code>set_metadata_value\n</code></pre> <p>set_metadata_value( (PyMetadataTimelineFX)arg1, (str)key [, (object)value=None]) -&gt; None :</p> <pre><code>Set the metadata on a Metadata Timeline FX.\n\nKeywords argument:\n\nkey -- Metadata key to be set or added.\n\nvalue -- Metadata value to be set or edited for the specified key. If None is specified, the current value will revert to the original value.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyMetadataTimelineFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyMetadataValue/","title":"Class: PyMetadataValue","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyMetadataValue/#description","title":"Description","text":"<p>This class holds the metadata of a specific data type.</p>"},{"location":"api/classes/PyMetadataValue/#properties","title":"Properties","text":"Name Description <code>type</code> Return the data type of the metadata"},{"location":"api/classes/PyMetadataValue/#methods","title":"Methods","text":""},{"location":"api/classes/PyMetadataValue/#get_value","title":"<code>get_value</code>","text":"<pre><code>get_value\n</code></pre> <p>get_value( (PyMetadataValue)arg1) -&gt; object :</p> <pre><code>Get the metadata value.\n</code></pre>"},{"location":"api/classes/PyMetadataValue/#set_value","title":"<code>set_value</code>","text":"<pre><code>set_value\n</code></pre> <p>set_value( (PyMetadataValue)arg1, (object)value) -&gt; None :</p> <pre><code>Set the metadata value.\n</code></pre>"},{"location":"api/classes/PyMorphNode/","title":"Class: PyMorphNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyMorphNode/#description","title":"Description","text":"<p>Object representing a Morph node.</p>"},{"location":"api/classes/PyMorphNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyMorphNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyMorphNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyMorphNode/#set_mix_to_range","title":"<code>set_mix_to_range</code>","text":"<pre><code>set_mix_to_range\n</code></pre> <p>set_mix_to_range( (PyMorphNode)arg1) -&gt; None :</p> <pre><code>Move the first and last keyframes of the mix curve to the range's first and last frame.\n</code></pre>"},{"location":"api/classes/PyNode/","title":"Class: PyNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyNode/#description","title":"Description","text":"<p>Object representing a Node.</p>"},{"location":"api/classes/PyNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyOFXNode/","title":"Class: PyOFXNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyOFXNode/#description","title":"Description","text":"<p>Object representing a OpenFX node.</p>"},{"location":"api/classes/PyOFXNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyOFXNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyOFXNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#change_plugin","title":"<code>change_plugin</code>","text":"<pre><code>change_plugin\n</code></pre> <p>change_plugin( (PyOFXNode)arg1, (str)plugin_name) -&gt; bool :</p> <pre><code>Change the active plugin for the openFX node\n</code></pre>"},{"location":"api/classes/PyOFXNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyOFXNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyPaintNode/","title":"Class: PyPaintNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyPaintNode/#description","title":"Description","text":"<p>Object representing a Paint node.</p>"},{"location":"api/classes/PyPaintNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyPaintNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyPaintNode/#add_source","title":"<code>add_source</code>","text":"<pre><code>add_source\n</code></pre> <p>add_source( (PyPaintNode)arg1) -&gt; object :</p> <pre><code>Add a Source layer to a Paint node.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyPaintNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyProject/","title":"Class: PyProject","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyProject/#description","title":"Description","text":"<p>Object representing a Project.</p>"},{"location":"api/classes/PyProject/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>current_workspace</code> Return the current Workspace. <code>description</code> Return the Project description. <code>media_folder</code> The path where the project media is located. <code>name</code> Return the Project name. <code>nickname</code> Return the Project nickname. <code>parent</code> The parent object of this object. <code>project_folder</code> The path where the project is located. <code>project_name</code> Deprecated / use name instead <code>setups_folder</code> The path where the project setups are located. <code>shared_libraries</code> Return a list of Shared Libraries inside the Project. <code>workspaces_count</code> Return the amount of Project Workspaces."},{"location":"api/classes/PyProject/#methods","title":"Methods","text":""},{"location":"api/classes/PyProject/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyProject/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyProject/#create_shared_library","title":"<code>create_shared_library</code>","text":"<pre><code>create_shared_library\n</code></pre> <p>create_shared_library( (PyProject)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Shared Library in the Project.\n</code></pre>"},{"location":"api/classes/PyProject/#export_ocio_config","title":"<code>export_ocio_config</code>","text":"<pre><code>export_ocio_config\n</code></pre> <p>export_ocio_config( (PyProject)arg1, (str)config_name [, (str)destination_folder='' [, (bool)overwrite_existing=False [, (bool)export_as_locked=False [, (bool)generate_ocioz=False]]]]) -&gt; bool :</p> <pre><code>Export the OCIO config file.\n\nKeyword arguments:\n\nconfig_name -- Specifies the name that will be written inside the exported OCIO config and used as the parent folder name where the config will be exported. It should not contain the '.ocio' extension. Mandatory.\n\ndestination_folder -- Specifies the absolute destination folder for the exported OCIO config. It will use the default colour management shared path if empty.\n\noverwrite_existing -- Specifies if the export should overwrite an existing OCIO config with the same name located in the same destination_folder.\n\nexport_as_locked -- Specifies if the exported OCIO config should be locked (the 'LockedPolicy' parameter inside the settings.cfg sidecar file).\n\ngenerate_ocioz -- Specifies if an OCIOZ archive should be created alongside the exported OCIO config.\n</code></pre>"},{"location":"api/classes/PyProject/#get_context_variables","title":"<code>get_context_variables</code>","text":"<pre><code>get_context_variables\n</code></pre> <p>get_context_variables( (PyProject)arg1) -&gt; dict :</p> <pre><code>Get the context variables in a dictionary.\n</code></pre>"},{"location":"api/classes/PyProject/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyProject/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyProject/#refresh_shared_libraries","title":"<code>refresh_shared_libraries</code>","text":"<pre><code>refresh_shared_libraries\n</code></pre> <p>refresh_shared_libraries( (PyProject)arg1) -&gt; bool :</p> <pre><code>Refresh the Shared Libraries list in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyProject/#reload_ocio_config","title":"<code>reload_ocio_config</code>","text":"<pre><code>reload_ocio_config\n</code></pre> <p>reload_ocio_config( (PyProject)arg1 [, (bool)reset_colour_policy=False]) -&gt; bool :</p> <pre><code>Reload the OCIO config file.\n\nKeyword argument:\n\nreset_colour_policy -- Delete the project's custom colour spaces, roles, and rules (false by default).\n</code></pre>"},{"location":"api/classes/PyProject/#reset_context_variables","title":"<code>reset_context_variables</code>","text":"<pre><code>reset_context_variables\n</code></pre> <p>reset_context_variables( (PyProject)arg1) -&gt; None :</p> <pre><code>Reset the context variables to their initial state from the ocio config.\n</code></pre>"},{"location":"api/classes/PyProject/#set_context_variable","title":"<code>set_context_variable</code>","text":"<pre><code>set_context_variable\n</code></pre> <p>set_context_variable( (PyProject)arg1, (str)name, (str)value) -&gt; None :</p> <pre><code>Set the value for the specified context variable.\n</code></pre>"},{"location":"api/classes/PyProjectSelector/","title":"Class: PyProjectSelector","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyProjectSelector/#description","title":"Description","text":"<p>Object representing the Project manager.</p>"},{"location":"api/classes/PyProjectSelector/#properties","title":"Properties","text":"Name Description <code>current_project</code> The PyProject linked to the current Project."},{"location":"api/classes/PyReadFileNode/","title":"Class: PyReadFileNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyReadFileNode/#description","title":"Description","text":"<p>Class derived from PyNode. This class represents a ReadFile node.</p>"},{"location":"api/classes/PyReadFileNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyReadFileNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyReadFileNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyReadFileNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyReel/","title":"Class: PyReel","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyReel/#description","title":"Description","text":"<p>Object representing a Reel.</p>"},{"location":"api/classes/PyReel/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>children</code> Return a list of the immediate children of the current object. <code>clips</code> Return a list of Clip objects that are immediate children of the current object. <code>parent</code> The parent object of this object. <code>sequences</code> Return a list of Sequence objects that are immediate children of the current object. <code>type</code> Return the Reel type (Reel, Schematic, Sequences, Shelf)."},{"location":"api/classes/PyReel/#methods","title":"Methods","text":""},{"location":"api/classes/PyReel/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyReel)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Clear the Reel content.\n</code></pre>"},{"location":"api/classes/PyReel/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReel/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyReel/#create_sequence","title":"<code>create_sequence</code>","text":"<pre><code>create_sequence\n</code></pre> <p>create_sequence( (PyReel)arg1 [, (str)name='Untitled Sequence' [, (int)video_tracks=1 [, (bool)video_stereo=False [, (object)width=None [, (object)height=None [, (object)ratio=None [, (object)bit_depth=None [, (object)scan_mode=None [, (object)frame_rate=None [, (object)start_at=00:00:00+00 [, (object)duration=00:00:00+01 [, (int)audio_tracks=1 [, (bool)audio_stereo=True]]]]]]]]]]]]]) -&gt; object :</p> <pre><code>Create a Sequence in a PyReel, PyLibrary, PyFolder.\n\nKeywords arguments:\n\nvideo_tracks -- Number of video tracks. Integer between 1 and 8.\n\nvideo_stereo -- Stereoscopy. False for mono, True for stereo.\n\nwidth -- Integer between 24 and 16384.\n\nheight -- Integer between 24 and 16384.\n\nratio -- Frame aspect ratio. Float between 0.01 and 100.\n\nscan_mode -- Scan mode of the sequence. (F1, F2, P)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps)\n\nstart_at -- Start timecode. The timecode format must be of the format specified by *frame_rate*.\n\nduration -- Can be an end timecode or an integer. If an end timecode, format must be of the format specified by *frame_rate*. If an integer, it represents a number of frames.\n\naudio_tracks -- Number of audio tracks. (0, 1, 2, 4, 8, 12, 16)\n\naudio_stereo -- Stereophony, apply to all *audio_tracks*. False for mono tracks, True for stereo.\n</code></pre>"},{"location":"api/classes/PyReel/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReel/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReel/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyReel)arg1) -&gt; bool :</p> <pre><code>Save the Reel to the defined save destination.\n</code></pre>"},{"location":"api/classes/PyReelGroup/","title":"Class: PyReelGroup","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyReelGroup/#description","title":"Description","text":"<p>Object representing a Reel Group.</p>"},{"location":"api/classes/PyReelGroup/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>children</code> Return a list of the immediate children of the current object. <code>parent</code> The parent object of this object. <code>reels</code> Return a list of Reel objects that are immediate children of the current object."},{"location":"api/classes/PyReelGroup/#methods","title":"Methods","text":""},{"location":"api/classes/PyReelGroup/#clear","title":"<code>clear</code>","text":"<pre><code>clear\n</code></pre> <p>clear( (PyReelGroup)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Clear the Reel Group content.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#create_reel","title":"<code>create_reel</code>","text":"<pre><code>create_reel\n</code></pre> <p>create_reel( (PyReelGroup)arg1, (str)name [, (bool)sequence=False]) -&gt; object :</p> <pre><code>Create a new Reel inside a Reel Group.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyReelGroup/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyReelGroup)arg1) -&gt; bool :</p> <pre><code>Save the Reel Group to the defined save destination.\n</code></pre>"},{"location":"api/classes/PyRenderNode/","title":"Class: PyRenderNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyRenderNode/#description","title":"Description","text":"<p>Class derived from PyNode. This class represents a Render node.</p>"},{"location":"api/classes/PyRenderNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>channels</code> The channels attribute is a list of tuples, where each tuple is made of a socket name and its channel name. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyRenderNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyRenderNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#set_channel_name","title":"<code>set_channel_name</code>","text":"<pre><code>set_channel_name\n</code></pre> <p>set_channel_name( (PyRenderNode)arg1, (object)channel, (object)name) -&gt; None :</p> <pre><code>Rename a channel, using its index or front channel name as the index key.\n\nKeyword arguments:\n\nchannel -- The channel to rename. Can be the channel index or the current name of the channel's front socket.\n\nname -- The new name of the channel. The type is either a string or a tuple. A Write File node always takes a string. A Render node takes a string or a tuple.\n\nIn a Render node, a string only sets the name of the channel's front socket; the function creates the name of the matte socket by appending '_alpha' to 'name'. In the UI, the channel is flagged 'Sync'. A Write File node has only one socket per channel, and requires only a string to set a socket name.\n\nIn a Render node, a tuple sets the names of the front and matte sockets. In the UI, the channel is not flagged 'Sync'. A Write File node does not accept a tuple.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#set_metadata_discarded","title":"<code>set_metadata_discarded</code>","text":"<pre><code>set_metadata_discarded\n</code></pre> <p>set_metadata_discarded( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (bool)discarded=True]]]) -&gt; None :</p> <pre><code>Discard key from the Node's metadata output.\n\nKeyword arguments:\n\nsocket_name -- The socket on which the discarded status of the metadata must be changed.\n\nkey -- Metadata key to be discarded or restored.\n\ndiscarded -- True to discard the key from the node metadata output, False to restore the key.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#set_metadata_key","title":"<code>set_metadata_key</code>","text":"<pre><code>set_metadata_key\n</code></pre> <p>set_metadata_key( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)name=None]]]) -&gt; None :</p> <pre><code>Rename a metadata key on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to rename the key. The default output is used when not specified.\n\nkey -- The current metadata key name to be renamed.\n\nname -- The new metadata key name. If None, the current key name will revert to its original value.\n</code></pre>"},{"location":"api/classes/PyRenderNode/#set_metadata_value","title":"<code>set_metadata_value</code>","text":"<pre><code>set_metadata_value\n</code></pre> <p>set_metadata_value( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)value=None [, (bool)is_dynamic=False]]]]) -&gt; None :</p> <pre><code>Set the metadata on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to set the metadata. The default output is used when not specified.\n\nkey -- Metadata key to be set or added.\n\nvalue -- Metadata value to be set or edited for the specified key. If None is specified, the current value will revert to the original value.\n\nis_dynamic -- Set the Metadata value to be resolved dynamically if it contains tokens.\n</code></pre>"},{"location":"api/classes/PyResolution/","title":"Class: PyResolution","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyResolution/#description","title":"Description","text":"<p>Object representing a resolution</p> <p>PyResolution()</p> <p>PyResolution(width, height, bit_depth, frame_ratio, scan_format)</p>"},{"location":"api/classes/PyResolution/#properties","title":"Properties","text":"Name Description <code>bit_depth</code> Return the resolution bit depth. <code>frame_ratio</code> Return the resolution frame ratio. <code>height</code> Return the resolution height. <code>resolution</code> Set the resolution based on its name in the UI. Possible values are:  Custom Resolution  Project Res  Project Resolution  A resolution, in the format used by the Resolution List in the UI. Example: HD 720 16:9 (1280 x 720) <code>scan_mode</code> Return the resolution scan mode. <code>width</code> Return the resolution width."},{"location":"api/classes/PySearch/","title":"Class: PySearch","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PySearch/#description","title":"Description","text":"<p>This class represents the search.</p>"},{"location":"api/classes/PySearch/#properties","title":"Properties","text":"Name Description <code>use_weight</code> Return true if the search sorting is done using weight."},{"location":"api/classes/PySearch/#methods","title":"Methods","text":""},{"location":"api/classes/PySearch/#activate_search_result","title":"<code>activate_search_result</code>","text":"<pre><code>activate_search_result\n</code></pre> <p>activate_search_result( (PySearch)arg1, (str)name, (str)type [, (str)tab='Tools']) -&gt; None :</p> <pre><code>Activate a search result.\n</code></pre>"},{"location":"api/classes/PySearch/#search_results","title":"<code>search_results</code>","text":"<pre><code>search_results\n</code></pre> <p>search_results( (PySearch)arg1 [, (str)search_str='*' [, (str)tab='Tools']]) -&gt; list :</p> <pre><code>Search results that match a string.\n</code></pre>"},{"location":"api/classes/PySearch/#set_tool_favorite","title":"<code>set_tool_favorite</code>","text":"<pre><code>set_tool_favorite\n</code></pre> <p>set_tool_favorite( (PySearch)arg1, (str)arg2, (str)name, (bool)type) -&gt; None :</p> <pre><code>Return the favorite status of a tool.\n</code></pre>"},{"location":"api/classes/PySearch/#set_tool_hidden","title":"<code>set_tool_hidden</code>","text":"<pre><code>set_tool_hidden\n</code></pre> <p>set_tool_hidden( (PySearch)arg1, (str)arg2, (str)name, (bool)type) -&gt; None :</p> <pre><code>Return the hidden status of a tool.\n</code></pre>"},{"location":"api/classes/PySearch/#set_tool_weight","title":"<code>set_tool_weight</code>","text":"<pre><code>set_tool_weight\n</code></pre> <p>set_tool_weight( (PySearch)arg1, (str)arg2, (str)name, (int)type) -&gt; None :</p> <pre><code>Return the tool weight.\n</code></pre>"},{"location":"api/classes/PySegment/","title":"Class: PySegment","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PySegment/#description","title":"Description","text":"<p>Object representing a Segment.</p>"},{"location":"api/classes/PySegment/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>container_clip</code> Return the current Matte mode. <code>effect_types</code> Return a list of available effect types for the segment <code>effects</code> Return a list of PyTimeline FX on the segment. <code>file_path</code> Return the file path of the Segment's source. <code>groups</code> Return a list of PySequenceGroups that contains the segment. <code>head</code> Return the amount of head of the Segment. <code>markers</code> Return a list of the segment's Markers. <code>matte_channel</code> Return the name of the Matte channel. <code>matte_channels</code> Return a list of all Matte channels. <code>matte_mode</code> Return the current Matte mode. <code>original_source_uid</code> Return the Clip's original source UID. <code>parent</code> The parent object of this object. <code>record_duration</code> Return the duration of the Segment. <code>record_in</code> Return the record time in of the Segment. <code>record_out</code> Return the record time out of the Segment. <code>rgb_channel</code> Return the name of the RGB channel. <code>rgb_channels</code> Return a list of all RGB channels <code>source_audio_track</code> Return the audio track of the source. <code>source_bit_depth</code> Return the Clip's bit depth. <code>source_cached</code> Return the Clip's cache status. <code>source_colour_primaries</code> Deduce the Clip's 'colour primaries' export attribute. <code>source_duration</code> Return the duration of the Segment's source. <code>source_essence_uid</code> Return the Clip's essence uid. <code>source_frame_rate</code> Return the Clip's frame rate. <code>source_has_history</code> Return the existence of history inside the Clip. <code>source_height</code> Return the Clip's height. <code>source_in</code> Return the source time in of the Segment. <code>source_matrix_coefficients</code> Deduce the Clip's 'matrix coefficients' export attribute. <code>source_name</code> Return the name of the Segment's source. <code>source_out</code> Return the source time out of the Segment. <code>source_ratio</code> Return the Clip's frame ratio. <code>source_sample_rate</code> Return the Clip's audio sample rate. <code>source_scan_mode</code> Return the Clip's scan mode. <code>source_transfer_characteristics</code> Deduce the Clip's 'transfer characteristics' export attribute. <code>source_uid</code> Return the Clip's source uid. <code>source_unlinked</code> Return the Clip's unlinked status. <code>source_width</code> Return the Clip's width. <code>start_frame</code> Return the start frame of the Segment. <code>tail</code> Return the amount of tail of the Segment. <code>tape_name</code> Return the tape name of the Segment. <code>type</code> Return the Segment type. <code>version_uid</code> Return the current version unique ID. <code>version_uids</code> Return a list of available version unique IDs."},{"location":"api/classes/PySegment/#methods","title":"Methods","text":""},{"location":"api/classes/PySegment/#change_start_frame","title":"<code>change_start_frame</code>","text":"<pre><code>change_start_frame\n</code></pre> <p>change_start_frame( (PySegment)arg1, (int)start_frame [, (bool)use_segment_connections=True]) -&gt; None :</p> <pre><code>Modify the start frame of the segment.\n\nKeywords argument:\n\nstart_frame -- New start frame of the segment.\n\nuse_segment_connections -- Sync the start frame of connected segments.\n</code></pre>"},{"location":"api/classes/PySegment/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PySegment)arg1) -&gt; None :</p> <pre><code>Clear the colour of the Segment.\n</code></pre>"},{"location":"api/classes/PySegment/#connected_segments","title":"<code>connected_segments</code>","text":"<pre><code>connected_segments\n</code></pre> <p>connected_segments( (PySegment)arg1 [, (str)scoping='all reels']) -&gt; object :</p> <pre><code>Return a list of the connected segments.\n\nKeywords argument:\n\nscoping -- Scopes of the sequences to query (all reels, sequences reels, current reel, current sequence).\n\n (Default:all reels)\n</code></pre>"},{"location":"api/classes/PySegment/#copy_to_media_panel","title":"<code>copy_to_media_panel</code>","text":"<pre><code>copy_to_media_panel\n</code></pre> <p>copy_to_media_panel( (PySegment)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip with a copy of the PyObject.\n</code></pre>"},{"location":"api/classes/PySegment/#create_connection","title":"<code>create_connection</code>","text":"<pre><code>create_connection\n</code></pre> <p>create_connection( (PySegment)arg1) -&gt; None :</p> <pre><code>Create a connected segment connection.\n</code></pre>"},{"location":"api/classes/PySegment/#create_effect","title":"<code>create_effect</code>","text":"<pre><code>create_effect\n</code></pre> <p>create_effect( (PySegment)arg1, (str)effect_type [, (str)after_effect_type='']) -&gt; object :</p> <pre><code>Add an effect of effect_type on the Segment.\n\nafter_effect_type can be specified to insert the effect at a specific position.\n</code></pre>"},{"location":"api/classes/PySegment/#create_marker","title":"<code>create_marker</code>","text":"<pre><code>create_marker\n</code></pre> <p>create_marker( (PySegment)arg1, (object)location) -&gt; object :</p> <pre><code>Create a Marker at the specified location on the Segment.\n</code></pre>"},{"location":"api/classes/PySegment/#create_unlinked_segment","title":"<code>create_unlinked_segment</code>","text":"<pre><code>create_unlinked_segment\n</code></pre> <p>create_unlinked_segment( (PySegment)arg1 [, (str)source_name='' [, (str)tape_name='' [, (object)start_time=0 [, (object)source_duration=0 [, (object)head=0 [, (str)file_path='' [, (int)source_audio_track=1 [, (int)width=0 [, (int)height=0 [, (float)ratio=0.0 [, (int)bit_depth=0 [, (str)scan_mode='Same As Sequence' [, (str)frame_rate='Same As Sequence' [, (object)timewarp_speed=None]]]]]]]]]]]]]]) -&gt; None :</p> <pre><code>Replace the gap with an unlinked source media segment.\n\nKeywords argument:\n\nsource_name -- Name of the source.\n\ntape_name -- Tape name of the source.\n\nstart_time -- Start time of the source. Must be a PyTime or a frame number.\n\nsource_duration -- Length of the source. Must be a PyTime, a number of frames, or \"Infinite\".\n\nhead -- Amount of head media to set on the segment.\n\nfile_path -- File path to the media.\n\nsource_audio_track -- Audio track from the source.\n\nwidth -- Width of the video media. (0 to use the sequence width)\n\nheight -- Height of the video media. (0 to use the sequence height)\n\nratio -- Frame ratio of the video media. (0.0 to use the sequence ratio)\n\nbit_depth -- Bit depth of the video media. (0 to use the sequence bit depth)\n\nscan_mode -- Scan mode of the video media. (P, F1, F2, or Same As Sequence)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps, Same As Sequence)\n\ntimewarp_speed -- When defined, a timewarp is applied to the segment with the percentage of timewarp_speed. For audio segments, the speed must be greater than zero.\n</code></pre>"},{"location":"api/classes/PySegment/#duplicate_source","title":"<code>duplicate_source</code>","text":"<pre><code>duplicate_source\n</code></pre> <p>duplicate_source( (PySegment)arg1) -&gt; None :</p> <pre><code>Insure that the segment's source is not shared anymore.\n</code></pre>"},{"location":"api/classes/PySegment/#get_colour_space","title":"<code>get_colour_space</code>","text":"<pre><code>get_colour_space\n</code></pre> <p>get_colour_space( (PySegment)arg1 [, (PyTime)time=None]) -&gt; str :</p> <pre><code>Return the colour space at the requested time. Use record_in when no time is supplied.\n</code></pre>"},{"location":"api/classes/PySegment/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PySegment)arg1 [, (str)key='' [, (PyTime)time=None]]) -&gt; object :</p> <pre><code>Return the metadata of the segment.\n\nKeywords argument:\n\nkey -- Key of the requested metadata. All metadata is returned when not specified.\n\ntime -- Must be a PyTime. If not specified, the segment start time is used.\n</code></pre>"},{"location":"api/classes/PySegment/#match","title":"<code>match</code>","text":"<pre><code>match\n</code></pre> <p>match( (PySegment)arg1, (PyArchiveEntry)destination [, (bool)preserve_handle=False [, (bool)use_sequence_info=True [, (bool)include_nested_content=False [, (bool)include_timeline_fx=False]]]]) -&gt; object :</p> <pre><code>Match out the media of the PySegment to the destination.\n\nReturns a PyClip or a list of PyClip (with the included_nested_content option).\n\nKeywords argument:\n\ndestination -- The PyObject that acts as the destination.\n\npreserve_handle -- Prevent the unrolling of the media handles.\n\nuse_sequence_info -- Copy sequence segment information to the new matched clip.\n\ninclude_nested_content -- Include all sources found inside a BFX or Matte Container.\n\ninclude_timeline_fx -- Copy the Timeline FX present on the original clip to the new matched clip.\n</code></pre>"},{"location":"api/classes/PySegment/#remove_connection","title":"<code>remove_connection</code>","text":"<pre><code>remove_connection\n</code></pre> <p>remove_connection( (PySegment)arg1) -&gt; None :</p> <pre><code>Remove the connected segment connection.\n</code></pre>"},{"location":"api/classes/PySegment/#set_gap_bars","title":"<code>set_gap_bars</code>","text":"<pre><code>set_gap_bars\n</code></pre> <p>set_gap_bars( (PySegment)arg1 [, (str)type='smpte' [, (bool)full_luminance=False [, (float)softness=0.0]]]) -&gt; object :</p> <pre><code>Create colour bars segment for the duration of the gap.\n\nReturns a new PySegment on success.\n\nKeywords argument:\n\ntype -- smpte or pal.\n\nfull_luminance -- bars created at 100 or 75 percent luminance.\n\nsoftness -- softness to apply between the bars.\n</code></pre>"},{"location":"api/classes/PySegment/#set_gap_colour","title":"<code>set_gap_colour</code>","text":"<pre><code>set_gap_colour\n</code></pre> <p>set_gap_colour( (PySegment)arg1 [, (float)r=0.0 [, (float)g=0.0 [, (float)b=0.0]]]) -&gt; None :</p> <pre><code>Create a colour source segment for the duration of the gap, or set the colour of an existing colour source.\n</code></pre>"},{"location":"api/classes/PySegment/#set_matte_channel","title":"<code>set_matte_channel</code>","text":"<pre><code>set_matte_channel\n</code></pre> <p>set_matte_channel( (PySegment)arg1 [, (str)channel_name='' [, (int)channel_index=-1 [, (str)scope='Follow Preferences' [, (str)matte_mode='Custom Matte']]]]) -&gt; bool :</p> <pre><code>Set the Matte channel of the source specified by channel_index or by channel_name if the matte_mode is set to Custom Matte.\n\nKeywords argument:\n\nchannel_name -- Name of the channel found in matte_channels.\n\nchannel_index -- Index of the channel found in matte_channels.\n\nscope -- Scope of the changes ( Follow Preferences, No Sharing, Follow Source Sharing, Follow Connected Segments).\n\nmatte_mode -- Matte origin (Follow RGB, No Matte, Custom Matte).\n</code></pre>"},{"location":"api/classes/PySegment/#set_rgb_channel","title":"<code>set_rgb_channel</code>","text":"<pre><code>set_rgb_channel\n</code></pre> <p>set_rgb_channel( (PySegment)arg1 [, (str)channel_name='' [, (int)channel_index=-1 [, (str)scope='Follow Preferences']]]) -&gt; bool :</p> <pre><code>Set the RGB channel of the source specified by channel_index or by channel_name\n\nKeywords argument:\n\nchannel_name -- Name of the channel found in rgb_channels.\n\nchannel_index -- Index of the channel found in rgb_channels.\n\nscope -- Scope of the changes ( Follow Preferences, No Sharing, Follow Source Sharing, Follow Connected Segments).\n</code></pre>"},{"location":"api/classes/PySegment/#set_version_uid","title":"<code>set_version_uid</code>","text":"<pre><code>set_version_uid\n</code></pre> <p>set_version_uid( (PySegment)arg1, (str)version_uid [, (str)scope='Follow Source Sharing']) -&gt; bool :</p> <pre><code>Set the current version unique ID of the source.\n\nKeywords argument:\n\nversion_uid -- version unique ID.\n\nscope -- Scope of the changes ( No Sharing, Follow Source Sharing, Follow Connected Segments).\n</code></pre>"},{"location":"api/classes/PySegment/#shared_source_segments","title":"<code>shared_source_segments</code>","text":"<pre><code>shared_source_segments\n</code></pre> <p>shared_source_segments( (PySegment)arg1) -&gt; object :</p> <pre><code>Return a list of the segments sharing this segment's source.\n</code></pre>"},{"location":"api/classes/PySegment/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PySegment)arg1, (int)offset [, (bool)sync=False]) -&gt; bool :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PySegment/#slip","title":"<code>slip</code>","text":"<pre><code>slip\n</code></pre> <p>slip( (PySegment)arg1, (int)offset [, (bool)sync=False [, (str)keyframes_move_mode='Shift']]) -&gt; bool :</p> <pre><code>Slip the media of the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slip the media.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n\nkeyframes_move_mode -- Select how the animation channels are affected ( Pin, Shift, Prop)\n</code></pre>"},{"location":"api/classes/PySegment/#smart_replace","title":"<code>smart_replace</code>","text":"<pre><code>smart_replace\n</code></pre> <p>smart_replace( (PySegment)arg1, (PyClip)source_clip) -&gt; None :</p> <pre><code>Replace the PySegment by the source_clip segment, including the Timeline FX.\n</code></pre>"},{"location":"api/classes/PySegment/#smart_replace_media","title":"<code>smart_replace_media</code>","text":"<pre><code>smart_replace_media\n</code></pre> <p>smart_replace_media( (PySegment)arg1, (PyClip)source_clip) -&gt; None :</p> <pre><code>Replace the media of PySegment by the source_clip segment, leaving the PySegment Timeline FX untouched\n</code></pre>"},{"location":"api/classes/PySegment/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PySegment)arg1) -&gt; None :</p> <pre><code>Sync connected segments with the Timeline FXs of the current segment.\n</code></pre>"},{"location":"api/classes/PySegment/#trim_head","title":"<code>trim_head</code>","text":"<pre><code>trim_head\n</code></pre> <p>trim_head( (PySegment)arg1, (int)offset [, (bool)ripple=False [, (bool)sync=False [, (str)keyframes_move_mode='Shift']]]) -&gt; bool :</p> <pre><code>Modify the amount of head of the PySegment.\n\nKeywords argument:\n\noffset -- Number of frames to add or remove from the head.\n\nripple -- Enable to prevent gaps from appearing when performing a trim.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n\nkeyframes_move_mode -- Select how the animation channels are affected ( Pin, Shift, Prop)\n</code></pre>"},{"location":"api/classes/PySegment/#trim_tail","title":"<code>trim_tail</code>","text":"<pre><code>trim_tail\n</code></pre> <p>trim_tail( (PySegment)arg1, (int)offset [, (bool)ripple=False [, (bool)sync=False [, (str)keyframes_move_mode='Shift']]]) -&gt; bool :</p> <pre><code>Modify the amount of tail of the PySegment.\n\nKeywords argument:\n\noffset -- Number of frames to add or remove from the tail.\n\nripple -- Enable to prevent gaps from appearing when performing a trim.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n\nkeyframes_move_mode -- Select how the animation channels are affected ( Pin, Shift, Prop)\n</code></pre>"},{"location":"api/classes/PySequence/","title":"Class: PySequence","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyClip, PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PySequence/#description","title":"Description","text":"<p>Object representing a Sequence.</p>"},{"location":"api/classes/PySequence/#properties","title":"Properties","text":"Name Description <code>archive_date</code> Return the Clip's last archive date. <code>archive_error</code> Return the Clip's last archive error. <code>attributes</code> The attributes of a python object. <code>audio_tracks</code> Return a list of the Clip's Audio Tracks. <code>bit_depth</code> Return the Clip's bit depth. <code>cached</code> Return the Clip's cache status. <code>colour_primaries</code> Deduce the Clip's 'colour primaries' export attribute. <code>creation_date</code> Return the Clip's creation date. <code>duration</code> Return the Clip's duration. <code>essence_uid</code> Return the Clip's essence uid. <code>frame_rate</code> Return the Clip's frame rate. <code>groups</code> Return a list of the sequence's PySequenceGroups. <code>has_deliverables</code> Return the existence of deliverables on the Clip. <code>has_history</code> Return the existence of history inside the Clip. <code>height</code> Return the Clip's height. <code>markers</code> Return a list of the Clip's Markers. <code>matrix_coefficients</code> Deduce the Clip's 'matrix coefficients' export attribute. <code>original_source_uid</code> Return the Clip's original source UID. <code>parent</code> The parent object of this object. <code>proxy_resolution</code> Return the Clip's proxy resolution if it has proxies. <code>ratio</code> Return the Clip's frame ratio. <code>sample_rate</code> Return the Clip's audio sample rate. <code>scan_mode</code> Return the Clip's scan mode. <code>source_uid</code> Return the Clip's source uid. <code>start_frame</code> Return the Clip's start frame. <code>subtitles</code> Return a list of the Clip's Subtitles Tracks. <code>transfer_characteristics</code> Deduce the Clip's 'transfer characteristics' export attribute. <code>unlinked</code> Return the Clip's unlinked status. <code>versions</code> Return a list of the Clip's versions. <code>width</code> Return the Clip's width."},{"location":"api/classes/PySequence/#methods","title":"Methods","text":""},{"location":"api/classes/PySequence/#cache_media","title":"<code>cache_media</code>","text":"<pre><code>cache_media\n</code></pre> <p>cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Cache the Clip's linked media.\n\nKeyword argument:\n\nmode -- Determine the version to cache (currently selected or all versions). All Versions is only useful with to multi-version clips (Current, All Versions)\n</code></pre>"},{"location":"api/classes/PySequence/#change_dominance","title":"<code>change_dominance</code>","text":"<pre><code>change_dominance\n</code></pre> <p>change_dominance( (PyClip)arg1, (str)scan_mode) -&gt; None :</p> <pre><code>Change the Clip's dominance. Changes only the clip's metadata.\n\nKeyword argument:\n\nscan_mode -- Field dominance. (P, F1, F2)\n</code></pre>"},{"location":"api/classes/PySequence/#change_start_frame","title":"<code>change_start_frame</code>","text":"<pre><code>change_start_frame\n</code></pre> <p>change_start_frame( (PyClip)arg1, (int)start_frame [, (bool)use_segment_connections=True]) -&gt; None :</p> <pre><code>Modify the start frame of a source Clip.\n\nKeywords argument:\n\nstart_frame -- New start frame of the clip.\n\nuse_segment_connections -- Sync the start frame of connected segments.\n</code></pre>"},{"location":"api/classes/PySequence/#clear_cache_media","title":"<code>clear_cache_media</code>","text":"<pre><code>clear_cache_media\n</code></pre> <p>clear_cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Clear the Clip's media cache.\n\nKeyword argument:\n\nmode -- Determine the version's cache to clear. (Current, All Versions, All But Current)\n</code></pre>"},{"location":"api/classes/PySequence/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PySequence/#clear_renders","title":"<code>clear_renders</code>","text":"<pre><code>clear_renders\n</code></pre> <p>clear_renders( (PyClip)arg1) -&gt; None :</p> <pre><code>Clear the Clip's Timeline FX renders.\n</code></pre>"},{"location":"api/classes/PySequence/#close_container","title":"<code>close_container</code>","text":"<pre><code>close_container\n</code></pre> <p>close_container( (PyClip)arg1) -&gt; None :</p> <pre><code>Close the container timeline if the Clip is inside a container.\n</code></pre>"},{"location":"api/classes/PySequence/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PySequence/#copy_selection_to_media_panel","title":"<code>copy_selection_to_media_panel</code>","text":"<pre><code>copy_selection_to_media_panel\n</code></pre> <p>copy_selection_to_media_panel( (PySequence)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip by copying the currently selected segments.\n\nReturn the new PyClip.\n\nKeyword arguments:\n\ndestination -- The PyObject that acts as the destination.\n\nduplicate_action -- Action to take when an object with the same name already exists (add or replace).\n</code></pre>"},{"location":"api/classes/PySequence/#create_audio","title":"<code>create_audio</code>","text":"<pre><code>create_audio\n</code></pre> <p>create_audio( (PySequence)arg1 [, (bool)stereo=False]) -&gt; object :</p> <pre><code>Add an Audio Track to the Sequence.\n</code></pre>"},{"location":"api/classes/PySequence/#create_container","title":"<code>create_container</code>","text":"<pre><code>create_container\n</code></pre> <p>create_container( (PySequence)arg1) -&gt; object :</p> <pre><code>Create a container with the selected segments or between the in and out marks.\n</code></pre>"},{"location":"api/classes/PySequence/#create_group","title":"<code>create_group</code>","text":"<pre><code>create_group\n</code></pre> <p>create_group( (PySequence)arg1, (str)name) -&gt; object :</p> <pre><code>Creates a new PySequenceGroup.\n\nThe group name must be supplied as argument.\n</code></pre>"},{"location":"api/classes/PySequence/#create_marker","title":"<code>create_marker</code>","text":"<pre><code>create_marker\n</code></pre> <p>create_marker( (PyClip)arg1, (object)location) -&gt; object :</p> <pre><code>Add a Marker to the Clip.Keyword argument:\n\nlocation -- The frame where the marker gets created.\n</code></pre>"},{"location":"api/classes/PySequence/#create_subtitle","title":"<code>create_subtitle</code>","text":"<pre><code>create_subtitle\n</code></pre> <p>create_subtitle( (PySequence)arg1) -&gt; object :</p> <pre><code>Add a Subtitle Track to the Sequence.\n</code></pre>"},{"location":"api/classes/PySequence/#create_version","title":"<code>create_version</code>","text":"<pre><code>create_version\n</code></pre> <p>create_version( (PySequence)arg1 [, (bool)stereo=False]) -&gt; object :</p> <pre><code>Add a Version to the Sequence.\n</code></pre>"},{"location":"api/classes/PySequence/#cut","title":"<code>cut</code>","text":"<pre><code>cut\n</code></pre> <p>cut( (PyClip)arg1, (PyTime)cut_time) -&gt; None :</p> <pre><code>Cut all tracks of the Clip.\n</code></pre>"},{"location":"api/classes/PySequence/#extract_selection_to_media_panel","title":"<code>extract_selection_to_media_panel</code>","text":"<pre><code>extract_selection_to_media_panel\n</code></pre> <p>extract_selection_to_media_panel( (PySequence)arg1 [, (PyArchiveEntry)destination=None [, (str)duplicate_action='add']]) -&gt; object :</p> <pre><code>Extract the selection from the sequence.\n\nReturn the new PyClip created from the selection when a destination is supplied.\n\nKeyword arguments:\n\ndestination -- The PyObject that acts as the destination.\n\nduplicate_action -- Action to take when an object with the same name already exists (add or replace).\n</code></pre>"},{"location":"api/classes/PySequence/#flush_cache_media","title":"<code>flush_cache_media</code>","text":"<pre><code>flush_cache_media\n</code></pre> <p>flush_cache_media( (PyClip)arg1 [, (str)mode='current']) -&gt; bool :</p> <pre><code>Clear the Clip's media cache.\n\nKeyword argument:\n\nmode -- Determine the version's cache to clear. (Current, All Versions, All But Current)(Deprecated: use 'clear_cache_media' instead.)\n</code></pre>"},{"location":"api/classes/PySequence/#flush_renders","title":"<code>flush_renders</code>","text":"<pre><code>flush_renders\n</code></pre> <p>flush_renders( (PyClip)arg1) -&gt; None :</p> <pre><code>Clear the Clip's Timeline FX renders.(Deprecated: use 'clear_renders' instead.)\n</code></pre>"},{"location":"api/classes/PySequence/#get_colour_space","title":"<code>get_colour_space</code>","text":"<pre><code>get_colour_space\n</code></pre> <p>get_colour_space( (PyClip)arg1 [, (PyTime)time=None]) -&gt; str :</p> <pre><code>Return the colour space at the requested time. Use current_time when no time is supplied.\n</code></pre>"},{"location":"api/classes/PySequence/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyClip)arg1 [, (str)key='' [, (PyTime)time=None]]) -&gt; object :</p> <pre><code>Return the metadata of the clip.\n\nKeywords argument:\n\nkey -- Key of the requested metadata. All metadata is returned when not specified.\n\ntime -- Must be a PyTime. If not specified, the current clip time is used.\n</code></pre>"},{"location":"api/classes/PySequence/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PySequence/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PySequence/#import_subtitles_file","title":"<code>import_subtitles_file</code>","text":"<pre><code>import_subtitles_file\n</code></pre> <p>import_subtitles_file( (PySequence)arg1, (str)file_name [, (object)file_type=None [, (bool)align_first_event_to_clip_start=False [, (object)convert_from_frame_rate=None]]]) -&gt; object :</p> <pre><code>Import a subtitles file into a new Subtitles Track.\n\nReturn the new PySubtitleTrack.\n\nKeyword arguments:\n\nfile_name -- The path and name of the file to import.\n\nfile_type -- The type of subtitle if it is not the file extension (srt or txt).\n\nalign_first_event_to_clip_start -- Force the first event to be aligned with the clip start.\n\nconvert_from_frame_rate -- frame rate of the imported file (for txt files only).\n</code></pre>"},{"location":"api/classes/PySequence/#insert","title":"<code>insert</code>","text":"<pre><code>insert\n</code></pre> <p>insert( (PySequence)arg1, (PyClip)source_clip [, (PyTime)insert_time=None [, (PyTrack)destination_track=None]]) -&gt; bool :</p> <pre><code>Creates a new PySequenceGroup.\n\nThe group name must be supplied as argument.\n</code></pre>"},{"location":"api/classes/PySequence/#is_rendered","title":"<code>is_rendered</code>","text":"<pre><code>is_rendered\n</code></pre> <p>is_rendered( (PyClip)arg1 [, (bool)top_only=False [, (str)render_quality='Full Resolution']]) -&gt; bool :</p> <pre><code>Return if a Clip is rendered.\n\nThe following attributes can be defined: top_only, render_quality.\n</code></pre>"},{"location":"api/classes/PySequence/#lift_selection_to_media_panel","title":"<code>lift_selection_to_media_panel</code>","text":"<pre><code>lift_selection_to_media_panel\n</code></pre> <p>lift_selection_to_media_panel( (PySequence)arg1 [, (PyArchiveEntry)destination=None [, (str)duplicate_action='add']]) -&gt; object :</p> <pre><code>Lift the selection from the sequence.\n\nReturn the new PyClip created from the selection when a destination is supplied.\n\nKeyword arguments:\n\ndestination -- The PyObject that acts as the destination.\n\nduplicate_action -- Action to take when an object with the same name already exists (add or replace).\n</code></pre>"},{"location":"api/classes/PySequence/#open","title":"<code>open</code>","text":"<pre><code>open\n</code></pre> <p>open( (PySequence)arg1) -&gt; bool :</p> <pre><code>Open the Sequence.\n</code></pre>"},{"location":"api/classes/PySequence/#open_as_sequence","title":"<code>open_as_sequence</code>","text":"<pre><code>open_as_sequence\n</code></pre> <p>open_as_sequence( (PyClip)arg1) -&gt; object :</p> <pre><code>Open the Clip as a Sequence. Mutates the PyClip object into a PySequence object.\n</code></pre>"},{"location":"api/classes/PySequence/#open_container","title":"<code>open_container</code>","text":"<pre><code>open_container\n</code></pre> <p>open_container( (PyClip)arg1) -&gt; bool :</p> <pre><code>Open the container timeline if the Clip is inside a container.\n</code></pre>"},{"location":"api/classes/PySequence/#overwrite","title":"<code>overwrite</code>","text":"<pre><code>overwrite\n</code></pre> <p>overwrite( (PySequence)arg1, (PyClip)source_clip [, (PyTime)overwrite_time=None [, (PyTrack)destination_track=None]]) -&gt; bool :</p> <pre><code>Creates a new PySequenceGroup.\n\nThe group name must be supplied as argument.\n</code></pre>"},{"location":"api/classes/PySequence/#reformat","title":"<code>reformat</code>","text":"<pre><code>reformat\n</code></pre> <p>reformat( (PyClip)arg1 [, (int)width=0 [, (int)height=0 [, (float)ratio=0.0 [, (int)bit_depth=0 [, (str)scan_mode='' [, (str)frame_rate='' [, (str)resize_mode='Letterbox']]]]]]]) -&gt; None :</p> <pre><code>Reformat the Clip to the specified format.\n\nKeywords arguments:\n\nwidth -- Integer between 24 and 16384.\n\nheight -- Integer between 24 and 16384.\n\nratio -- Frame aspect ratio. Float between 0.01 and 100.\n\nbit_depth -- Bit depth. (8, 10, 12, 16 or 32)\n\nscan_mode -- Scan mode of the sequence. (F1, F2, P)\n\nframe_rate -- Frame rate. (60 fps, 59.54 NDF, 59.94 DF, 50 fps, 30 fps, 29.97 NDF, 29.97 DF, 25 fps, 24 fps, 23.976 fps)\n\nresize_mode -- Resize mode. (Letterbox, Crop Edges, Fill, Centre)\n</code></pre>"},{"location":"api/classes/PySequence/#render","title":"<code>render</code>","text":"<pre><code>render\n</code></pre> <p>render( (PyClip)arg1 [, (str)render_mode='All' [, (str)render_option='Foreground' [, (str)render_quality='Full Resolution' [, (str)effect_type='' [, (str)effect_caching_mode='Current' [, (bool)include_handles=False]]]]]]) -&gt; bool :</p> <pre><code>Trigger a render of the Clip\n\nThe following attributes can be defined: render_mode, render_option, render_quality, effect_type, effect_caching_mode and include_handles.\n</code></pre>"},{"location":"api/classes/PySequence/#save","title":"<code>save</code>","text":"<pre><code>save\n</code></pre> <p>save( (PyClip)arg1) -&gt; bool :</p> <pre><code>Save the Clip to the defined save destination.\n</code></pre>"},{"location":"api/classes/PySequenceGroup/","title":"Class: PySequenceGroup","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PySequenceGroup/#description","title":"Description","text":"<p>Object representing a Group in a Sequence.</p>"},{"location":"api/classes/PySequenceGroup/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>segments</code> Return a list of the Group's PySegments."},{"location":"api/classes/PySequenceGroup/#methods","title":"Methods","text":""},{"location":"api/classes/PySequenceGroup/#add","title":"<code>add</code>","text":"<pre><code>add\n</code></pre> <p>add( (PySequenceGroup)arg1, (object)segments) -&gt; None :</p> <pre><code>Adds a PySegment or list of PySegments to the Group.\n</code></pre>"},{"location":"api/classes/PySequenceGroup/#remove","title":"<code>remove</code>","text":"<pre><code>remove\n</code></pre> <p>remove( (PySequenceGroup)arg1, (object)segments) -&gt; None :</p> <pre><code>Remove a PySegment or list of PySegments from the Group.\n</code></pre>"},{"location":"api/classes/PySubtitleTrack/","title":"Class: PySubtitleTrack","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTrack, PyFlameObject, instance, object</p>"},{"location":"api/classes/PySubtitleTrack/#description","title":"Description","text":"<p>Object representing a Subtitle Track.</p>"},{"location":"api/classes/PySubtitleTrack/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>segments</code> Return a list of the Track's segments. <code>transitions</code> Return a list of the Track's transitions."},{"location":"api/classes/PySubtitleTrack/#methods","title":"Methods","text":""},{"location":"api/classes/PySubtitleTrack/#copy_to_media_panel","title":"<code>copy_to_media_panel</code>","text":"<pre><code>copy_to_media_panel\n</code></pre> <p>copy_to_media_panel( (PyTrack)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip with a copy of the PyObject.\n</code></pre>"},{"location":"api/classes/PySubtitleTrack/#cut","title":"<code>cut</code>","text":"<pre><code>cut\n</code></pre> <p>cut( (PyTrack)arg1, (PyTime)cut_time [, (bool)sync=False]) -&gt; None :</p> <pre><code>Cut the Track.\n</code></pre>"},{"location":"api/classes/PySubtitleTrack/#export_as_srt_file","title":"<code>export_as_srt_file</code>","text":"<pre><code>export_as_srt_file\n</code></pre> <p>export_as_srt_file( (PySubtitleTrack)arg1, (str)file_name [, (bool)character_based_attributes=True [, (bool)export_colours=False [, (str)exclude_colour='' [, (bool)use_original_colours=False [, (bool)use_original_alignment=False [, (bool)export_alignments=False [, (str)alignment_type='an' [, (str)exclude_alignment='' [, (str)start_timecode='Same as Clip']]]]]]]]]) -&gt; None :</p> <pre><code>Export the Subtitles Track as a SubRip (srt) file.Keyword arguments:\n\nfile_name -- The path and name of the file to write.\n\ncharacter_based_attributes -- Export the bold, italic, and underline attributes.\n\nexport_colours -- Export colours.\n\nexclude_colour -- Specify a colour, in hexadecimal or CSS colour name, to ignore.\n\nuse_original_colours -- Reuse hexadecimal or CSS colour names from the imported file.\n\nuse_original_alignment -- Reuse alignment tokens from the imported file .\n\nexport_alignments -- Export alignments.\n\nalignment_type -- Set to a or an alignment style tokens.\n\nexclude_alignment -- Specify an alignment to ignore.\n\nstart_timecode -- Specify the timecode mode, Same as Clip or, Relative to Clip Start.\n</code></pre>"},{"location":"api/classes/PySubtitleTrack/#insert_transition","title":"<code>insert_transition</code>","text":"<pre><code>insert_transition\n</code></pre> <p>insert_transition( (PyTrack)arg1, (PyTime)record_time, (str)type [, (int)duration=10 [, (str)alignment='Centred' [, (int)in_offset=0 [, (bool)sync=False]]]]) -&gt; object :</p> <pre><code>Insert a Transition on the Track.\n\nReturns the new PyTransition if successful.\n\nKeywords argument:\n\nrecord_time -- Time at which the Transition is inserted.\n\ntype -- Type of the new Transition.\n\nduration -- Duration of the new Transition in frames.\n\nalignment -- Alignment of the new Transition.\n\nin_offset -- Number of frames on left side of the cut in custom alignment.\n\nsync -- Perform the operation on all Tracks part of the sync group.\n</code></pre>"},{"location":"api/classes/PyTime/","title":"Class: PyTime","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyTime/#description","title":"Description","text":"<p>Object representing a time unit</p> <p>PyTime(timecode, frame_rate)</p> <p>PyTime(relative_frame)</p> <p>PyTime(absolute_frame, frame_rate)</p>"},{"location":"api/classes/PyTime/#properties","title":"Properties","text":"Name Description <code>frame</code> Return the absolute frame number. <code>frame_rate</code> Return the object frame rate. <code>relative_frame</code> Return the relative frame number. <code>timecode</code> Return the timecode."},{"location":"api/classes/PyTimeline/","title":"Class: PyTimeline","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyTimeline/#description","title":"Description","text":"<p>This class represents the Timeline.</p>"},{"location":"api/classes/PyTimeline/#properties","title":"Properties","text":"Name Description <code>clip</code> The associated PyClip or PySequence of the Timeline. <code>current_effect</code> The PyTimeline FX currently focused on the timeline. <code>current_marker</code> The PyMarker currently focused on the timeline. <code>current_segment</code> The PySegment currently focused on the timeline. <code>current_transition</code> The PyTransition currently focused on the timeline. <code>type</code> The type of Timeline currently focused."},{"location":"api/classes/PyTimelineFX/","title":"Class: PyTimelineFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTimelineFX/#description","title":"Description","text":"<p>Object representing a Timeline FX.</p>"},{"location":"api/classes/PyTimelineFX/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyTimelineFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyTimelineFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyTimelineFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/","title":"Class: PyTimewarpNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTimewarpNode/#description","title":"Description","text":"<p>Object representing a Timewarp node.</p>"},{"location":"api/classes/PyTimewarpNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyTimewarpNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyTimewarpNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#get_duration_timing","title":"<code>get_duration_timing</code>","text":"<pre><code>get_duration_timing\n</code></pre> <p>get_duration_timing( (PyTimewarpNode)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the timing value for the current frame while in the duration mode.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#get_speed","title":"<code>get_speed</code>","text":"<pre><code>get_speed\n</code></pre> <p>get_speed( (PyTimewarpNode)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the speed attribute at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#get_speed_timing","title":"<code>get_speed_timing</code>","text":"<pre><code>get_speed_timing\n</code></pre> <p>get_speed_timing( (PyTimewarpNode)arg1, (float)frame) -&gt; float :</p> <pre><code>The timing value for the current frame while in the speed mode.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#get_timing","title":"<code>get_timing</code>","text":"<pre><code>get_timing\n</code></pre> <p>get_timing( (PyTimewarpNode)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the timing value at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#set_speed","title":"<code>set_speed</code>","text":"<pre><code>set_speed\n</code></pre> <p>set_speed( (PyTimewarpNode)arg1, (float)frame, (float)new_speed) -&gt; None :</p> <pre><code>Set the speed at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpNode/#set_timing","title":"<code>set_timing</code>","text":"<pre><code>set_timing\n</code></pre> <p>set_timing( (PyTimewarpNode)arg1, (float)frame, (float)new_timing) -&gt; None :</p> <pre><code>Set the timing at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/","title":"Class: PyTimewarpTimelineFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTimelineFX, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTimewarpTimelineFX/#description","title":"Description","text":"<p>Object representing a Timewarp node.</p>"},{"location":"api/classes/PyTimewarpTimelineFX/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyTimewarpTimelineFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyTimewarpTimelineFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#get_duration_timing","title":"<code>get_duration_timing</code>","text":"<pre><code>get_duration_timing\n</code></pre> <p>get_duration_timing( (PyTimewarpTimelineFX)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the timing value for the current frame while in the duration mode.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#get_speed","title":"<code>get_speed</code>","text":"<pre><code>get_speed\n</code></pre> <p>get_speed( (PyTimewarpTimelineFX)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the speed attribute at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#get_speed_timing","title":"<code>get_speed_timing</code>","text":"<pre><code>get_speed_timing\n</code></pre> <p>get_speed_timing( (PyTimewarpTimelineFX)arg1, (float)frame) -&gt; float :</p> <pre><code>The timing value for the current frame while in the speed mode.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#get_timing","title":"<code>get_timing</code>","text":"<pre><code>get_timing\n</code></pre> <p>get_timing( (PyTimewarpTimelineFX)arg1, (float)frame) -&gt; float :</p> <pre><code>Return the timing value at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#set_speed","title":"<code>set_speed</code>","text":"<pre><code>set_speed\n</code></pre> <p>set_speed( (PyTimewarpTimelineFX)arg1, (float)frame, (float)new_speed) -&gt; None :</p> <pre><code>Set the speed at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#set_timing","title":"<code>set_timing</code>","text":"<pre><code>set_timing\n</code></pre> <p>set_timing( (PyTimewarpTimelineFX)arg1, (float)frame, (float)new_timing) -&gt; None :</p> <pre><code>Set the timing at the requested frame.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyTimewarpTimelineFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyTrack/","title":"Class: PyTrack","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTrack/#description","title":"Description","text":"<p>Object representing a Track.</p>"},{"location":"api/classes/PyTrack/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>segments</code> Return a list of the Track's segments. <code>transitions</code> Return a list of the Track's transitions."},{"location":"api/classes/PyTrack/#methods","title":"Methods","text":""},{"location":"api/classes/PyTrack/#copy_to_media_panel","title":"<code>copy_to_media_panel</code>","text":"<pre><code>copy_to_media_panel\n</code></pre> <p>copy_to_media_panel( (PyTrack)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip with a copy of the PyObject.\n</code></pre>"},{"location":"api/classes/PyTrack/#cut","title":"<code>cut</code>","text":"<pre><code>cut\n</code></pre> <p>cut( (PyTrack)arg1, (PyTime)cut_time [, (bool)sync=False]) -&gt; None :</p> <pre><code>Cut the Track.\n</code></pre>"},{"location":"api/classes/PyTrack/#insert_transition","title":"<code>insert_transition</code>","text":"<pre><code>insert_transition\n</code></pre> <p>insert_transition( (PyTrack)arg1, (PyTime)record_time, (str)type [, (int)duration=10 [, (str)alignment='Centred' [, (int)in_offset=0 [, (bool)sync=False]]]]) -&gt; object :</p> <pre><code>Insert a Transition on the Track.\n\nReturns the new PyTransition if successful.\n\nKeywords argument:\n\nrecord_time -- Time at which the Transition is inserted.\n\ntype -- Type of the new Transition.\n\nduration -- Duration of the new Transition in frames.\n\nalignment -- Alignment of the new Transition.\n\nin_offset -- Number of frames on left side of the cut in custom alignment.\n\nsync -- Perform the operation on all Tracks part of the sync group.\n</code></pre>"},{"location":"api/classes/PyTransition/","title":"Class: PyTransition","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTransition/#description","title":"Description","text":"<p>Object representing a Transition.</p>"},{"location":"api/classes/PyTransition/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>in_offset</code> Return the in offset of the Transition. <code>parent</code> The parent object of this object. <code>record_time</code> Return the record time of Transition focus. <code>type</code> Return the Transition type."},{"location":"api/classes/PyTransition/#methods","title":"Methods","text":""},{"location":"api/classes/PyTransition/#set_dissolve_to_from_colour","title":"<code>set_dissolve_to_from_colour</code>","text":"<pre><code>set_dissolve_to_from_colour\n</code></pre> <p>set_dissolve_to_from_colour( (PyTransition)arg1 [, (float)r=0.0 [, (float)g=0.0 [, (float)b=0.0]]]) -&gt; None :</p> <pre><code>Make a dissolve transition dissolve to/from a colour.\n</code></pre>"},{"location":"api/classes/PyTransition/#set_fade_to_from_silence","title":"<code>set_fade_to_from_silence</code>","text":"<pre><code>set_fade_to_from_silence\n</code></pre> <p>set_fade_to_from_silence( (PyTransition)arg1) -&gt; None :</p> <pre><code>Make a fade dip to/from silence.\n</code></pre>"},{"location":"api/classes/PyTransition/#set_transition","title":"<code>set_transition</code>","text":"<pre><code>set_transition\n</code></pre> <p>set_transition( (PyTransition)arg1, (str)type [, (int)duration=10 [, (str)alignment='Centred' [, (int)in_offset=0]]]) -&gt; object :</p> <pre><code>Replace the Transition with another type of Transition.\n\nReturns the new PyTransition if successful.\n\nKeywords argument:\n\ntype -- Type of the new Transition.\n\nduration -- Duration of the new Transition in frames.\n\nalignment -- Alignment of the new Transition.\n\nin_offset -- Number of frames on left side of the cut in custom alignment.\n</code></pre>"},{"location":"api/classes/PyTransition/#slide","title":"<code>slide</code>","text":"<pre><code>slide\n</code></pre> <p>slide( (PyTransition)arg1, (int)offset [, (bool)sync=False]) -&gt; bool :</p> <pre><code>Slide the Transition.\n\nKeywords argument:\n\noffset -- Amount of frames to slide the Transition with.\n\nsync -- Enable to perform the same operation on transitions that belong to the same sync group as the current PyTransition.\n</code></pre>"},{"location":"api/classes/PyTypeFX/","title":"Class: PyTypeFX","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyTimelineFX, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTypeFX/#description","title":"Description","text":"<p>Object representing a Type Timeline FX.</p>"},{"location":"api/classes/PyTypeFX/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>has_maps_cache_media</code> Return whether the Timeline FX has Maps or ML cached media. <code>layers</code> Return the layers list. <code>parent</code> The parent object of this object. <code>type</code> Return the type of the Timeline FX."},{"location":"api/classes/PyTypeFX/#methods","title":"Methods","text":""},{"location":"api/classes/PyTypeFX/#add_layer","title":"<code>add_layer</code>","text":"<pre><code>add_layer\n</code></pre> <p>add_layer( (PyTypeFX)arg1 [, (str)layer_type='Centre']) -&gt; object :</p> <pre><code>Create a new layer.\n\nKeyword argument:\n\nlayer_type -- Must be one of Left, Centre(default), Right, Roll, or Crawl.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#append_type_setup","title":"<code>append_type_setup</code>","text":"<pre><code>append_type_setup\n</code></pre> <p>append_type_setup( (PyTypeFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Append a setup to the current Type setup.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#clear_maps_cache_media","title":"<code>clear_maps_cache_media</code>","text":"<pre><code>clear_maps_cache_media\n</code></pre> <p>clear_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#flush_maps_cache_media","title":"<code>flush_maps_cache_media</code>","text":"<pre><code>flush_maps_cache_media\n</code></pre> <p>flush_maps_cache_media( (PyTimelineFX)arg1) -&gt; bool :</p> <pre><code>Clear the Timeline FX Maps and ML cached media.(Deprecated: Use clear_maps_cache_media instead.)\n</code></pre>"},{"location":"api/classes/PyTypeFX/#load_setup","title":"<code>load_setup</code>","text":"<pre><code>load_setup\n</code></pre> <p>load_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyTimelineFX)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Timeline FX name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#save_setup","title":"<code>save_setup</code>","text":"<pre><code>save_setup\n</code></pre> <p>save_setup( (PyTimelineFX)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#slide_keyframes","title":"<code>slide_keyframes</code>","text":"<pre><code>slide_keyframes\n</code></pre> <p>slide_keyframes( (PyTimelineFX)arg1, (float)offset) -&gt; None :</p> <pre><code>Slide the keyframes the PySegment.\n\nKeywords argument:\n\noffset -- Relative offset to slide the keyframes.\n\nsync -- Enable to perform the same operation on the segments that belong to the same sync group as the current PySegment.\n</code></pre>"},{"location":"api/classes/PyTypeFX/#sync_connected_segments","title":"<code>sync_connected_segments</code>","text":"<pre><code>sync_connected_segments\n</code></pre> <p>sync_connected_segments( (PyTimelineFX)arg1) -&gt; None :</p> <pre><code>Push the Timeline FX to connected segments.\n</code></pre>"},{"location":"api/classes/PyTypeLayer/","title":"Class: PyTypeLayer","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTypeLayer/#description","title":"Description","text":"<p>Object representing a Type Layer.</p>"},{"location":"api/classes/PyTypeLayer/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>type</code> The layer type: Text, Roll, Crawl, or On Path."},{"location":"api/classes/PyTypeNode/","title":"Class: PyTypeNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyTypeNode/#description","title":"Description","text":"<p>Object representing a Type node.</p>"},{"location":"api/classes/PyTypeNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>input_sockets</code> Return a list of the node input sockets names. <code>layers</code> Return the layers list. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyTypeNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyTypeNode/#add_layer","title":"<code>add_layer</code>","text":"<pre><code>add_layer\n</code></pre> <p>add_layer( (PyTypeNode)arg1 [, (str)layer_type='Centre']) -&gt; object :</p> <pre><code>Create a new layer.\n\nKeyword argument:\n\nlayer_type -- Must be one of Left, Centre(default), Right, Roll, or Crawl.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#append_type_setup","title":"<code>append_type_setup</code>","text":"<pre><code>append_type_setup\n</code></pre> <p>append_type_setup( (PyTypeNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Append a setup to the current Type setup.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyTypeNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyUser/","title":"Class: PyUser","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyUser/#description","title":"Description","text":"<p>Object representing a User.</p>"},{"location":"api/classes/PyUser/#properties","title":"Properties","text":"Name Description <code>name</code> User name. <code>nickname</code> User nickname. <code>shortcuts_profile</code> Keyboard Shortcuts profile. Possible values are:   - Flame   - Smoke Classic   - Smoke (FCP 7)   - Lustre"},{"location":"api/classes/PyUsers/","title":"Class: PyUsers","text":"<p>Module: <code>flame</code></p> <p>Inherits from: instance, object</p>"},{"location":"api/classes/PyUsers/#description","title":"Description","text":"<p>Object representing the User manager.</p>"},{"location":"api/classes/PyUsers/#properties","title":"Properties","text":"Name Description <code>current_user</code> The PyUser linked to the current User."},{"location":"api/classes/PyVersion/","title":"Class: PyVersion","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyFlameObject, instance, object</p>"},{"location":"api/classes/PyVersion/#description","title":"Description","text":"<p>Object representing a Version.</p>"},{"location":"api/classes/PyVersion/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>parent</code> The parent object of this object. <code>stereo</code> Return whether or not the Version is stereo. <code>tracks</code> Return a list of the Version's Tracks."},{"location":"api/classes/PyVersion/#methods","title":"Methods","text":""},{"location":"api/classes/PyVersion/#copy_to_media_panel","title":"<code>copy_to_media_panel</code>","text":"<pre><code>copy_to_media_panel\n</code></pre> <p>copy_to_media_panel( (PyVersion)arg1, (PyArchiveEntry)destination [, (str)duplicate_action='add']) -&gt; object :</p> <pre><code>Create a new clip with a copy of the PyObject.\n</code></pre>"},{"location":"api/classes/PyVersion/#create_track","title":"<code>create_track</code>","text":"<pre><code>create_track\n</code></pre> <p>create_track( (PyVersion)arg1 [, (int)track_index=-1 [, (bool)hdr=False]]) -&gt; object :</p> <pre><code>Add a track to the Version.Keywords arguments:\n\ntrack_index -- Index to insert the new track at, -1 to append at the top.\n\nhdr -- Set to True to create an HDR track.\n</code></pre>"},{"location":"api/classes/PyVersion/#import_dolbyvision_xml","title":"<code>import_DolbyVision_xml</code>","text":"<pre><code>import_DolbyVision_xml\n</code></pre> <p>import_DolbyVision_xml( (PyVersion)arg1, (str)file_name [, (str)mode='Include Frame Based Transitions Trims' [, (int)track_index=-1]]) -&gt; object :</p> <pre><code>Add a track to the Version.Keywords arguments:\n\ntrack_index -- Index to insert the new track at, -1 to append at the top.\n\nhdr -- Set to True to create an HDR track.\n</code></pre>"},{"location":"api/classes/PyWorkspace/","title":"Class: PyWorkspace","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyArchiveEntry, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyWorkspace/#description","title":"Description","text":"<p>Object representing a Workspace.</p>"},{"location":"api/classes/PyWorkspace/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>desktop</code> Return the current Desktop. <code>libraries</code> Return the Workspace Libraries. <code>parent</code> The parent object of this object."},{"location":"api/classes/PyWorkspace/#methods","title":"Methods","text":""},{"location":"api/classes/PyWorkspace/#clear_colour","title":"<code>clear_colour</code>","text":"<pre><code>clear_colour\n</code></pre> <p>clear_colour( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Clear the colour of an object in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#commit","title":"<code>commit</code>","text":"<pre><code>commit\n</code></pre> <p>commit( (PyArchiveEntry)arg1) -&gt; None :</p> <pre><code>Commit to disk the Media Panel object or its closest container possible.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#create_library","title":"<code>create_library</code>","text":"<pre><code>create_library\n</code></pre> <p>create_library( (PyWorkspace)arg1, (str)name) -&gt; object :</p> <pre><code>Create a new Library in a Workspace.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#get_wiretap_node_id","title":"<code>get_wiretap_node_id</code>","text":"<pre><code>get_wiretap_node_id\n</code></pre> <p>get_wiretap_node_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap Node ID of the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#get_wiretap_storage_id","title":"<code>get_wiretap_storage_id</code>","text":"<pre><code>get_wiretap_storage_id\n</code></pre> <p>get_wiretap_storage_id( (PyArchiveEntry)arg1) -&gt; str :</p> <pre><code>Return the Wiretap server's storage ID for the Flame object, but only if the object is in the Media Panel.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#replace_desktop","title":"<code>replace_desktop</code>","text":"<pre><code>replace_desktop\n</code></pre> <p>replace_desktop( (PyWorkspace)arg1, (PyDesktop)desktop) -&gt; bool :</p> <pre><code>Replace the Workspace active Desktop with another one.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#set_desktop_reels","title":"<code>set_desktop_reels</code>","text":"<pre><code>set_desktop_reels\n</code></pre> <p>set_desktop_reels( (PyWorkspace)arg1 [, (object)group=None]) -&gt; bool :</p> <pre><code>Set the Desktop Reels view mode.\n</code></pre>"},{"location":"api/classes/PyWorkspace/#set_freeform","title":"<code>set_freeform</code>","text":"<pre><code>set_freeform\n</code></pre> <p>set_freeform( (PyWorkspace)arg1 [, (object)reel=None]) -&gt; bool :</p> <pre><code>Set the Freeform view mode.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/","title":"Class: PyWriteFileNode","text":"<p>Module: <code>flame</code></p> <p>Inherits from: PyRenderNode, PyNode, PyFlameObject, instance, object</p>"},{"location":"api/classes/PyWriteFileNode/#description","title":"Description","text":"<p>Class derived from PyRenderNode. This class represents a WriteFile node.</p>"},{"location":"api/classes/PyWriteFileNode/#properties","title":"Properties","text":"Name Description <code>attributes</code> The attributes of a python object. <code>channels</code> The channels attribute is a list of tuples, where each tuple is made of a socket name and its channel name. <code>input_sockets</code> Return a list of the node input sockets names. <code>output_sockets</code> Return a list of the node output sockets names. <code>parent</code> The parent object of this object. <code>sockets</code> Return a dictionary of the input/output sockets names and their connections."},{"location":"api/classes/PyWriteFileNode/#methods","title":"Methods","text":""},{"location":"api/classes/PyWriteFileNode/#cache_range","title":"<code>cache_range</code>","text":"<pre><code>cache_range\n</code></pre> <p>cache_range( (PyNode)arg1 [, (object)start=None [, (object)end=None]]) -&gt; int :</p> <pre><code>Cache the Node result.\n\nKeyword arguments:\n\nstart -- The first frame of the cache range. The current Batch start frame is used when not specified.\n\nend -- The last frame of the cache range. The current Batch end frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#clear_schematic_colour","title":"<code>clear_schematic_colour</code>","text":"<pre><code>clear_schematic_colour\n</code></pre> <p>clear_schematic_colour( (PyNode)arg1) -&gt; None :</p> <pre><code>Clear the schematic colour of the Node.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#delete","title":"<code>delete</code>","text":"<pre><code>delete\n</code></pre> <p>delete( (PyFlameObject)arg1 [, (bool)confirm=True]) -&gt; bool :</p> <pre><code>Delete the node.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#duplicate","title":"<code>duplicate</code>","text":"<pre><code>duplicate\n</code></pre> <p>duplicate( (PyNode)arg1 [, (bool)keep_node_connections=False]) -&gt; object :</p> <pre><code>Duplicate the node.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#get_metadata","title":"<code>get_metadata</code>","text":"<pre><code>get_metadata\n</code></pre> <p>get_metadata( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the metadata of the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket from which to pull the metadata. The default output is used when not specified.\n\nkey -- key of the requested metadata. All metadata is returned when not specified.\n\nframe -- frame of the requested metadata. The current frame is used when not specified.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#get_resolved_media_path","title":"<code>get_resolved_media_path</code>","text":"<pre><code>get_resolved_media_path\n</code></pre> <p>get_resolved_media_path( (PyWriteFileNode)arg1 [, (bool)show_extension=True [, (bool)translate_path=True [, (object)frame=None]]]) -&gt; object :</p> <pre><code>Return the resolved media path.\n\nKeyword arguments:\n\nshow_extension -- Set True to display the extension.\n\ntranslate_path -- Set True to apply the Media Location Path Translation.\n\nframe -- Pass a frame number, between range_start and range_end, to get the path for that frame.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#load_node_setup","title":"<code>load_node_setup</code>","text":"<pre><code>load_node_setup\n</code></pre> <p>load_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Load a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#output_channel_as_metadata_key","title":"<code>output_channel_as_metadata_key</code>","text":"<pre><code>output_channel_as_metadata_key\n</code></pre> <p>output_channel_as_metadata_key( (PyNode)arg1, (str)channel_name [, (bool)enable=True]) -&gt; None :</p> <pre><code>Enable/Disable the output as metadata of a channel.\n\nKeyword arguments:\n\nchannel_name -- The name of the channel to output in the metadata; the Node name can be omitted.\n\nenable -- True to output metadata, False to stop outputting.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#save_node_setup","title":"<code>save_node_setup</code>","text":"<pre><code>save_node_setup\n</code></pre> <p>save_node_setup( (PyNode)arg1, (str)file_name) -&gt; bool :</p> <pre><code>Save a Node setup. A path and a file name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#set_channel_name","title":"<code>set_channel_name</code>","text":"<pre><code>set_channel_name\n</code></pre> <p>set_channel_name( (PyRenderNode)arg1, (object)channel, (object)name) -&gt; None :</p> <pre><code>Rename a channel, using its index or front channel name as the index key.\n\nKeyword arguments:\n\nchannel -- The channel to rename. Can be the channel index or the current name of the channel's front socket.\n\nname -- The new name of the channel. The type is either a string or a tuple. A Write File node always takes a string. A Render node takes a string or a tuple.\n\nIn a Render node, a string only sets the name of the channel's front socket; the function creates the name of the matte socket by appending '_alpha' to 'name'. In the UI, the channel is flagged 'Sync'. A Write File node has only one socket per channel, and requires only a string to set a socket name.\n\nIn a Render node, a tuple sets the names of the front and matte sockets. In the UI, the channel is not flagged 'Sync'. A Write File node does not accept a tuple.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#set_context","title":"<code>set_context</code>","text":"<pre><code>set_context\n</code></pre> <p>set_context( (PyNode)arg1, (int)index [, (str)socket_name='Default']) -&gt; bool :</p> <pre><code>Set a Context view on a Node socket. An index and a socket name must be defined as arguments.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#set_metadata_discarded","title":"<code>set_metadata_discarded</code>","text":"<pre><code>set_metadata_discarded\n</code></pre> <p>set_metadata_discarded( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (bool)discarded=True]]]) -&gt; None :</p> <pre><code>Discard key from the Node's metadata output.\n\nKeyword arguments:\n\nsocket_name -- The socket on which the discarded status of the metadata must be changed.\n\nkey -- Metadata key to be discarded or restored.\n\ndiscarded -- True to discard the key from the node metadata output, False to restore the key.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#set_metadata_key","title":"<code>set_metadata_key</code>","text":"<pre><code>set_metadata_key\n</code></pre> <p>set_metadata_key( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)name=None]]]) -&gt; None :</p> <pre><code>Rename a metadata key on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to rename the key. The default output is used when not specified.\n\nkey -- The current metadata key name to be renamed.\n\nname -- The new metadata key name. If None, the current key name will revert to its original value.\n</code></pre>"},{"location":"api/classes/PyWriteFileNode/#set_metadata_value","title":"<code>set_metadata_value</code>","text":"<pre><code>set_metadata_value\n</code></pre> <p>set_metadata_value( (PyNode)arg1 [, (str)socket_name='Default' [, (str)key='' [, (object)value=None [, (bool)is_dynamic=False]]]]) -&gt; None :</p> <pre><code>Set the metadata on the Node.\n\nKeyword arguments:\n\nsocket_name -- The socket on which to set the metadata. The default output is used when not specified.\n\nkey -- Metadata key to be set or added.\n\nvalue -- Metadata value to be set or edited for the specified key. If None is specified, the current value will revert to the original value.\n\nis_dynamic -- Set the Metadata value to be resolved dynamically if it contains tokens.\n</code></pre>"},{"location":"api/flame/hooks/","title":"Python Hooks Reference","text":"<p>Source: Autodesk Flame Family 2026 Help | Python Hooks Reference</p>"},{"location":"api/flame/hooks/#overview","title":"Overview","text":"<p>Python Hooks allow you to inject external code to monitor, inspect, or modify Flame's behavior. They are essential for pipeline integration, shot management, and automation.</p> <p>Key Features: -   Location: Hooks are standard Python files (<code>.py</code>) placed in specific directories. -   Discovery: Flame scans these directories and loads any file containing supported hook functions. -   Multiple Definitions: You can define the same hook in multiple files. Flame will execute all of them (usually sequentially or by merging results). -   Blocking: Hooks are blocking and run in the main thread. Use threading for long-running tasks.</p>"},{"location":"api/flame/hooks/#hook-locations","title":"Hook Locations","text":"<p>Flame scans for hooks in the following order (by default):</p> <ol> <li>User:<ul> <li>Linux: <code>/home/&lt;user&gt;/flame/python/</code></li> <li>macOS: <code>/Users/&lt;user&gt;/Library/Preferences/Autodesk/flame/python/</code></li> </ul> </li> <li>Project: <code>/opt/Autodesk/project/&lt;project&gt;/python/</code></li> <li>Application: <code>/opt/Autodesk/&lt;version&gt;/python/</code></li> <li>Shared: <code>/opt/Autodesk/shared/python/</code></li> </ol> <p>Note: You can customize the scan path using the <code>DL_PYTHON_HOOK_PATH</code> environment variable.</p>"},{"location":"api/flame/hooks/#custom-ui-actions","title":"Custom UI Actions","text":"<p>Custom UI Actions allow you to add items to Flame's context menus.</p>"},{"location":"api/flame/hooks/#hook-functions","title":"Hook Functions","text":"Hook Name Context <code>get_main_menu_custom_ui_actions</code> Main Menu (Flame logo) <code>get_media_panel_custom_ui_actions</code> Media Panel (right-click) <code>get_timeline_custom_ui_actions</code> Timeline (right-click) <code>get_batch_custom_ui_actions</code> Batch (right-click) <code>get_action_custom_ui_actions</code> Action/GMask/Image (right-click) <code>get_mediahub_files_custom_ui_actions</code> MediaHub Files <code>get_mediahub_archives_custom_ui_actions</code> MediaHub Archives"},{"location":"api/flame/hooks/#return-format","title":"Return Format","text":"<p>These hooks must return a tuple of dictionaries. Each dictionary represents a menu group or action.</p>"},{"location":"api/flame/hooks/#action-dictionary","title":"Action Dictionary","text":"<pre><code>{\n    \"name\": \"Unique Name\",          # Internal unique name\n    \"caption\": \"Menu Label\",        # (Optional) Visible label\n    \"execute\": my_callback_func,    # Function to run\n    \"isEnabled\": True,              # (Optional) Bool or Function(selection)\n    \"isVisible\": True,              # (Optional) Bool or Function(selection)\n    \"minimumVersion\": \"2025.1\"      # (Optional)\n}\n</code></pre>"},{"location":"api/flame/hooks/#group-dictionary","title":"Group Dictionary","text":"<pre><code>{\n    \"name\": \"My Submenu\",\n    \"actions\": ( action_dict_1, action_dict_2 )\n}\n</code></pre>"},{"location":"api/flame/hooks/#callback-signature","title":"Callback Signature","text":"<p>The <code>execute</code>, <code>isEnabled</code>, and <code>isVisible</code> callbacks receive a single argument: <code>selection</code>. -   <code>selection</code> is a tuple of the selected Python objects (e.g., <code>( &lt;PyClip&gt;, &lt;PySequence&gt; )</code>).</p>"},{"location":"api/flame/hooks/#export-hooks-exporthookpy","title":"Export Hooks (<code>exportHook.py</code>)","text":"<p>These hooks trigger during the export process.</p> <p>Execution Order: 1.  <code>pre_custom_export</code> (If using custom profiles) 2.  <code>pre_export</code> (Export dialog opens) 3.  <code>pre_export_sequence</code> 4.  <code>pre_export_asset</code> (Called per asset) 5.  <code>post_export_asset</code> 6.  <code>post_export_sequence</code> 7.  <code>post_export</code> 8.  <code>post_custom_export</code></p>"},{"location":"api/flame/hooks/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>DL_PYTHON_HOOK_PATH</code>: Colon-separated list of additional paths to scan.</li> <li><code>DL_DEBUG_PYTHON_HOOKS</code>: Set to <code>1</code> to enable verbose logging of hook loading and execution.</li> </ul>"},{"location":"api/flame/module_defines/","title":"Defines for the flame Module","text":"<p>Defines can be set for objects supported in the Python API. These shortcuts allow quick access to commonly used objects within the current context.</p> <p>Source: Autodesk Flame Family 2026 Help | Defines for the flame Module</p> <p>Note: <code>flame.project</code> was changed to <code>flame.projects</code> in the 2020.1 Update version. Both syntaxes are supported, but <code>flame.projects</code> is preferred.</p>"},{"location":"api/flame/module_defines/#global-objects","title":"Global Objects","text":"Object Define PyProject <code>flame.projects.current_project</code> PyWorkspace <code>flame.projects.current_project.current_workspace</code>OR<code>PyProject.current_workspace</code> PyDesktop <code>flame.projects.current_project.current_workspace.desktop</code>OR<code>PyWorkspace.desktop</code> PyBatch <code>flame.projects.current_project.current_workspace.desktop.batch_groups[#]</code>OR<code>flame.batch</code> (current batch)"},{"location":"api/flame/module_defines/#batch-elements","title":"Batch Elements","text":"Object Define PyNode <code>flame.batch.nodes[#]</code><code>flame.batch.current_node</code><code>flame.batch.get_node(\"name\")</code><code>flame.batch.create_node(\"type\")</code> PyBatchIteration <code>flame.batch.batch_iterations[#]</code>"},{"location":"api/flame/module_defines/#media-hierarchy","title":"Media Hierarchy","text":"Object Define PyReelGroup <code>flame.projects.current_project.libraries[#].reel_groups[#]</code><code>flame.projects.current_project.current_workspace.desktop.reel_groups[#]</code> PyReel <code>flame.projects.current_project.current_workspace.libraries[#].reel_groups[#].reels[#]</code><code>flame.projects.current_project.current_workspace.desktop.reel_groups[#].reels[#]</code> PyLibrary <code>flame.projects.current_project.current_workspace.libraries[#]</code> PyFolder <code>flame.projects.current_project.current_workspace.libraries[#].folders[#]</code> PyClip <code>flame.projects.current_project.current_workspace.libraries[#].clips[#]</code><code>flame.projects.current_project.current_workspace.desktop.reel_groups[#].reels[#].clips[#]</code> PySequence <code>flame.projects.current_project.current_workspace.libraries[#].sequences[#]</code><code>flame.projects.current_project.current_workspace.desktop.reel_groups[#].reels[#].sequences[#]</code>"},{"location":"api/flame/module_defines/#sequence-structure","title":"Sequence Structure","text":"Object Define PyVersion <code>PySequence.versions[#]</code> PyTrack <code>PyReel.sequences[#].versions[#].tracks[#]</code> PySegment <code>PyReel.sequences[#].versions[#].tracks[#].segments[#]</code> PyTimelineFX <code>PyReel.sequences[#].versions[#].tracks[#].segments[#].effects[#]</code> PyMarker <code>PyReel.sequences[#].versions[#].tracks[#].segments[#].markers[#]</code><code>PyReel.sequences[#].markers[#]</code> PyAudioTrack <code>PyReel.sequences[#].audio_tracks[#]</code>"},{"location":"api/flame/py_objects/","title":"Flame Python API Object Reference","text":"<p>Source: Autodesk Flame Family 2026 Help | Autodesk Flame Python: flame module</p>"},{"location":"api/flame/py_objects/#core-classes","title":"Core Classes","text":""},{"location":"api/flame/py_objects/#flamepyflameobject","title":"<code>flame.PyFlameObject</code>","text":"<p>The base class for all Flame Python objects. - Attributes:     - <code>attributes</code>: Dictionary of object attributes.     - <code>parent</code>: The parent object.</p>"},{"location":"api/flame/py_objects/#flamepyarchiveentry-inherits-pyflameobject","title":"<code>flame.PyArchiveEntry</code> (Inherits <code>PyFlameObject</code>)","text":"<p>Base class for objects in the Media Panel. - Methods:     - <code>clear_colour()</code>     - <code>commit()</code>: Save changes to disk.     - <code>get_wiretap_node_id()</code>     - <code>get_wiretap_storage_id()</code></p>"},{"location":"api/flame/py_objects/#hierarchy","title":"Hierarchy","text":""},{"location":"api/flame/py_objects/#flamepyproject-inherits-pyarchiveentry","title":"<code>flame.PyProject</code> (Inherits <code>PyArchiveEntry</code>)","text":"<ul> <li>Properties: <code>name</code>, <code>nickname</code>, <code>description</code>, <code>current_workspace</code>, <code>shared_libraries</code>.</li> <li>Methods:<ul> <li><code>create_shared_library(name)</code></li> <li><code>export_ocio_config(...)</code></li> <li><code>reload_ocio_config()</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#flamepyworkspace-inherits-pyarchiveentry","title":"<code>flame.PyWorkspace</code> (Inherits <code>PyArchiveEntry</code>)","text":"<ul> <li>Properties: <code>desktop</code>, <code>libraries</code>.</li> <li>Methods:<ul> <li><code>create_library(name)</code></li> <li><code>set_desktop_reels()</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#flamepydesktop-inherits-pyarchiveentry","title":"<code>flame.PyDesktop</code> (Inherits <code>PyArchiveEntry</code>)","text":"<ul> <li>Properties: <code>batch_groups</code>, <code>reel_groups</code>.</li> <li>Methods:<ul> <li><code>create_batch_group(...)</code></li> <li><code>create_reel_group(name)</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#flamepylibrary-inherits-pyarchiveentry","title":"<code>flame.PyLibrary</code> (Inherits <code>PyArchiveEntry</code>)","text":"<ul> <li>Methods: <code>acquire_exclusive_access()</code>, <code>release_exclusive_access()</code>.</li> </ul>"},{"location":"api/flame/py_objects/#batch","title":"Batch","text":""},{"location":"api/flame/py_objects/#flamepybatch-inherits-pyflameobject","title":"<code>flame.PyBatch</code> (Inherits <code>PyFlameObject</code>)","text":"<p>Represents a Batch Group. - Properties: <code>nodes</code>, <code>reels</code>, <code>shelf_reels</code>, <code>current_iteration</code>. - Methods:     - <code>create_node(type, path)</code>     - <code>connect_nodes(out_node, out_socket, in_node, in_socket)</code>     - <code>import_clip(path, reel)</code>     - <code>organize()</code>     - <code>render()</code>     - <code>save()</code>     - <code>go_to()</code>: Open this batch group.</p>"},{"location":"api/flame/py_objects/#flamepynode-inherits-pyflameobject","title":"<code>flame.PyNode</code> (Inherits <code>PyFlameObject</code>)","text":"<ul> <li>Properties: <code>name</code>, <code>type</code>, <code>pos_x</code>, <code>pos_y</code>, <code>input_sockets</code>, <code>output_sockets</code>.</li> <li>Methods:<ul> <li><code>set_context(index, socket)</code></li> <li><code>delete()</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#specialized-nodes","title":"Specialized Nodes","text":"<ul> <li><code>PyActionNode</code> / <code>PyActionFamilyNode</code>:<ul> <li><code>add_media()</code></li> <li><code>import_fbx()</code>, <code>export_fbx()</code></li> <li><code>create_node()</code> (inside Action schematic)</li> </ul> </li> <li><code>PyWriteFileNode</code>:<ul> <li><code>get_resolved_media_path()</code></li> </ul> </li> <li><code>PyMatchbox</code>: (Accessed via generic PyNode, but has <code>shader_name</code>)</li> <li><code>PyOpenFX</code>: (Accessed via generic PyNode, but has <code>plugin_name</code>)</li> </ul>"},{"location":"api/flame/py_objects/#timeline","title":"Timeline","text":""},{"location":"api/flame/py_objects/#flamepyclip-flamepysequence-inherits-pyarchiveentry","title":"<code>flame.PyClip</code> / <code>flame.PySequence</code> (Inherits <code>PyArchiveEntry</code>)","text":"<ul> <li>Properties: <code>versions</code>, <code>audio_tracks</code>, <code>markers</code>, <code>segments</code>, <code>start_frame</code>, <code>duration</code>.</li> <li>Methods:<ul> <li><code>reformat(...)</code></li> <li><code>render(...)</code></li> <li><code>export(...)</code> (via Exporter)</li> <li><code>open_as_sequence()</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#flamepytrack","title":"<code>flame.PyTrack</code>","text":"<ul> <li>Properties: <code>segments</code>, <code>transitions</code>, <code>stereo_linked</code>.</li> </ul>"},{"location":"api/flame/py_objects/#flamepysegment","title":"<code>flame.PySegment</code>","text":"<ul> <li>Properties: <code>name</code>, <code>record_in</code>, <code>record_out</code>, <code>source_name</code>, <code>file_path</code>.</li> <li>Methods:<ul> <li><code>create_effect(type)</code></li> <li><code>create_marker(frame)</code></li> </ul> </li> </ul>"},{"location":"api/flame/py_objects/#helpers","title":"Helpers","text":""},{"location":"api/flame/py_objects/#flamepytime","title":"<code>flame.PyTime</code>","text":"<p>Represents a time value. - <code>PyTime(\"10:00:00:00\", \"23.976 fps\")</code> - <code>PyTime(frame_int)</code></p>"},{"location":"api/flame/py_objects/#flamepyexporter","title":"<code>flame.PyExporter</code>","text":"<p>Configures export settings. - <code>export(sources, preset_path, out_dir)</code></p>"},{"location":"api/flame/py_objects/#module-functions","title":"Module Functions","text":"<ul> <li><code>flame.execute_shortcut(name)</code></li> <li><code>flame.import_clips(path, dest)</code></li> <li><code>flame.schedule_idle_event(callback)</code></li> </ul>"},{"location":"architecture/overview/","title":"Architecture: FLAME-UTILITIES","text":"<p>The FLAME-UTILITIES suite uses a decoupled bridge architecture consisting of six core components:</p> <ul> <li>fu_bootstrap: The foundational infrastructure layer that resolves paths and enables direct imports across the toolkit, bypassing Flame's <code>__init__.py</code> constraints.</li> <li>fu_eavesdrop (inside Flame): A high-performance JSON-over-TCP service located in <code>service/</code> that executes Python code on the Flame main thread.</li> <li>fu_whisper (MCP Bridge): An AI-native gateway using the Model Context Protocol (MCP) that allows Large Language Models to autonomously interact with the Flame API.</li> <li>fu_relay: The secure communication conduit managing TCP handshakes and data routing.</li> <li>Knowledge Layer (RAG): A vector database (<code>chroma_db</code>) containing Flame API documentation and research insights, accessible via <code>fu_whisper</code>.</li> <li>Audit Logger: A persistent system that captures conversation JSON for security and debugging.</li> </ul>"},{"location":"architecture/overview/#threading-and-execution-model","title":"Threading and Execution Model","text":"<p>All calls to the Flame Python API must be executed on Flame's main UI thread. </p> <p><code>fu_eavesdrop</code> receives code fragments and automatically schedules their execution using <code>flame.schedule_idle_event()</code>. This prevents the application from crashing due to non-thread-safe API access from the background TCP listener thread.</p>"},{"location":"architecture/overview/#the-bootstrap-pattern","title":"The Bootstrap Pattern","text":"<p>Because Autodesk Flame prohibits traditional Python packages, the toolkit uses <code>fu_bootstrap.py</code>. This utility is imported by all internal scripts to: 1.  Discover the absolute location of the <code>flame-utilities</code> folder. 2.  Inject <code>src/</code>, <code>lib/</code>, and <code>service/</code> into <code>sys.path</code>. 3.  Load configuration files from the <code>config/</code> directory.</p>"},{"location":"architecture/overview/#component-map","title":"Component Map","text":"<pre><code>graph TD\n    subgraph External_Tools [External Tools]\n        AI[AI Agent / Cursor / Claude]\n        Whisper[FU_Whisper MCP Bridge]\n        RAG[(RAG Docs)]\n        Log[(Audit Log)]\n    end\n\n    subgraph Communication [Communication Layer]\n        Relay[fu_relay]\n    end\n\n    subgraph Flame_Runtime [Autodesk Flame]\n        Boot[fu_bootstrap Infrastructure]\n        List[fu_eavesdrop Listener]\n        API[Flame Python API]\n    end\n\n    AI -- Tool Call --&gt; Whisper\n    Whisper -- Query --&gt; RAG\n    Whisper -- Write JSON --&gt; Log\n    Whisper -- JSON/TCP --&gt; Relay\n    Relay -- JSON/TCP --&gt; List\n    List -- Bootstrap Path --&gt; Boot\n    List -- Main Thread Dispatch --&gt; API\n    API -- Results --&gt; List\n    List -- JSON --&gt; Relay\n    Relay -- Results --&gt; Whisper\n</code></pre> <p>Note: The legacy VS Code Extension has been moved to <code>unused/</code>.</p>"},{"location":"architecture/protocol/","title":"Communication Protocol: fu_relay","text":"<p>The fu_relay layer manages the JSON-over-TCP communication between external tools and the internal Flame listener.</p>"},{"location":"architecture/protocol/#transport","title":"Transport","text":"<ul> <li>TCP Socket (127.0.0.1): Default transport for cross-platform stability.</li> <li>Default Port: 5555.</li> </ul>"},{"location":"architecture/protocol/#message-format","title":"Message format","text":""},{"location":"architecture/protocol/#client-fu_eavesdrop-json","title":"Client \u2192 fu_eavesdrop (JSON)","text":"<pre><code>{\n  \"command\": \"execute\",\n  \"id\": \"uuid-v4-string\",\n  \"token\": \"your-security-token\",\n  \"code\": \"import flame; print(flame.project.current_project.name)\",\n  \"timeout\": 5.0\n}\n</code></pre>"},{"location":"architecture/protocol/#fu_eavesdrop-client-json-response","title":"fu_eavesdrop \u2192 Client (JSON response)","text":"<pre><code>{\n  \"id\": \"matching-uuid-v4\",\n  \"stdout\": \"Project_Name\\n\",\n  \"stderr\": \"\",\n  \"exception\": null\n}\n</code></pre>"},{"location":"architecture/protocol/#available-commands","title":"Available Commands","text":"<ul> <li><code>execute</code>: Executes the provided Python code on the Flame main thread. Returns stdout, stderr, and any exception name.</li> <li><code>ping</code>: Returns <code>pong</code> if the listener is alive. Used by fu_whisper to verify connection.</li> <li><code>start_debug_server</code>: Launches an in-process <code>debugpy</code> adapter for remote debugging.</li> </ul>"},{"location":"architecture/protocol/#error-handling","title":"Error Handling","text":"<ul> <li>ConnectionRefusedError: <code>fu_eavesdrop</code> is not running or port is blocked.</li> <li>TimeoutError: The Python code took longer than the requested <code>timeout</code> (default 5s).</li> <li>AuthError: The provided <code>token</code> is missing or incorrect.</li> </ul>"},{"location":"development/api_reports/","title":"How to Generate Flame API Reports","text":"<p>This guide explains how to systematically crawl the running Autodesk Flame Python API to generate detailed JSON reports of all available modules, classes, functions, and properties.</p> <p>Target Audience: Developers and AI Agents (Gemini).</p>"},{"location":"development/api_reports/#prerequisites","title":"Prerequisites","text":"<ol> <li>Autodesk Flame must be running.</li> <li>The fu_eavesdrop listener must be deployed and active.<ul> <li>Check: You should see <code>fu_eavesdrop listening on 127.0.0.1:5555</code> in the Flame console.</li> </ul> </li> <li>Deploy: If not running, follow the instructions in <code>docs/setup/deploy.md</code>.</li> </ol>"},{"location":"development/api_reports/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"development/api_reports/#1-run-the-collector-script","title":"1. Run the Collector Script","text":"<p>Open a terminal in the repository root and run:</p> <pre><code>python scripts/collect_flame_api.py --include-all\n</code></pre> <ul> <li><code>--include-all</code>: Forces the script to inspect every discovered symbol (classes, functions, singletons) instead of just the core <code>Py*</code> classes.</li> </ul>"},{"location":"development/api_reports/#2-locate-the-output","title":"2. Locate the Output","text":"<p>The script creates a timestamped directory for each run:</p> <pre><code>reports/api_dump/YYYY-MM-DD_HH-MM-SS/\n</code></pre> <p>Inside you will find: *   <code>index.json</code>: A summary of all crawled items. *   <code>&lt;SymbolName&gt;.json</code>: Detailed introspection for each object (e.g., <code>PyBatch.json</code>, <code>execute_command.json</code>).</p>"},{"location":"development/api_reports/#3-generate-type-stubs-optional-but-recommended","title":"3. Generate Type Stubs (Optional but Recommended)","text":"<p>To update the IDE autocompletion and type checking files, run:</p> <pre><code>python scripts/generate_stubs_from_reports.py --latest\n</code></pre> <p>This will update <code>stubs/flame.pyi</code> with the signatures and docstrings extracted from the latest crawl.</p>"},{"location":"development/api_reports/#instructions-for-ai-agents-gemini","title":"Instructions for AI Agents (Gemini)","text":"<p>If you are an AI assistant tasked with updating the API definitions or checking for version compatibility, follow this protocol:</p> <ol> <li>Verify Connection:     Run a ping check via the fu_whisper bridge or use <code>nc -zv 127.0.0.1 5555</code>.</li> <li>Execute Crawl:     Run <code>python scripts/collect_flame_api.py --include-all</code>.</li> <li>Ingest Results:     Read the generated <code>reports/api_dump/&lt;latest_timestamp&gt;/index.json</code> to understand the scope.     Read specific <code>&lt;Symbol&gt;.json</code> files to update your internal knowledge or generate type stubs (<code>.pyi</code>).</li> </ol>"},{"location":"development/api_reports/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Connection Refused: <code>fu_eavesdrop</code> is not running in Flame. Check <code>flame.project.json</code> or your manual deployment.</li> <li>Timeout: The API might be busy. The script waits 10s per request. Ensure Flame is not blocked by a modal dialog.</li> </ul>"},{"location":"development/extension_dev/","title":"Extension development \u2014 quick start","text":"<p>Follow these steps to run and debug the Flame VS Code extension locally.</p>"},{"location":"development/extension_dev/#run-in-extension-development-host-fast","title":"Run in Extension Development Host (fast)","text":"<ol> <li>Open this repository in VS Code.</li> <li>Open the <code>extension/</code> folder in the Explorer.</li> <li>Press <code>F5</code> (Run \u2192 Start Debugging) to launch the Extension Development Host.</li> <li>In the host window, open the Command Palette and run:</li> <li><code>Flame: Connect</code> to connect to the fu_eavesdrop listener,</li> <li><code>Flame: Start debug server</code> to request Flame start a debug server,</li> <li><code>Flame: Run in Flame</code> to send the current file/selection to Flame.</li> </ol>"},{"location":"development/extension_dev/#development-virtual-environment","title":"Development virtual environment","text":"<p>We recommend using a system Python virtual environment for running tests and development tools.</p> <p>Quick setup:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npython -m pip install -r requirements.txt\n</code></pre>"},{"location":"development/extension_dev/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>FLAME_TOKEN</code>: Your security token for connecting to the listener.</li> <li><code>FLAME_READ_ONLY</code>: If <code>true</code>, the fu_whisper bridge will block destructive commands.</li> <li><code>FLAME_LISTENER_LOG</code>: Path to the listener log (defaults to <code>/tmp/fu_eavesdrop.log</code>).</li> </ul>"},{"location":"development/extension_dev/#build-package","title":"Build &amp; package","text":"<ul> <li>Install deps: <code>npm ci</code> (in <code>extension/</code>).</li> <li>Build: <code>npm run compile</code>.</li> <li>Package: <code>npx vsce package</code> to produce a <code>.vsix</code>.</li> </ul>"},{"location":"development/extension_dev/#component-testing","title":"Component Testing","text":"<ul> <li>fu_eavesdrop: Run <code>tests/test_listener_robustness.py</code>.</li> <li>fu_whisper: Run <code>python flame-mcp/fu_whisper.py</code> and test with Claude Desktop.</li> <li>Mock Server: Use <code>tests/mock_flame_server.py</code> for CI testing without Flame.</li> </ul>"},{"location":"development/stubs/","title":"Flame API Stubs","text":"<p>VS Code cannot inspect Flame's embedded Python interpreter at design time. To provide IntelliSense, autocompletion, and hover documentation, we ship high-quality <code>.pyi</code> stub files.</p>"},{"location":"development/stubs/#generation-pipeline","title":"Generation Pipeline","text":"<p>We use a two-phase automated pipeline to ensure the stubs are always accurate and up-to-date with your current Flame version.</p>"},{"location":"development/stubs/#1-json-report-collection","title":"1. JSON Report Collection","text":"<p>The first step is to crawl the running Flame API using <code>scripts/collect_flame_api.py</code>. This script uses deep introspection to capture: - Class hierarchies and inheritance. - Method signatures and parameter default values. - Property descriptions and docstrings. - Global managers (singletons) and utility functions.</p>"},{"location":"development/stubs/#2-stub-generation","title":"2. Stub Generation","text":"<p>Once the JSON reports are gathered, <code>scripts/generate_stubs_from_reports.py</code> parses the reports and generates a consolidated <code>stubs/flame.pyi</code> file.</p> <p>This script is highly specialized for Flame's Boost.Python implementation, extracting signatures directly from docstrings when standard introspection is blocked by the C++ bridge.</p>"},{"location":"development/stubs/#how-to-update-stubs","title":"How to Update Stubs","text":"<p>If you upgrade Flame or want to ensure your stubs are fresh:</p> <pre><code># 1. Gather latest API data from a running Flame instance\npython scripts/collect_flame_api.py --include-all\n\n# 2. Generate the .pyi file from the reports\npython scripts/generate_stubs_from_reports.py --latest\n</code></pre>"},{"location":"development/stubs/#using-stubs-in-vs-code","title":"Using Stubs in VS Code","text":"<p>The <code>flame-vscode</code> extension automatically configures the environment to use these stubs. If you are developing scripts locally without the extension, add the <code>stubs/</code> directory to your <code>python.analysis.extraPaths</code> setting.</p>"},{"location":"goals/flame-comfyui-bridge/","title":"Goal: Flame-to-ComfyUI Bridge (PyBox v3.13)","text":""},{"location":"goals/flame-comfyui-bridge/#objective","title":"Objective","text":"<p>Develop a production-grade bridge that enables Autodesk Flame to utilize ComfyUI as a generative AI processing engine. This bridge will use the <code>fu_pybox_v3.13</code> SDK as the primary interface, allowing Flame artists to trigger AI workflows (e.g., automated in-painting, texture generation, upscaling) directly from the Batch or Timeline environments.</p>"},{"location":"goals/flame-comfyui-bridge/#rationale","title":"Rationale","text":"<ul> <li>Native Integration: PyBox is Flame's established method for integrating external processors into the compositing pipeline.</li> <li>High Fidelity: By using the Python 3.13 SDK, we can maintain 16-bit Float OpenEXR data paths, essential for professional VFX.</li> <li>Stateless Synergy: Both PyBox and the ComfyUI API operate on a stateless, JSON-driven model, making them architecturally compatible.</li> <li>Automation: Leveraging <code>fu_whisper</code> and <code>fu_comfyui.py</code> allows for automated AI workflows that feel like native Flame nodes.</li> </ul>"},{"location":"goals/flame-comfyui-bridge/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"goals/flame-comfyui-bridge/#1-pybox-handler-development","title":"1. PyBox Handler Development","text":"<ul> <li>[ ] <code>fu_comfyui_handler.py</code>: Create a modern PyBox v3.13 handler that:<ul> <li>Sets up EXR input/output sockets.</li> <li>Provides a UI for selecting ComfyUI workflow templates.</li> <li>Includes a \"Trigger\" button (Global Element) to submit the prompt to ComfyUI.</li> <li>Monitors execution status and notifies Flame upon completion.</li> </ul> </li> </ul>"},{"location":"goals/flame-comfyui-bridge/#2-comfyui-side-integration","title":"2. ComfyUI Side Integration","text":"<ul> <li>[ ] Flame-Aware Nodes: Identify or create custom ComfyUI nodes that:<ul> <li>Read OpenEXR files from specific paths (preserving HDR range).</li> <li>Auto-save results to the \"Result\" paths defined by the PyBox JSON payload.</li> </ul> </li> <li>[ ] Metadata Passthrough: Ensure Flame metadata (Shot Name, Project Name) is passed to ComfyUI for organizational purposes.</li> </ul>"},{"location":"goals/flame-comfyui-bridge/#3-orchestration-communication","title":"3. Orchestration &amp; Communication","text":"<ul> <li>[ ] Backend Relay: Use <code>fu-comfyui/fu_comfyui.py</code> to handle the HTTP/WebSocket handshake between the PyBox handler and the ComfyUI server.</li> <li>[ ] Shared Storage Setup: Standardize the use of a shared NVMe/RAM disk \"Drop Zone\" for frame exchange between the Flame workstation and the AI worker.</li> </ul>"},{"location":"goals/flame-comfyui-bridge/#4-workflow-library","title":"4. Workflow Library","text":"<ul> <li>[ ] Templates: Create a set of base <code>.json</code> workflows for ComfyUI specifically tuned for Flame:<ul> <li>AI Clean Plate: Automated removal of objects using masks.</li> <li>Background Extender: Out-painting for ratio changes.</li> <li>Texture Synthesizer: Generating tileable textures from selection.</li> </ul> </li> </ul>"},{"location":"goals/flame-comfyui-bridge/#success-metrics","title":"Success Metrics","text":"<ul> <li>A Flame artist can add a PyBox node, select \"fu_comfyui_handler.py\", and see a generated AI result in the Result View (F4).</li> <li>Preservation of full dynamic range (no clipping) from Flame -&gt; ComfyUI -&gt; Flame.</li> <li>Successful round-trip execution in under 10 seconds for a 2K frame (hardware permitting).</li> </ul>"},{"location":"goals/flame-encyclopedia-rag/","title":"Goal: FU_Encyclopedia (Knowledge RAG)","text":""},{"location":"goals/flame-encyclopedia-rag/#objective","title":"Objective","text":"<p>Create <code>fu_encyclopedia.py</code> to act as the \"Intelligence Layer\" for the FLAME-UTILITIES ecosystem. It will provide semantic search capabilities over the vast amount of synthesized documentation and API stubs, allowing AI agents to find precise workflow details without consuming the entire context window.</p>"},{"location":"goals/flame-encyclopedia-rag/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Semantic Indexing: Index all Markdown files in <code>docs/</code> and Python stubs in <code>stubs/</code>.</li> <li>Knowledge Retrieval: Provide a tool for <code>fu_whisper</code> to perform semantic queries (e.g., \"Find the method for tagging ARRI LogC4 in a Pybox\").</li> <li>Version Awareness: Index version-specific quirks extracted from the research docs.</li> <li>Vertex AI Integration: Utilize <code>vertexai.preview.rag</code> for corpus management and high-quality embeddings (<code>text-embedding-005</code>).</li> </ul>"},{"location":"goals/flame-encyclopedia-rag/#technical-implementation-fu_encyclopediapy","title":"Technical Implementation (fu_encyclopedia.py)","text":"<ul> <li>Corpus Management: Functions to create and update the <code>RagCorpus</code>.</li> <li>File Upload: Automated scripts to sync the local <code>docs/</code> directory with the Vertex AI RAG backend.</li> <li>Retrieval Logic: Implementation of <code>rag.retrieval_query</code> to return relevant contexts to the LLM.</li> </ul>"},{"location":"goals/flame-encyclopedia-rag/#integration-with-fu_whisper","title":"Integration with FU_Whisper","text":"<ul> <li><code>fu_whisper.py</code> will be updated to include a new tool: <code>search_flame_encyclopedia(query: str)</code>.</li> <li>When a user asks a complex question, the AI will first query the encyclopedia, retrieve the relevant documentation snippets, and then execute the appropriate Flame commands.</li> </ul>"},{"location":"goals/flame-encyclopedia-rag/#success-metrics","title":"Success Metrics","text":"<ul> <li>Reduction in token usage by only providing relevant documentation snippets.</li> <li>Higher accuracy in generating complex multi-node Batch setups.</li> <li>Ability to answer \"how-to\" questions that aren't explicitly in the prompt.</li> </ul>"},{"location":"goals/flame-mcp-creation/","title":"Goal: The Flame-MCP Bridge","text":""},{"location":"goals/flame-mcp-creation/#vision","title":"Vision","text":"<p>To evolve <code>VSCODE-CONNECT-TO-FLAME</code> from a developer-centric toolset into an AI-native ecosystem. By implementing a Model Context Protocol (MCP) server, we allow Large Language Models (LLMs) to interact with Autodesk Flame as if they were a local user, enabling autonomous scripting, live inspection, and real-time debugging.</p>"},{"location":"goals/flame-mcp-creation/#1-architecture-the-bridge-pattern","title":"1. Architecture: The Bridge Pattern","text":"<p>The implementation will follow a \"Relay\" architecture, utilizing the existing infrastructure.</p> <ol> <li>AI Client: (Claude Desktop, Cursor, Gemini) sends a request.</li> <li>MCP Server (New): A Python process using <code>fastmcp</code> that interprets the AI's intent and translates it into Flame-specific commands.</li> <li>Flame Listener (Existing): Receives the Python code from the MCP server and executes it safely on Flame's main thread.</li> <li>Autodesk Flame: The host environment performing the actual work.</li> </ol> <pre><code>graph LR\n    A[AI Client] --&gt; B[MCP Server]\n    B --&gt; C[Flame Listener]\n    C --&gt; D[Flame API]\n</code></pre>"},{"location":"goals/flame-mcp-creation/#2-implementation-strategy","title":"2. Implementation Strategy","text":""},{"location":"goals/flame-mcp-creation/#a-technology-stack","title":"A. Technology Stack","text":"<ul> <li>Language: Python 3.9+ (matching Flame's environment).</li> <li>Framework: <code>fastmcp</code> for rapid tool definition.</li> <li>Communication: <code>requests</code> or <code>httpx</code> to talk to the existing <code>flame-listener</code> REST/Socket endpoint.</li> </ul>"},{"location":"goals/flame-mcp-creation/#b-core-toolset-phase-1","title":"B. Core Toolset (Phase 1)","text":"<p>The AI should have access to these primary \"skills\":</p> Tool Name Description Example AI Use Case <code>flame_exec</code> Executes raw Python code in Flame. \"Fix the indentation in the current script.\" <code>get_context</code> Returns current Project/User/Workspace. \"Which project am I currently working in?\" <code>list_media</code> Lists clips in the current Desktop/Batch. \"Find all clips labeled 'RETAKE'.\" <code>inspect_api</code> Queries Flame's internal <code>dir()</code> for symbols. \"What properties does a <code>PySegment</code> have?\""},{"location":"goals/flame-mcp-creation/#3-high-level-implementation-plan","title":"3. High-Level Implementation Plan","text":""},{"location":"goals/flame-mcp-creation/#step-1-scaffold-the-mcp-server","title":"Step 1: Scaffold the MCP Server","text":"<p>Create a dedicated directory <code>flame-mcp/</code> containing a <code>server.py</code>. This server will run independently of Flame but on the same network.</p>"},{"location":"goals/flame-mcp-creation/#step-2-define-the-relay-logic","title":"Step 2: Define the \"Relay\" Logic","text":"<p>Implement a standard execution wrapper that sends code to the listener:</p> <pre><code>def relay_to_flame(code: str):\n    # Sends code to localhost:5555\n    # Returns stdout/stderr\n</code></pre>"},{"location":"goals/flame-mcp-creation/#step-3-tool-exposure","title":"Step 3: Tool Exposure","text":"<p>Decorate functions with <code>@mcp.tool()</code> to make them visible to the LLM.</p>"},{"location":"goals/flame-mcp-creation/#4-key-benefits","title":"4. Key Benefits","text":""},{"location":"goals/flame-mcp-creation/#autonomous-refactoring","title":"Autonomous Refactoring","text":"<p>Instead of the developer copying code from an AI chat into a file and then running it, the AI can: 1.  Read the current script from Flame. 2.  Rewrite it for optimization. 3.  Push it back into Flame and run it to verify success.</p>"},{"location":"goals/flame-mcp-creation/#intelligent-api-discovery","title":"Intelligent API Discovery","text":"<p>Since the Flame API is proprietary and sometimes poorly documented, the AI can \"explore\" the API live. If it's unsure how to delete a marker, it can run a tool to inspect the <code>flame.PyMarker</code> class dynamically.</p>"},{"location":"goals/flame-mcp-creation/#visual-reasoning-future","title":"Visual Reasoning (Future)","text":"<p>By adding a <code>take_screenshot</code> tool, the AI can \"see\" the Flame UI, allowing it to assist with UI-heavy tasks like layout alignment or finding specific buttons in the Batch schematic.</p>"},{"location":"goals/flame-mcp-creation/#5-security-safety-hitl","title":"5. Security &amp; Safety (HITL)","text":"<p>To ensure the AI doesn't accidentally delete a whole project, we will maintain a Human-In-The-Loop (HITL) approach: *   The MCP server will log every command it sends to Flame. *   Destructive commands (e.g., <code>flame.delete</code>) will require a confirmation flag or be restricted to specific \"Sandbox\" volumes.</p>"},{"location":"goals/flame-sharp-3d-integration/","title":"Goal: SHARP 3D Integration (Single-Image to 3D)","text":""},{"location":"goals/flame-sharp-3d-integration/#objective","title":"Objective","text":"<p>Integrate Apple's SHARP (Sharp Monocular View Synthesis) research model into Autodesk Flame using the <code>fu_pybox_v3_13</code> SDK. This will allow Flame artists to generate high-quality 3D Gaussian Splatting data or detailed depth maps from a single 2D source frame directly within the Batch schematic.</p>"},{"location":"goals/flame-sharp-3d-integration/#rationale","title":"Rationale","text":"<ul> <li>Instant Pre-viz: SHARP can reconstruct a 3D scene in under a second, providing immediate spatial context for VFX artists.</li> <li>Enhanced Relighting: Extracting high-fidelity monocular depth allows for more accurate relighting in Flame's Action node.</li> <li>Set Extensions: Rapidly generate turntable references or multiview frames for background extensions without a full photogrammetry session.</li> <li>Local AI Utilization: Leverages the GPU power of the Flame workstation (MPS on Mac or CUDA on Linux) without needing cloud dependencies.</li> </ul>"},{"location":"goals/flame-sharp-3d-integration/#technical-strategy","title":"Technical Strategy","text":"<ul> <li>Decoupled Worker: Run the SHARP inference engine in a standalone environment to manage heavy dependencies (PyTorch).</li> <li>PyBox Interface: Use a v3.13 handler to provide the UI, handle the EXR input, and read the generated 3D data back into the pipeline.</li> <li>Data Contract: Prioritize the export of 16-bit Depth Maps and PLY Point Clouds which are natively supported by Flame's Action node.</li> </ul>"},{"location":"goals/flame-sharp-3d-integration/#success-metrics","title":"Success Metrics","text":"<ul> <li>Successful generation of a PLY point cloud from a single EXR frame inside a PyBox node.</li> <li>Sub-2-second round-trip for \"Draft\" quality reconstruction.</li> <li>Consistent metadata tracking (focal length, shot name) from Flame through to the AI output.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/","title":"Goal: FLAME-UTILITIES Rebrand (Phase 1)","text":""},{"location":"goals/flame-utilities-rebrand/#vision","title":"Vision","text":"<p>To establish a cohesive, professional identity for our suite of Autodesk Flame tools under the <code>FLAME-UTILITIES</code> (<code>fu_</code>) namespace. This rebrand moves away from generic technical names toward a metaphorical and memorable naming convention that reflects the role of each component.</p> <ul> <li><code>fu_eavesdrop</code> (formerly <code>flame_listener</code>): The component that sits inside Flame, \"listening\" for incoming instructions and \"overhearing\" the internal API state.</li> <li><code>fu_whisper</code> (formerly <code>flame-mcp</code> bridge): The external component that \"whispers\" Python commands into Flame's ear via the listener.</li> <li><code>fu_relay</code> (formerly <code>relay</code>): The secure communication conduit between the two.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/#1-architectural-impact","title":"1. Architectural Impact","text":"<p>The core logic remains unchanged, but the Namespace and Public Identity of the tools are unified. This prevents naming collisions with other hooks and makes the toolkit instantly recognizable to pipeline engineers.</p>"},{"location":"goals/flame-utilities-rebrand/#2-rebrand-tasks","title":"2. Rebrand Tasks","text":""},{"location":"goals/flame-utilities-rebrand/#phase-a-listener-rebrand-flame-listener","title":"Phase A: Listener Rebrand (<code>flame-listener/</code>)","text":"<ul> <li>[x] Rename <code>flame_listener.py</code> to <code>fu_eavesdrop.py</code>.</li> <li>[x] Rename <code>startup_flame_listener.py</code> to <code>fu_eavesdrop_init.py</code>.</li> <li>[x] Rename <code>start_server</code> function to <code>initialize_eavesdrop</code>.</li> <li>[x] Update <code>fu_eavesdrop_init.py</code> to import <code>initialize_eavesdrop</code> from <code>fu_eavesdrop</code>.</li> <li>[x] Update internal logs in <code>fu_eavesdrop.py</code> to use the <code>[fu_eavesdrop]</code> prefix.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/#phase-b-bridge-rebrand-flame-mcp","title":"Phase B: Bridge Rebrand (<code>flame-mcp/</code>)","text":"<ul> <li>[ ] Rename <code>relay.py</code> to <code>fu_relay.py</code>.</li> <li>[ ] Rename <code>server.py</code> to <code>fu_whisper.py</code>.</li> <li>[ ] Update <code>fu_whisper.py</code> to:<ul> <li>Import <code>FlameRelay</code> from <code>fu_relay</code>.</li> <li>Change the MCP server name to <code>FU_Whisper</code>.</li> </ul> </li> <li>[ ] Update <code>requirements.txt</code> if necessary.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/#phase-c-documentation-configuration","title":"Phase C: Documentation &amp; Configuration","text":"<ul> <li>[ ] Update <code>flame-mcp/GETTING_STARTED.md</code> with new file paths and names.</li> <li>[ ] Update <code>flame-mcp/README.md</code>.</li> <li>[ ] Update the root <code>docs/tasks/flame-mcp-bridge-tasks.md</code> to reflect the new nomenclature.</li> <li>[ ] Update <code>GEMINI.md</code> to reflect the current architectural names.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/#phase-d-deployment-verification","title":"Phase D: Deployment &amp; Verification","text":"<ul> <li>[ ] Update the manual deployment instructions for Flame hooks.</li> <li>[ ] Verify the end-to-end connection: <code>AI -&gt; fu_whisper -&gt; fu_relay -&gt; fu_eavesdrop -&gt; Flame</code>.</li> <li>[ ] Confirm audit logs in <code>fu_whisper</code> are correctly capturing the new names.</li> </ul>"},{"location":"goals/flame-utilities-rebrand/#3-future-roadmap","title":"3. Future Roadmap","text":"<p>Once the core branding is established, all future tools in the <code>flame-utilities/</code> directory will follow the <code>fu_&lt;action&gt;.py</code> convention, ensuring a clean and predictable API for both humans and AI agents.</p>"},{"location":"goals/grand-consolidation/","title":"Goal: The Grand Consolidation [COMPLETE]","text":""},{"location":"goals/grand-consolidation/#status-completed-feb-2026","title":"Status: \u2705 Completed (Feb 2026)","text":"<p>This goal has been fully realized. All core components are now unified within the <code>flame-utilities/</code> and <code>fu-whisper/</code> hierarchies.</p>"},{"location":"goals/grand-consolidation/#vision","title":"Vision","text":"<p>To transform <code>FLAME-UTILITIES</code> into a self-contained, portable toolkit that can be archived and restored alongside Autodesk Flame projects. By moving all listener and AI bridge logic into a single directory hierarchy, we ensure that project-specific automation never breaks due to workstation-level changes.</p>"},{"location":"goals/grand-consolidation/#1-architectural-pivot-project-centric-deployment","title":"1. Architectural Pivot: Project-Centric Deployment","text":"<p>Instead of global workstation hooks, the entire <code>flame-utilities/</code> folder is copied into: <code>&lt;Flame_Project_Path&gt;/setups/python/flame-utilities/</code></p> <p>A robust launcher (<code>fu_activate.py</code>) in the parent directory leverages the Bootstrap Pattern to \"ignite\" the tools.</p>"},{"location":"goals/grand-consolidation/#2-structural-consolidation-initial-phase","title":"2. Structural Consolidation (Initial Phase)","text":"Old Location New Location Purpose <code>flame-listener/fu_eavesdrop.py</code> <code>flame-utilities/service/fu_eavesdrop.py</code> The Listener Logic <code>flame-listener/fu_eavesdrop_init.py</code> <code>flame-utilities/service/fu_eavesdrop_init.py</code> The Hook Entry Point <code>flame-listener/generate_stubs.py</code> <code>flame-utilities/scripts/fu_generate_stubs.py</code> Maintenance <code>flame-mcp/</code> <code>fu-whisper/</code> The AI Bridge Hierarchy"},{"location":"goals/grand-consolidation/#3-subsequent-evolution","title":"3. Subsequent Evolution","text":"<p>Following the consolidation, the toolkit underwent a major Project Structure Refactoring (see <code>docs/goals/project-structure-refactoring.md</code>) which implemented: *   The Bootstrap Pattern for path management. *   Flattening of the <code>src/</code> directory for cleaner imports. *   Consolidation of background services into <code>service/</code>.</p>"},{"location":"goals/grand-consolidation/#4-key-deliverables","title":"4. Key Deliverables","text":"<ol> <li>Consolidated Directory: All logic under <code>flame-utilities/</code>. \u2705</li> <li>Portable Loader: <code>fu_activate.py</code> leveraging <code>fu_bootstrap.py</code>. \u2705</li> <li>Updated Automation: <code>deploy_to_flame_project.py</code> handles the new layout. \u2705</li> </ol>"},{"location":"goals/project-structure-refactoring/","title":"Goal: Project Structure Refactoring","text":""},{"location":"goals/project-structure-refactoring/#vision","title":"Vision","text":"<p>To evolve the <code>flame-utilities</code> directory into a professional, scalable, and robust architecture that respects Autodesk Flame's unique constraints (no <code>__init__.py</code> files) while providing a cleaner developer experience. This refactor aims to eliminate \"root clutter\" and standardize how the toolkit \"ignites\" itself within the Flame environment.</p>"},{"location":"goals/project-structure-refactoring/#1-architectural-pivot-the-bootstrap-pattern","title":"1. Architectural Pivot: The Bootstrap Pattern","text":"<p>Since Flame prohibits traditional Python packages, we will implement a Bootstrap Pattern. A single, authoritative <code>fu_bootstrap.py</code> will be responsible for resolving the toolkit's root and injecting all necessary subdirectories into <code>sys.path</code>. </p>"},{"location":"goals/project-structure-refactoring/#the-reasoning-why-bootstrap","title":"The Reasoning: Why Bootstrap?","text":"<p>Currently, every major script (e.g., <code>fu_logger.py</code>, <code>fu_eavesdrop.py</code>) contains redundant, fragile boilerplate to find the toolkit root and manipulate <code>sys.path</code>. This has several drawbacks: *   Maintenance Overhead: Moving a file requires updating the path logic in multiple places. *   Import Fragility: If a script is executed from a different working directory, imports often fail. *   Context Bloat: Scripts are cluttered with 10-15 lines of path math before the actual logic begins.</p> <p><code>fu_bootstrap.py</code> centralizes this \"infrastructure\" logic. By importing bootstrap first, any script in the toolkit gains immediate access to <code>src/</code>, <code>lib/</code>, and <code>service/</code> without needing to know where they are relative to itself.</p>"},{"location":"goals/project-structure-refactoring/#2-proposed-structural-changes","title":"2. Proposed Structural Changes","text":"Directory / File Action Purpose <code>flame-utilities/fu_bootstrap.py</code> NEW Central path discovery and environment setup. <code>flame-utilities/service/</code> NEW Move <code>fu_eavesdrop.py</code>, <code>fu_activate.py</code>, and <code>fu_eavesdrop_init.py</code> here. <code>flame-utilities/lib/</code> RETAIN Keep high-level SDKs (e.g., <code>fu_pybox_v3_13.py</code>) and AI technical bridges. <code>flame-utilities/src/</code> FLATTEN Consolidate <code>src/utils</code> and <code>src/core</code> into a flatter structure to reduce import depth. <code>flame-utilities/*.json</code> MOVE Ensure all JSON configs remain in <code>config/</code> to keep the root pristine."},{"location":"goals/project-structure-refactoring/#targeted-root-cleanup","title":"Targeted Root Cleanup","text":"<p>The root of <code>flame-utilities/</code> should ideally only contain: - <code>fu_bootstrap.py</code> (The entry point) - <code>README.md</code> - <code>config/</code>, <code>lib/</code>, <code>service/</code>, <code>src/</code>, <code>scripts/</code>, <code>tests/</code></p>"},{"location":"goals/project-structure-refactoring/#3-initiative-task-list","title":"3. Initiative Task List","text":"Task ID Action Affected Files REF-01 Create <code>fu_bootstrap.py</code> <code>flame-utilities/fu_bootstrap.py</code> (NEW) REF-02 Migrate Services <code>fu_eavesdrop.py</code>, <code>fu_eavesdrop_init.py</code> $\\rightarrow$ <code>flame-utilities/service/</code> REF-03 Flatten Source <code>src/core/*</code>, <code>src/utils/*</code> $\\rightarrow$ <code>flame-utilities/src/</code> REF-04 Refactor <code>fu_activate</code> <code>flame-utilities/fu_activate.py</code> (Use bootstrap to trigger init) REF-05 Update Imports All <code>.py</code> files in <code>src/</code>, <code>lib/</code>, and <code>service/</code> (Remove path boilerplate) REF-06 Update Automation <code>scripts/deploy_to_flame_project.py</code>, <code>.github/workflows/ci.yml</code>"},{"location":"goals/project-structure-refactoring/#4-consequences-benefits","title":"4. Consequences &amp; Benefits","text":""},{"location":"goals/project-structure-refactoring/#strengths-gained","title":"Strengths Gained","text":"<ul> <li>Import Reliability: By using <code>fu_bootstrap</code>, we ensure that <code>import fu_logger</code> always works, regardless of which subdirectory the parent script is running from.</li> <li>Deployment Simplicity: The project becomes a \"drop-in\" folder where only the bootstrap needs to be referenced by external hooks.</li> <li>Reduced Complexity: Flat internal structures make it easier for AI agents (and humans) to locate utilities without navigating deep nested hierarchies that aren't true Python packages.</li> </ul>"},{"location":"goals/project-structure-refactoring/#weaknesses-addressed","title":"Weaknesses Addressed","text":"<ul> <li>Eliminates Root Clutter: Service-level logic is no longer mixed with documentation and metadata.</li> <li>Solves Path Fragility: Removes the need for every script to contain <code>os.path.dirname(os.path.dirname(__file__))</code> boilerplate.</li> </ul> <p>Proposed by Gemini on 2026-02-02.</p>"},{"location":"goals/pybox-modernization/","title":"Goal: PyBox Modernization (Python 3.13 Migration)","text":""},{"location":"goals/pybox-modernization/#objective","title":"Objective","text":"<p>Establish the <code>pybox_v3.13</code> SDK\u2014a modern, clean-room implementation of the PyBox protocol natively written for Python 3.13. This migration moves away from the legacy <code>pybox_v1</code> (Python 2.7) architecture to enable high-performance, AI-compatible, and type-safe workflows within Autodesk Flame.</p>"},{"location":"goals/pybox-modernization/#rationale","title":"Rationale","text":"<ul> <li>End of Life: Python 2.7 reached end-of-life in 2020; the VFX industry has moved to the VFX Reference Platform CY2024+ standards.</li> <li>AI-Native Ready: Modern generative AI frameworks (ComfyUI, PyTorch) require Python 3.10+.</li> <li>Clean-Room Compliance: By implementing the established JSON protocol from scratch as <code>pybox_v3.13</code>, we ensure modernization without contravening Autodesk's proprietary source copyright.</li> <li>Future-Proofing: Leverages Python 3.13 features like advanced typing, Pathlib integration, and improved error reporting.</li> </ul>"},{"location":"goals/pybox-modernization/#migration-tasks","title":"Migration Tasks","text":""},{"location":"goals/pybox-modernization/#1-new-sdk-development-pybox_v313py","title":"1. New SDK Development (<code>pybox_v3.13.py</code>)","text":"<ul> <li>[x] Clean-Room Implementation: Developed <code>flame-utilities/lib/fu_pybox_v3_13.py</code> from scratch, based on the documented JSON communication schema.</li> <li>[x] Unicode &amp; Pathlib: Implemented native UTF-8 handling and use <code>pathlib.Path</code> for all image sequence and temporary file operations.</li> <li>[x] Modern Class Structure: Refactored the <code>BaseClass</code> to use native Python 3 features (e.g., <code>@property</code>, <code>super()</code>).</li> <li>[x] PEP 484 Type Hinting: Provided full type stubs and inline hints to enable robust AI introspection via <code>fu_whisper</code>.</li> </ul>"},{"location":"goals/pybox-modernization/#2-handler-migration-v1-to-v313","title":"2. Handler Migration (v1 to v3.13)","text":"<ul> <li>[ ] Migration Tool: Create a utility script (<code>fu_pybox_converter.py</code>) that uses AST analysis to port legacy 2.7 handlers to 3.13 syntax.</li> <li>[x] Logic Conversion: Updated initial production handler (<code>fu_pybox_no_op_v3.py</code>) to use <code>pybox_v3.13</code> imports and logic.</li> <li>[ ] I/O Refactoring: Ensure handlers correctly distinguish between Unicode JSON metadata and binary image data.</li> </ul>"},{"location":"goals/pybox-modernization/#3-execution-infrastructure","title":"3. Execution Infrastructure","text":"<ul> <li>[ ] Universal Wrapper: Implement a wrapper logic that detects the available Python 3.13 binary and sets up an isolated environment for the handler.</li> <li>[ ] Environment Isolation: Standardize the use of <code>.venv</code> for PyBox handlers to manage dependencies (OpenCV, ComfyUI-Client) safely.</li> </ul>"},{"location":"goals/pybox-modernization/#4-flame-utilities-integration","title":"4. FLAME-UTILITIES Integration","text":"<ul> <li>[ ] MCP Version Detection: Update <code>fu_whisper</code> to detect if a PyBox node is running a <code>v1</code> or <code>v3.13</code> handler and suggest migrations.</li> <li>[ ] Semantic Discovery: Integrate <code>pybox_v3.13</code> symbols into <code>fu_encyclopedia</code> for RAG-assisted handler development.</li> </ul>"},{"location":"goals/pybox-modernization/#success-metrics","title":"Success Metrics","text":"<ul> <li>Successful execution of a 3.13-native <code>no_op.py</code> handler using <code>pybox_v3.13</code> inside Flame.</li> <li>Successful integration of <code>fu_comfyui</code> calls directly within a PyBox execution loop.</li> <li>Full verification that no proprietary <code>pybox_v1</code> source code is redistributed within the <code>flame-utilities/</code> directory.</li> </ul>"},{"location":"goals/vision/","title":"Vision: FLAME-UTILITIES","text":"<p>The FLAME-UTILITIES suite aims to revolutionize Autodesk Flame pipeline development by bridging the gap between Flame's closed environment and modern, AI-augmented workflows. </p>"},{"location":"goals/vision/#core-goals","title":"Core Goals","text":"<ul> <li>AI-Native Interaction: Leverage the fu_whisper bridge to allow AI agents to autonomously inspect, automate, and debug Flame projects in real-time.</li> <li>Rapid Iteration: Instant execution of Flame scripts from VS Code without application restarts or manual reloading.</li> <li>Deep IntelliSense: Provide frame-accurate autocompletion and documentation via a fully automated API intelligence pipeline.</li> <li>Enterprise Safety: Ensure reliability through thread-safe execution and secure, token-based authentication.</li> </ul>"},{"location":"goals/vision/#the-ai-augmented-workflow","title":"The AI-Augmented Workflow","text":"<p>By implementing the Model Context Protocol (MCP), FLAME-UTILITIES transforms the AI from a simple code generator into an active pipeline participant.</p> <ul> <li>Yesterday: You ask an AI to write a Renaming script, then copy-paste it into a file and run it.</li> <li>Today: You tell the AI, \"Rename all segments in the current sequence to match the shot name from their metadata,\" and the AI executes the task directly inside Flame via FU_Whisper.</li> </ul>"},{"location":"goals/vision/#component-overview","title":"Component Overview","text":"<pre><code>graph TD\n    subgraph Development_Environment [External / VS Code]\n        AI[AI Agent / LLM]\n        Ext[VS Code Extension]\n        Whisper[FU_Whisper MCP Bridge]\n    end\n\n    subgraph Flame_Instance [Autodesk Flame]\n        Eavesdrop[fu_eavesdrop Listener]\n        API[Autodesk Flame Python API]\n    end\n\n    AI -- Tools --&gt; Whisper\n    Whisper -- fu_relay --&gt; Eavesdrop\n    Ext -- fu_relay --&gt; Eavesdrop\n    Eavesdrop -- Main Thread --&gt; API\n</code></pre>"},{"location":"goals/vision/#future-roadmap","title":"Future Roadmap","text":"<ol> <li>Visual Reasoning: Integrating screenshot capabilities so AI agents can \"see\" the Batch schematic and Media Hub.</li> <li>Autonomous Conform Suite: Specialized tools for matching offline edits to high-res sources autonomously.</li> <li>Real-Time Debugging: Full integration of <code>debugpy</code> for line-by-line inspection of running hooks.</li> </ol>"},{"location":"insight/adsk/python/insight-archive_hook/","title":"Insight: Monitoring Archive Operations","text":"<p>This document explains the <code>archive_hook.py</code> file. It shows how Flame can notify your Python scripts about the status of backups and restores.</p> <p>Target Audience: Novice Python programmers interested in data safety and system monitoring.</p>"},{"location":"insight/adsk/python/insight-archive_hook/#1-what-is-an-archive-hook","title":"1. What is an Archive Hook?","text":"<p>In Flame, \"Archiving\" is the process of backing up your project to a server or a tape. Because archives can take a long time, you might not want to sit and watch the progress bar.</p> <p>The Solution: Archive Hooks. These are \"Event Listeners\" that run automatically when an archive starts, finishes, or hits a milestone.</p>"},{"location":"insight/adsk/python/insight-archive_hook/#2-key-events-hooks","title":"2. Key Events (Hooks)","text":"<p>The script defines several empty placeholders (functions) that Flame will fill with data:</p>"},{"location":"insight/adsk/python/insight-archive_hook/#a-archive_completed","title":"A. <code>archive_completed</code>","text":"<p>Flame runs this as soon as a backup is 100% finished. - Use case: Send an email to the producer saying: \"The backup for 'Project_X' is done!\"</p>"},{"location":"insight/adsk/python/insight-archive_hook/#b-archive_restored","title":"B. <code>archive_restored</code>","text":"<p>Runs when you successfully bring a project back from an archive. - Use case: Log that a project was reopened for auditing purposes.</p>"},{"location":"insight/adsk/python/insight-archive_hook/#c-archive_segment_completed","title":"C. <code>archive_segment_completed</code>","text":"<p>Archives are often broken into smaller \"segments\" (files). This hook runs every time one of those small files is finished. - Why? It tells you the <code>status</code>. If it's not zero, something went wrong! You can catch errors early instead of waiting for the very end.</p>"},{"location":"insight/adsk/python/insight-archive_hook/#d-archive_selection_updated","title":"D. <code>archive_selection_updated</code>","text":"<p>Runs when you select clips to be archived. It gives you technical data like <code>num_frames</code> and <code>data_size</code> (in MB). - Use case: Warn the artist if they are trying to archive more data than is available on the backup drive.</p>"},{"location":"insight/adsk/python/insight-archive_hook/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Automation: You can trigger external scripts (like database updates) based on archive success.</li> <li>Error Handling: You get immediate, detailed feedback if a backup fails.</li> <li>Reporting: You can build a history of how much data your studio is archiving every day.</li> </ul>"},{"location":"insight/adsk/python/insight-archive_hook/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Hooks are like \"Automatic Notifications\" for your code. Instead of your script constantly asking Flame \"Are you done yet?\", Flame simply \"calls\" your script's function when the event happens and hands over all the relevant information (like the archive name and path).</p>"},{"location":"insight/adsk/python/insight-batch_hook/","title":"Insight: Mastering the Batch Lifecycle","text":"<p>This document explains the <code>batch_hook.py</code> file. It covers every stage of the Batch process\u2014from saving your work to rendering the final images.</p> <p>Target Audience: Novice Python programmers learning about render pipelines and automation.</p>"},{"location":"insight/adsk/python/insight-batch_hook/#1-what-is-a-batch-hook","title":"1. What is a Batch Hook?","text":"<p>Batch is Flame's node-based compositing environment. Because Batch is where most of the \"Heavy Lifting\" (rendering) happens, it has many hooks to help you track progress and prevent mistakes.</p>"},{"location":"insight/adsk/python/insight-batch_hook/#2-key-lifecycle-stages","title":"2. Key Lifecycle Stages","text":"<p>The script breaks the Batch workflow into three main parts:</p>"},{"location":"insight/adsk/python/insight-batch_hook/#a-setup-management-batch_setup_loaded-saved","title":"A. Setup Management (<code>batch_setup_loaded</code> / <code>saved</code>)","text":"<p>These run when you open or save your Batch schematic. - Use case: Keep a log of who is opening which Batch setup and when.</p>"},{"location":"insight/adsk/python/insight-batch_hook/#b-iterations-batch_setup_iterated_pre-post","title":"B. Iterations (<code>batch_setup_iterated_pre</code> / <code>post</code>)","text":"<p>In Flame, an \"Iteration\" is a versioned save. - The \"Pre\" Hook: Runs before the save happens. You can use this to Abort the save if the file name doesn't match studio standards. - The \"Post\" Hook: Runs after the save. It tells you if it was successful.</p>"},{"location":"insight/adsk/python/insight-batch_hook/#c-rendering-exporting-begin-end-hooks","title":"C. Rendering &amp; Exporting (<code>begin</code> / <code>end</code> hooks)","text":"<p>This is where the images are actually created. - <code>batch_render_begin</code>: Runs before a local render. - <code>batch_burn_begin</code>: Runs before sending a job to a \"Burn\" render node. - <code>batch_export_begin</code>: Runs before a \"Write File\" node starts exporting to disk.</p>"},{"location":"insight/adsk/python/insight-batch_hook/#3-the-info-and-userdata-pattern","title":"3. The <code>info</code> and <code>userData</code> Pattern","text":"<p>Almost all these functions use two special parameters:</p> <ol> <li><code>info</code> [Dictionary]: This is a read-only (and sometimes modifiable) \"ID Card\" for the task. It contains paths, frame rates, resolution, and job names.</li> <li><code>userData</code> [Dictionary]: This is like a \"Sticky Note.\" You can write something on it in the <code>_begin</code> hook (like a timestamp), and Flame will hand that same sticky note back to you in the <code>_end</code> hook. It's the best way to track how long a job took!</li> </ol>"},{"location":"insight/adsk/python/insight-batch_hook/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Quality Control: Use the <code>begin</code> hooks to check if the render settings (like resolution) are correct before wasting hours on a render.</li> <li>Custom Notifications: Use the <code>end</code> hooks to trigger a Slack message or email when a long render is finished.</li> <li>Path Redirection: Use the <code>batch_export_begin</code> hook to dynamically change where files are saved based on the project name.</li> </ul>"},{"location":"insight/adsk/python/insight-batch_hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Batch hooks allow you to \"Sandwich\" Flame's built-in actions with your own code. By putting logic at the \"Start\" and \"End\" of a render, you can build a highly controlled and intelligent production pipeline.</p>"},{"location":"insight/adsk/python/insight-custom_actions_hook/","title":"Insight: Creating Custom Right-Click Menus","text":"<p>This document explains the <code>custom_actions_hook.py</code> file. It is the \"Master List\" of where and how you can add your own buttons to the Flame interface.</p> <p>Target Audience: Novice Python programmers who want to customize the Flame UI.</p>"},{"location":"insight/adsk/python/insight-custom_actions_hook/#1-what-are-custom-actions","title":"1. What are Custom Actions?","text":"<p>In Flame, almost every area (the Media Panel, the Timeline, the Batch Schematic) has a right-click menu. A Custom Action is your way of adding a new button to those menus that runs your own Python code.</p>"},{"location":"insight/adsk/python/insight-custom_actions_hook/#2-where-can-you-add-menus","title":"2. Where can you add Menus?","text":"<p>The script lists many functions, each corresponding to a different \"Home\" in Flame:</p> <ul> <li><code>get_media_panel_custom_ui_actions</code>: Right-clicking on clips or folders in the browser.</li> <li><code>get_main_menu_custom_ui_actions</code>: The top Flame menu.</li> <li><code>get_timeline_custom_ui_actions</code>: Right-clicking on segments in the timeline.</li> <li><code>get_batch_custom_ui_actions</code>: Right-clicking in the Batch schematic.</li> <li><code>get_mediahub_files_custom_ui_actions</code>: Right-clicking on files you are about to import.</li> </ul>"},{"location":"insight/adsk/python/insight-custom_actions_hook/#3-how-to-define-an-action","title":"3. How to Define an Action","text":"<p>Each action is a Dictionary (a list of settings). Here are the most important settings:</p> <ul> <li><code>name</code>: The text that appears in the menu.</li> <li><code>execute</code>: The name of the Python function to run when the user clicks the button.</li> <li><code>isVisible</code>: A \"Gatekeeper.\" If this is False, the button stays hidden. </li> <li>Tip: Use this to only show \"Timeline\" tools when the user is actually on the Timeline.</li> <li><code>isEnabled</code>: Similar to <code>isVisible</code>, but it makes the button greyed-out (disabled) instead of hiding it.</li> </ul>"},{"location":"insight/adsk/python/insight-custom_actions_hook/#4-organizing-with-groups","title":"4. Organizing with Groups","text":"<p>You don't just add single buttons; you add Groups.  - A Group is like a folder in the menu.  - This keeps your tools organized (e.g., all your \"Export\" tools inside one \"My Studio / Exports\" group).</p>"},{"location":"insight/adsk/python/insight-custom_actions_hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of <code>custom_actions_hook.py</code> as the \"Registry\" of your tools. It doesn't usually contain the logic of what the tool does; it just tells Flame where to put the button and which script to wake up when that button is pressed.</p>"},{"location":"insight/adsk/python/insight-export_hook/","title":"Insight: Customizing the Export Pipeline","text":"<p>This document explains the <code>export_hook.py</code> file. It is one of the most powerful and complex hook files in Flame, allowing you to control exactly what happens when media is saved to disk.</p> <p>Target Audience: Novice Python programmers interested in complex automation and data management.</p>"},{"location":"insight/adsk/python/insight-export_hook/#1-the-export-sandwich","title":"1. The Export \"Sandwich\"","text":"<p>Exporting a clip in Flame isn't just one single action; it's a sequence of events. Flame allows you to \"sandwich\" your own code at every layer of this process.</p>"},{"location":"insight/adsk/python/insight-export_hook/#the-execution-order","title":"The Execution Order:","text":"<ol> <li><code>pre_export</code>: Runs once at the very beginning of the whole export job.</li> <li><code>pre_export_sequence</code>: Runs for every Sequence in your export list.</li> <li><code>pre_export_asset</code>: Runs for every individual file (Video, Audio, OpenClip) being created.</li> <li><code>post_export_asset</code>: Runs as soon as a file is finished.</li> <li><code>post_export_sequence</code>: Runs when all assets in a sequence are done.</li> <li><code>post_export</code>: Runs once everything is finished.</li> </ol>"},{"location":"insight/adsk/python/insight-export_hook/#2-key-features","title":"2. Key Features","text":""},{"location":"insight/adsk/python/insight-export_hook/#a-the-abort-switch","title":"A. The \"Abort\" Switch","text":"<p>Most <code>pre_</code> hooks allow you to cancel the export if something is wrong.</p> <pre><code>if info[\"destinationPath\"] == \"/forbidden/path\":\n    info[\"abort\"] = True\n    info[\"abort_message\"] = \"You cannot export to this server!\"\n</code></pre>"},{"location":"insight/adsk/python/insight-export_hook/#b-overwriting-files","title":"B. Overwriting Files","text":"<p>The <code>export_overwrite_file</code> hook lets you decide what happens if a file already exists.  - You can tell Flame to always <code>\"overwrite\"</code>, <code>\"skip\"</code>, or <code>\"ask\"</code> the user. This is perfect for avoiding those annoying pop-up boxes!</p>"},{"location":"insight/adsk/python/insight-export_hook/#c-userdata-sharing","title":"C. <code>userData</code> Sharing","text":"<p>Like the Batch hooks, Export hooks use a <code>userData</code> dictionary. You can put info in at the <code>pre_export</code> stage and read it back at <code>post_export</code>. This is how you track total export time or gather a list of every file created.</p>"},{"location":"insight/adsk/python/insight-export_hook/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Custom Naming: You can use <code>pre_export_asset</code> to dynamically change the filename (<code>info[\"resolvedPath\"]</code>) based on the shot name or project code.</li> <li>Post-Processing: Use <code>post_export_asset</code> to automatically trigger an external transcode (like making a low-res H.264 for the web) as soon as the high-res file is ready.</li> <li>Security: Ensure that exports only go to approved storage locations.</li> </ul>"},{"location":"insight/adsk/python/insight-export_hook/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The export pipeline is granular. If you want to change something for the whole job, use <code>pre_export</code>. If you want to change something for one specific clip, use <code>pre_export_asset</code>. Understanding this hierarchy is the key to building a professional studio pipeline.</p>"},{"location":"insight/adsk/python/insight-hook/","title":"Insight: Global Application Hooks","text":"<p>This document explains the <code>hook.py</code> file. These are the \"Global\" events that happen at the highest level of Autodesk Flame.</p> <p>Target Audience: Novice Python programmers interested in general automation and default settings.</p>"},{"location":"insight/adsk/python/insight-hook/#1-what-is-a-global-hook","title":"1. What is a Global Hook?","text":"<p>While most hooks are about specific tasks (like rendering or exporting), Global Hooks are about the Application itself. They run when Flame starts, when you switch projects, or when you log in as a different user.</p>"},{"location":"insight/adsk/python/insight-hook/#2-key-global-events","title":"2. Key Global Events","text":""},{"location":"insight/adsk/python/insight-hook/#a-lifecycle-hooks-app_initialized-app_exited","title":"A. Lifecycle Hooks (<code>app_initialized</code> / <code>app_exited</code>)","text":"<ul> <li><code>app_initialized</code>: Runs as soon as Flame is ready for work.</li> <li>Use case: Automatically open a specific library or print a \"Welcome\" message to the console.</li> <li><code>app_exited</code>: Runs when you quit Flame.</li> <li>Use case: Clean up temporary files or save a log of how long you worked.</li> </ul>"},{"location":"insight/adsk/python/insight-hook/#b-user-changes-user_changed","title":"B. User Changes (<code>user_changed</code>)","text":"<p>Flame runs this when you switch from \"Editor A\" to \"Editor B.\" - Use case: Automatically load the user's preferred hotkeys or window layouts via Python.</p>"},{"location":"insight/adsk/python/insight-hook/#c-default-naming-hooks","title":"C. Default Naming Hooks","text":"<p>Flame uses several hooks to decide what the \"Default Name\" should be for things like Markers and Shots: - <code>timeline_default_shot_name</code> - <code>timeline_default_marker_name</code> - <code>default_reference_name</code></p> <p>Instead of every shot being named \"Shot 1\", \"Shot 2\", you can write a script that names them based on the Date and the Project Name automatically.</p>"},{"location":"insight/adsk/python/insight-hook/#3-monitoring-performance","title":"3. Monitoring Performance","text":"<p>The <code>render_ended</code> hook in this file is different from the Batch render hook. It triggers for any render in Flame (Timeline, Effects, etc.) and tells you exactly how many seconds it took. - Use case: Build a report showing which modules (like \"Action\" or \"GMask\") are taking the most time to render across your project.</p>"},{"location":"insight/adsk/python/insight-hook/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Consistency: You can enforce studio-wide naming standards for markers and shots so everyone's projects look the same.</li> <li>Environment Setup: You can prepare the Flame environment (like setting the Video Preview device) automatically every time the software starts.</li> </ul>"},{"location":"insight/adsk/python/insight-hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Global hooks are for \"Set it and Forget it\" logic. Once you write a hook here, it works across every project and every user, making it the best place for infrastructure-level automation.</p>"},{"location":"insight/adsk/python/insight-otio_reader/","title":"Insight: The OTIO Translation Engine","text":"<p>This document explains the <code>otio_reader.py</code> script. While the \"Hook\" script starts the process, this is the \"Brain\" that does the actual work of turning an OTIO file into a Flame sequence.</p> <p>Target Audience: Novice Python programmers interested in object-oriented programming (OOP) and \"Data Mapping.\"</p>"},{"location":"insight/adsk/python/insight-otio_reader/#1-what-is-a-reader-class","title":"1. What is a \"Reader\" Class?","text":"<p>This script uses a Class called <code>FlameOTIOReader</code>.  - The Concept: Think of this class as a professional translator. It reads a book in one language (OTIO) and writes a new one in another language (Flame API).</p>"},{"location":"insight/adsk/python/insight-otio_reader/#2-key-translation-steps","title":"2. Key Translation Steps","text":"<p>The script doesn't just \"copy\" the file. It has to map every OTIO concept to a Flame concept:</p>"},{"location":"insight/adsk/python/insight-otio_reader/#a-the-timeline-map","title":"A. The Timeline Map","text":"<ul> <li>OTIO Timeline becomes a Flame Sequence.</li> <li>OTIO Track becomes a Flame Track (Video or Audio).</li> <li>OTIO Clip becomes a Flame Segment.</li> </ul>"},{"location":"insight/adsk/python/insight-otio_reader/#b-frame-rate-conversion","title":"B. Frame Rate Conversion","text":"<p>OTIO might say \"23.98 fps,\" but Flame expects exactly <code>\"23.976 fps\"</code>. The function <code>_otio_rate_to_frame</code> handles this tricky math so the timing stays perfect.</p>"},{"location":"insight/adsk/python/insight-otio_reader/#c-finding-media","title":"C. Finding Media","text":"<p>OTIO files often use \"Relative Paths\" (e.g., <code>../media/shot.mov</code>). The script is smart enough to find the real file on your hard drive by looking at where the OTIO file itself is saved.</p>"},{"location":"insight/adsk/python/insight-otio_reader/#3-advanced-feature-pre-and-post-hooks","title":"3. Advanced Feature: \"Pre\" and \"Post\" Hooks","text":"<p>The reader is designed to be extensible. It uses its own internal hooks: - <code>pre_hook_Clip</code>: Runs just before a clip is created. - <code>post_hook_Clip</code>: Runs after the clip is in Flame. This allows other programmers to add custom logic (like adding a specific Color FX) without changing the main reader code.</p>"},{"location":"insight/adsk/python/insight-otio_reader/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Robustness: By putting all the logic in one Class, the code is easier to test and fix.</li> <li>Complexity: It handles nested structures (like stacks and gaps) that a simple script couldn't manage.</li> <li>Accuracy: It ensures that metadata, markers, and transitions are preserved during the move between software.</li> </ul>"},{"location":"insight/adsk/python/insight-otio_reader/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Mapping data from one format to another is a common job for Python. The secret is to break the big problem into small pieces: first translate the Timeline, then the Tracks, then the Clips, then the Markers. </p>"},{"location":"insight/adsk/python/insight-otio_reader_hook/","title":"Insight: Importing OpenTimelineIO (OTIO)","text":"<p>This document explains the <code>otio_reader_hook.py</code> file. It shows how Flame can understand \"OTIO\" files\u2014a universal format for sharing movie timelines between different software.</p> <p>Target Audience: Novice Python programmers interested in cross-software compatibility.</p>"},{"location":"insight/adsk/python/insight-otio_reader_hook/#1-what-is-otio","title":"1. What is OTIO?","text":"<p>Imagine you edited a video in Adobe Premiere or DaVinci Resolve and you want to bring that exact timeline (all the clips in the right order) into Flame. Usually, you would use an XML or AAF file. </p> <p>OpenTimelineIO (OTIO) is a modern, open-source way to do this. It's more reliable and easier for programmers to use.</p>"},{"location":"insight/adsk/python/insight-otio_reader_hook/#2-how-the-hook-works","title":"2. How the Hook Works","text":"<p>This script acts as a \"Bridge.\" </p> <ol> <li>The Trigger: When you try to import an OTIO file, Flame runs the <code>import_otio</code> function.</li> <li>The Engine: It calls another script (<code>otio_reader.py</code>) to do the heavy lifting.</li> <li>The Translation: It takes the \"Clips\" and \"Tracks\" from the OTIO file and recreates them inside Flame as <code>PySequence</code> and <code>PySegment</code> objects.</li> </ol>"},{"location":"insight/adsk/python/insight-otio_reader_hook/#3-error-handling","title":"3. Error Handling","text":"<p>Importing timelines is messy. Clips might be missing, or files might be corrupted. The script uses a <code>try...except</code> block:</p> <pre><code>try:\n    otio.read_otio_file(file_path, first_sel)\nexcept Exception as e:\n    return f\"Caught exception: {e}\"\n</code></pre> <p>This ensures that if the import fails, Flame doesn't crash. Instead, it \"catches\" the error and shows a helpful message to the user.</p>"},{"location":"insight/adsk/python/insight-otio_reader_hook/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Interoperability: It allows Flame to sit in the middle of a pipeline with many different editing tools.</li> <li>Customization: Because it's written in Python, you can customize how the import happens\u2014for example, automatically looking for missing media in a specific studio folder.</li> </ul>"},{"location":"insight/adsk/python/insight-otio_reader_hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Hooks aren't just for small tasks; they can be used to add Entire New Features to Flame. By writing a reader hook, you are teaching Flame how to understand a file format it didn't know about when it was first built!</p>"},{"location":"insight/adsk/python/insight-project_hook/","title":"Insight: Automating the Project Lifecycle","text":"<p>This document explains the <code>project_hook.py</code> file. It gives you total control over how Flame projects are created, saved, and managed.</p> <p>Target Audience: Novice Python programmers interested in project management and data safety.</p>"},{"location":"insight/adsk/python/insight-project_hook/#1-what-is-a-project-hook","title":"1. What is a Project Hook?","text":"<p>In Flame, a \"Project\" is the container for all your work. Because projects are so important, Flame gives you hooks for every possible change that can happen to one.</p>"},{"location":"insight/adsk/python/insight-project_hook/#2-key-lifecycle-events","title":"2. Key Lifecycle Events","text":""},{"location":"insight/adsk/python/insight-project_hook/#a-creation-setup-project_init_creation-pre_creation","title":"A. Creation &amp; Setup (<code>project_init_creation</code> / <code>pre_creation</code>)","text":"<ul> <li><code>project_init_creation</code>: Runs as soon as you open the \"New Project\" window.</li> <li>Use case: Automatically fill in the Project Description or Nickname based on today's date.</li> <li><code>project_pre_creation</code>: Runs right before the project is actually built.</li> <li>Use case: Abort the creation if the name doesn't follow studio rules (e.g., must start with a job number).</li> </ul>"},{"location":"insight/adsk/python/insight-project_hook/#b-project-changes-project_changed-project_saved","title":"B. Project Changes (<code>project_changed</code> / <code>project_saved</code>)","text":"<ul> <li><code>project_changed</code>: Runs when you switch from Project A to Project B.</li> <li><code>project_saved</code>: Runs every time you save.</li> <li>Tip: It even tells you if it was an \"Auto-Save\" or a manual save by the artist!</li> </ul>"},{"location":"insight/adsk/python/insight-project_hook/#c-conversion-migration-project_pre_conversion","title":"C. Conversion &amp; Migration (<code>project_pre_conversion</code>)","text":"<p>When you upgrade Flame, you often have to convert old projects. - Use case: Log which projects have been migrated to the new version for auditing.</p>"},{"location":"insight/adsk/python/insight-project_hook/#d-deletion-protection-project_pre_delete","title":"D. Deletion &amp; Protection (<code>project_pre_delete</code>)","text":"<p>This is the \"Security Guard\" hook. - Use case: Prevent anyone from deleting a project if it's currently marked as \"Active\" in your studio database.</p>"},{"location":"insight/adsk/python/insight-project_hook/#3-the-abort-power","title":"3. The \"Abort\" Power","text":"<p>Just like Export hooks, Project hooks allow you to set <code>info[\"abort\"] = True</code>. This is the ultimate safety feature. It stops Flame from doing anything until the project data meets your studio's standards.</p>"},{"location":"insight/adsk/python/insight-project_hook/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Organization: Ensure every project has a consistent folder structure and naming convention.</li> <li>Safety: Prevent accidental deletion of \"Master\" projects.</li> <li>Automation: Automatically link Flame projects to external systems like ShotGrid as soon as they are created.</li> </ul>"},{"location":"insight/adsk/python/insight-project_hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Project hooks are about \"Governance.\" They allow you to turn Flame from a standalone tool into a part of a larger, managed studio ecosystem where rules are enforced automatically by code.</p>"},{"location":"insight/adsk/python/insight-tokens_hook/","title":"Insight: Creating Custom Naming Tokens","text":"<p>This document explains the <code>tokens_hook.py</code> file. It shows how to add your own \"Magic Words\" (Tokens) to Flame's naming and export windows.</p> <p>Target Audience: Novice Python programmers interested in dynamic naming and string manipulation.</p>"},{"location":"insight/adsk/python/insight-tokens_hook/#1-what-are-tokens","title":"1. What are Tokens?","text":"<p>You've probably seen tokens in Flame like <code>&lt;shot_name&gt;</code> or <code>{width}</code>. When you use them, Flame automatically replaces the token with the real name or resolution of the clip.</p> <p>The Goal: Add your own custom tokens, like <code>&lt;artist_name&gt;</code> or <code>&lt;job_number&gt;</code>, so you don't have to type them manually in every export window.</p>"},{"location":"insight/adsk/python/insight-tokens_hook/#2-two-steps-to-custom-tokens","title":"2. Two Steps to Custom Tokens","text":"<p>Adding a token is a two-part process:</p>"},{"location":"insight/adsk/python/insight-tokens_hook/#step-1-listing-the-token-get_hook_token_list","title":"Step 1: Listing the Token (<code>get_hook_token_list</code>)","text":"<p>You first have to tell Flame that your token exists so it shows up in the \"Add Token\" dropdown menu. - Contexts: You can add tokens for Browsing (MediaHub), Clips (Export), or Segments (Timeline).</p>"},{"location":"insight/adsk/python/insight-tokens_hook/#step-2-resolving-the-token-resolve_hook_token","title":"Step 2: Resolving the Token (<code>resolve_hook_token</code>)","text":"<p>This is the \"Search and Replace\" part. When Flame sees your token, it runs this function to find out what the real value should be.</p> <pre><code>def resolve_hook_token(context, context_info, token_name, hint):\n    if token_name == \"&lt;my_custom_token&gt;\":\n        return \"Real_Value_123\"\n</code></pre>"},{"location":"insight/adsk/python/insight-tokens_hook/#3-advanced-trick-the-cache","title":"3. Advanced Trick: The \"Cache\"","text":"<p>If you have a token that is hard to calculate (like asking a website for a job number), you don't want Flame to do that 1,000 times for 1,000 clips.</p> <p>The script shows an example of a TTL Cache (Time-To-Live). It calculates the value once and then \"remembers\" it for 5 seconds. This keeps Flame feeling fast and responsive.</p>"},{"location":"insight/adsk/python/insight-tokens_hook/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Dynamic Exporting: You can create an export path that automatically includes the current artist's name and the date without ever typing it.</li> <li>Project Context: Pull information from external files or databases and inject it directly into Flame's file naming.</li> <li>Consistency: Ensures that everyone in the studio uses the exact same naming format for their renders.</li> </ul>"},{"location":"insight/adsk/python/insight-tokens_hook/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Tokens are like Variables for your filenames. By defining them in <code>tokens_hook.py</code>, you are creating a shortcut that turns complex, dynamic data into simple words that any Flame artist can use.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/","title":"Insight: Automating OCIO Context Variables in Flame","text":"<p>This document explains the <code>context_variables.py</code> example script. It is designed to help you understand how to automate OpenColorIO (OCIO) Context Variables using the Autodesk Flame Python API.</p> <p>Target Audience: Novice Python programmers getting started with Flame automation.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#1-what-is-the-goal","title":"1. What is the Goal?","text":"<p>In modern color pipelines, we often use OCIO (OpenColorIO) to manage color spaces. A powerful feature of OCIO is Context Variables.</p> <p>Imagine you have a specific Color Correction file (<code>.cc</code> or <code>.lut</code>) for every single shot in your movie. Instead of manually loading <code>shot_010.cc</code> for Shot 010 and <code>shot_020.cc</code> for Shot 020, you can tell Flame:</p> <p>\"Look for a file named <code>${SHOT}.cc</code>.\"</p> <p>Then, you just need to tell Flame what <code>${SHOT}</code> equals for each clip.</p> <p>This script automates that second part. It takes the Shot Name of your clip (e.g., \"sh010\") and automatically plugs it into the <code>SHOT</code> Context Variable in the Color Management settings.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#2-key-functions-breakdown","title":"2. Key Functions Breakdown","text":"<p>The script provides two main ways to do this: one for the Timeline and one for Batch.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#a-timeline-workflow-add_cmfx_with_shot_based_cc","title":"A. Timeline Workflow: <code>add_cmfx_with_shot_based_cc</code>","text":"<p>This function adds a Source Colour Management Timeline FX to your segments.</p> <ol> <li> <p>Selection Handling:     First, it looks at what you selected.</p> <ul> <li>If you selected Segments, it uses them directly.</li> <li>If you selected Sequences, it finds all the segments inside them.</li> </ul> </li> <li> <p>Safety Check:     It checks if you already have a Color Management effect.</p> <ul> <li>If yes, it pops up a dialog box asking: \"Do you want to overwrite the existing effect?\"</li> <li>This is great practice! It prevents your script from accidentally destroying previous work.</li> </ul> </li> <li> <p>The \"Magic\" Loop:     It goes through each segment one by one:     ```python     # 1. Get the Shot Name     shot_name = segment.shot_name.get_value()</p> </li> </ol>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#2-create-the-effect","title":"2. Create the Effect","text":"<p>clmgt = segment.create_effect(\"Source Colour Mgmt\")</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#3-configure-the-effect","title":"3. Configure the Effect","text":"<p>clmgt.mode = \"View Transform\" clmgt.view = \"Shot Based CC\" # This view expects a variable!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#4-set-the-variable","title":"4. Set the Variable","text":"<p>clmgt.set_context_variable(\"SHOT\", shot_name) <code>`` **Result:** The effect is created, and the</code>${SHOT}` variable is now equal to \"sh010\" (or whatever your shot is named).</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#b-batch-workflow-add_cmnode_with_shot_based_cc","title":"B. Batch Workflow: <code>add_cmnode_with_shot_based_cc</code>","text":"<p>This function works in the Batch schematic (Flame's node-based compositor).</p> <ol> <li> <p>Selection Handling:     It looks for Clip Nodes in your selection or inside selected Batch Groups.</p> </li> <li> <p>Node Creation:     For every clip:</p> <ul> <li>It creates a new Colour Mgmt node.</li> <li>It connects it to the Clip node automatically.</li> <li>Tip: <code>batch.connect_nodes(clip_node, \"Default\", clmgt, \"Default\")</code> is how you wire things together with code.</li> </ul> </li> <li> <p>Setting the Variable:     Just like the timeline version, it takes the <code>shot_name</code> from the clip and feeds it into <code>clmgt.set_context_variable(\"SHOT\", shot_name)</code>.</p> </li> </ol>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#3-how-does-it-appear-in-flame","title":"3. How does it appear in Flame?","text":"<p>The functions at the bottom (<code>get_timeline_custom_ui_actions</code>, etc.) tell Flame where to put this script in the menu.</p> <ul> <li>Context: You will see a new menu item \"Examples / Context Variables\" when you right-click on the Timeline, in Batch, or in the Media Panel.</li> <li>Visibility: The <code>isVisible</code> filters ensure you only see the \"Batch\" command when you are actually in Batch, and the \"Timeline\" command when you are on the Timeline. This keeps the menus clean.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>Without this script, you would have to: 1.  Add a Color Mgmt node. 2.  Open it. 3.  Type the shot name into the Context Variable tab. 4.  Repeat 100 times for 100 shots.</p> <p>With this script, you click one button, and it's done for all 100 shots instantly.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-context_variables/#5-next-steps-for-you","title":"5. Next Steps for You","text":"<p>Try modifying the script! -   Challenge: Can you change it to use a different variable name, like <code>SEQUENCE</code> instead of <code>SHOT</code>? -   Hint: Look for the line <code>clmgt.set_context_variable(\"SHOT\", shot_name)</code> and change <code>\"SHOT\"</code> to <code>\"SEQUENCE\"</code>.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/","title":"Insight: Customizing Project Conversion in Flame","text":"<p>This document explains the <code>conversion_description.py</code> example script. It is a simple but powerful example of using Hooks to automate tasks when upgrading projects in Autodesk Flame.</p> <p>Target Audience: Novice Python programmers interested in project management automation.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#1-what-is-the-goal","title":"1. What is the Goal?","text":"<p>When you upgrade Autodesk Flame to a new major version (e.g., from 2025 to 2026), your existing projects often need to be \"converted\" to work with the new software.</p> <p>Normally, this just happens. But what if you want to leave a \"paper trail\" or tag these projects so you know they have been changed?</p> <p>This script automates that tagging. - It automatically adds \" (Converted)\" to the end of the project's name. - It changes the project's description to say exactly when the conversion happened.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#a-the-hook","title":"A. The \"Hook\"","text":"<p>The core of this script is a special function name: <code>project_init_conversion</code>. Flame looks for this specific function name. If it finds it in a loaded script, it runs it right before the conversion process starts.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#b-the-info-dictionary","title":"B. The <code>info</code> Dictionary","text":"<p>When Flame runs this function, it passes a variable called <code>info</code> to it. Think of <code>info</code> as a container (a Python dictionary) that holds the project's ID card: - <code>info[\"project_name\"]</code>: The name of the project. - <code>info[\"project_description\"]</code>: The description text you see in the startup screen.</p> <p>By changing the data inside this container, you change what Flame writes to the database.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#3-code-breakdown","title":"3. Code Breakdown","text":"<p>Let's look at the code line by line:</p> <pre><code>import datetime\n\ndef project_init_conversion(info):\n    # 1. Modify the Name\n    info[\"project_name\"] = info[\"project_name\"] + \" (Converted)\"\n\n    # 2. Modify the Description\n    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    info[\"project_description\"] = \"Converted on {0}\".format(timestamp)\n</code></pre> <ol> <li><code>import datetime</code>: This imports a standard Python tool for working with dates and times.</li> <li><code>info[\"project_name\"] = ...</code>: It takes the current name (e.g., \"MyCommercial\") and adds text to it. The new name becomes \"MyCommercial (Converted)\".</li> <li><code>info[\"project_description\"] = ...</code>:<ul> <li><code>datetime.datetime.now()</code> gets the current moment.</li> <li><code>.strftime(...)</code> formats it into a readable string like \"2026-01-29 14:30:00\".</li> <li>It overwrites the old description with this new timestamp.</li> </ul> </li> </ol>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>This is a perfect example of Workflow Safety. - Organization: You can instantly tell which projects have been migrated just by looking at the list. - Audit Trail: You know exactly when the migration happened. - Automation: You don't have to remember to type this in manually for every single project.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-conversion_description/#5-next-steps-for-you","title":"5. Next Steps for You","text":"<p>Try customizing it! - Challenge: Instead of overwriting the description, can you append the date to the existing description so you don't lose the original text? - Hint: <code>python   # Try this instead:   info[\"project_description\"] = info[\"project_description\"] + \" | Converted on: \" + timestamp</code></p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/","title":"Insight: Using Callable Objects for Custom Actions","text":"<p>This document explains the <code>custom_action_object.py</code> example script. It shows an advanced but very efficient way to create many similar menu items without writing a separate function for each one.</p> <p>Target Audience: Novice Python programmers learning about Classes and \"Callables.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/#1-the-problem-repeating-yourself","title":"1. The Problem: Repeating Yourself","text":"<p>Imagine you want 4 menu items: \"Action 1\", \"Action 2\", \"Action 3\", and \"Action 4\". All of them should do basically the same thing, but they need to know which button was clicked.</p> <p>The \"old\" way would be to write 4 separate functions. That's a lot of copying and pasting!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/#2-the-solution-the-callable-object","title":"2. The Solution: The \"Callable\" Object","text":"<p>In Python, you can create a Class that acts like a function. This is called making an object \"callable.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/#how-it-works","title":"How it works:","text":"<p>Look at the <code>Action</code> class inside the script:</p> <pre><code>class Action(object):\n    def __init__(self, action_id):\n        self._action_id = action_id # Remember which ID I am\n\n    def __call__(self, selection):\n        # This makes the object act like a function!\n        return action_on_selection(self._action_id, selection)\n</code></pre> <ol> <li><code>__init__</code>: When we create <code>Action(\"Action1\")</code>, it saves \"Action1\" inside itself.</li> <li><code>__call__</code>: This is a special Python magic method. It tells Python: \"If someone tries to run this object like a function (using parentheses), run this code.\"</li> </ol>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/#3-why-is-this-powerful","title":"3. Why is this powerful?","text":"<p>Look at how the menu is built in the loop:</p> <pre><code>action_ids = [\"Action1\", \"Action2\", \"Action3\", \"Action4\"]\nfor action_id in action_ids:\n    # We create a NEW object for each ID\n    actions[\"actions\"].append({\n        \"name\": action_id, \n        \"execute\": Action(action_id) # Pass the object as the command\n    })\n</code></pre> <p>By using this trick, you can generate hundreds of menu items dynamically (for example, one for every preset file in a folder) while only writing the logic once.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_action_object/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>If you find yourself writing <code>function1()</code>, <code>function2()</code>, <code>function3()</code> that all look identical, consider using a Callable Class. It keeps your code clean, short, and much easier to fix if you need to change the logic later!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/","title":"Insight: Designing Complex Menus in Flame","text":"<p>This document explains the <code>custom_menu_structure.py</code> example script. It shows how to organize your Python scripts into clean, professional submenus within the Flame interface.</p> <p>Target Audience: Novice Python programmers who want to improve the \"Look and Feel\" of their tools.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#1-organizing-your-tools","title":"1. Organizing Your Tools","text":"<p>When you start writing many scripts, putting them all in one long list makes the Flame UI messy. Professional tools use Submenus, Ordering, and Separators.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#2-the-modern-way-flame-20232","title":"2. The \"Modern\" Way (Flame 2023.2+)","text":"<p>In newer versions of Flame, the API gives you precise control over the menu layout using three key attributes:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#a-hierarchy","title":"A. <code>hierarchy</code>","text":"<p>This tells Flame where to put your menu item. - <code>hierarchy: []</code> means \"put this in the main right-click menu.\" - <code>hierarchy: [\"Example / Add Nodes\"]</code> means \"put this inside the 'Add Nodes' folder.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#b-order","title":"B. <code>order</code>","text":"<p>Normally, Flame lists things alphabetically. <code>order</code> lets you force a specific sequence. - An item with <code>order: 1</code> will always appear above <code>order: 2</code>.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#c-separator","title":"C. <code>separator</code>","text":"<p>Use <code>\"separator\": \"below\"</code> to draw a thin line in the menu. This is great for grouping related tools together (e.g., separating \"Import\" tools from \"Export\" tools).</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#3-code-example-breakdown","title":"3. Code Example Breakdown","text":"<p>The script creates a main category called \"Example / Add Nodes\". Inside that, it creates two sub-folders:</p> <ol> <li>Tools: Contains \"Add Resize\" and \"Add Mono\".</li> <li>Outputs: Contains \"Add Render\" and \"Add Write File\".</li> </ol> <pre><code>{\n    \"name\": \"Tools\",\n    \"hierarchy\": [\"Example / Add Nodes\"], # Put inside the main folder\n    \"order\": 1,                           # Show this folder first\n    \"separator\": \"below\",                 # Put a line under this folder\n    \"actions\": [...]                      # The actual buttons\n}\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#4-supporting-older-versions","title":"4. Supporting Older Versions","text":"<p>The script also shows how to use <code>maximumVersion</code>. - If a user is on an old version of Flame that doesn't support submenus, the script provides a \"flat list\" instead. - Why? This ensures your script doesn't crash if a colleague is using an older version of the software.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-custom_menu_structure/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Good code isn't just about what it does; it's about how easy it is for a human to use. Taking five minutes to organize your menus makes your tools feel like a built-in part of Flame!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/","title":"Insight: Custom File Browsers in Flame","text":"<p>This document explains the <code>import_file_using_custom_dialog.py</code> example script. It shows two different ways to let a user pick files from their computer using Python.</p> <p>Target Audience: Novice Python programmers interested in User Interface (UI) design.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#1-why-not-just-hardcode-paths","title":"1. Why Not Just Hardcode Paths?","text":"<p>If you write a script that always imports <code>C:\\Media\\shot.mov</code>, it only works once. To make a tool useful, you need to let the user browse and select the files they want.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#2-two-different-approaches","title":"2. Two Different Approaches","text":"<p>This script shows two ways to do this:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#a-the-standard-computer-way-qt-pyside6","title":"A. The \"Standard Computer\" Way (Qt / PySide6)","text":"<p>This uses PySide6, which is the industry-standard way to make windows and buttons in Python. - Pros: It looks like a normal Windows or Mac folder window. It's familiar to everyone. - How it works: <code>python   from PySide6 import QtWidgets   dlg = QtWidgets.QFileDialog() # Create a window   if dlg.exec(): # Show the window and wait for the user to click OK       files = dlg.selectedFiles() # Get the list of chosen files</code></p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#b-the-flame-native-way-flamebrowser","title":"B. The \"Flame Native\" Way (<code>flame.browser</code>)","text":"<p>Flame has its own built-in file browser. - Pros: It looks exactly like Flame. It understands Flame-specific things like \"Clips\" and \"Frame Sequences.\" - How it works: <code>python   import flame   flame.browser.show(title=\"Select Clips\", multi_selection=True)   # The user's choice is saved in flame.browser.selection   flame.batch.import_clips(flame.browser.selection, ...)</code></p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#3-scoping-making-the-menu-context-aware","title":"3. Scoping: Making the Menu Context-Aware","text":"<p>The script uses a clever trick to make sure the \"Import\" buttons only appear when you right-click on the background of the Batch schematic:</p> <pre><code>def scope_background(selection):\n    return len(selection) == 0 # Only True if NOTHING is selected\n</code></pre> <p>If you right-click on a clip node, this menu won't show up. This prevents clutter and ensures you don't try to \"import into a clip.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-import_file_using_custom_dialog/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<ul> <li>Use <code>PySide6</code> if you want a standard OS feeling or need special filters (like \"only show .jpg\").</li> <li>Use <code>flame.browser</code> if you want your tool to feel like a native part of the Flame experience.</li> <li>Both ways ultimately give you a Path (a string of text like <code>/Users/pman/Desktop/video.mov</code>) which you then pass to Flame's <code>import_clip()</code> command.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/","title":"Insight: Scoping Tools to Specific Objects","text":"<p>This document explains the <code>object_scoping.py</code> example script. It shows how to make your Python tools \"smart\" so they only appear when they are actually useful.</p> <p>Target Audience: Novice Python programmers who want to clean up their Flame menus.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#1-what-is-scoping","title":"1. What is Scoping?","text":"<p>If you write a script that \"Deletes All Render Nodes,\" you don't want that script to show up when you right-click on a Clip or an Audio Track.</p> <p>Scoping is the process of checking what the user has selected before showing the menu.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#2-three-common-scoping-patterns","title":"2. Three Common Scoping Patterns","text":"<p>The script shows three ways to filter your selection:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#a-background-scoping-nothing-selected","title":"A. Background Scoping (Nothing Selected)","text":"<p>Use this for tools that create new things from scratch, like \"Import Media\" or \"Create New Reel.\"</p> <pre><code>def scope_background(selection):\n    return len(selection) == 0 # True only if the background was clicked\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#b-object-type-scoping-is-it-a-node","title":"B. Object Type Scoping (Is it a Node?)","text":"<p>Use this if your script only works on specific types of Flame objects.</p> <pre><code>def scope_object(selection):\n    for item in selection:\n        if isinstance(item, flame.PyNode): # Is this a Batch Node?\n            return True\n    return False\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#c-specific-node-scoping-is-it-a-comp-node","title":"C. Specific Node Scoping (Is it a 'Comp' Node?)","text":"<p>This is the most precise. It checks the specific kind of node.</p> <pre><code>def scope_node(selection):\n    for item in selection:\n        if isinstance(item, flame.PyNode) and item.type == \"Comp\":\n            return True\n    return False\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#3-how-to-use-it-in-your-menu","title":"3. How to use it in your Menu","text":"<p>Once you've written your scoping function, you simply plug it into your menu definition using the <code>isVisible</code> or <code>isEnabled</code> key:</p> <pre><code>{\n    \"name\": \"My Smart Tool\",\n    \"isVisible\": scope_node, # Flame runs this function automatically!\n    \"execute\": my_main_function\n}\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Prevent Errors: Users can't run a \"Batch\" script on a \"Timeline\" segment by mistake.</li> <li>Cleaner UI: Your right-click menu stays short and relevant to what you are doing.</li> <li>Professionalism: This is how built-in Flame tools work.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-object_scoping/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of scoping as an \"If Statement\" for your menu. Before you write the logic for what your tool does, first decide exactly where it belongs!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/","title":"Insight: Automating Snapshots with Post-Export Hooks","text":"<p>This document explains the <code>post_export_asset_using_snapshot.py</code> example script. It shows how Flame can \"watch\" its own export process and perform an action immediately after a file is saved.</p> <p>Target Audience: Novice Python programmers interested in workflow automation and \"Self-Healing\" pipelines.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#1-what-is-an-export-snapshot","title":"1. What is an \"Export Snapshot\"?","text":"<p>In Flame, a Snapshot is a quick way to save a single frame or a short clip as a file on your hard drive. Usually, once you hit export, the process is finished.</p> <p>The Goal: Every time you take a snapshot in the Player, Flame should automatically re-import that file back onto your Desktop reels.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#2-the-post_export_asset-hook","title":"2. The <code>post_export_asset</code> Hook","text":"<p>Flame has a special \"event\" called <code>post_export_asset</code>. Every time any export finishes, Flame shouts: \"Hey! I just finished exporting something. Does anyone want to do anything with it?\"</p> <p>Our script listens for that shout.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#3-how-the-script-works","title":"3. How the Script Works","text":"<p>The script follows three logic steps:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#step-1-filter-the-noise","title":"Step 1: Filter the Noise","text":"<p>Since this hook runs for every export (even big renders), we first check if this was actually a Snapshot:</p> <pre><code>if info[\"isSnapshot\"]: # Is this a snapshot, or a regular export?\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#step-2-find-the-destination","title":"Step 2: Find the Destination","text":"<p>The script looks at your project and finds the first reel on your Desktop:</p> <pre><code>reel = flame.projects.current_project.current_workspace.desktop.reel_groups[0].reels[0]\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#step-3-re-import-the-file","title":"Step 3: Re-Import the File","text":"<p>Flame tells the script exactly where the file was saved using <code>info[\"destinationPath\"]</code>. The script then tells Flame to import that path:</p> <pre><code>clip_path = os.path.join(info[\"destinationPath\"], info[\"resolvedPath\"])\nflame.import_clips(clip_path, reel)\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#4-why-is-this-powerful","title":"4. Why is this powerful?","text":"<p>This creates a Loop. You can stay in the Player, take snapshots of different versions of a shot, and when you look back at your Desktop, they are all waiting for you in a neat reel. </p> <p>It eliminates the tedious manual task of: 1. Exporting. 2. Opening the MediaHub. 3. Browsing to the folder. 4. Dragging the file in.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_asset_after_snapshot/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Hooks like <code>post_export_asset</code> allow Flame to talk to itself. By using the information Flame provides in the <code>info</code> dictionary, you can bridge the gap between \"Saving a File\" and \"Using a File.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/","title":"Insight: Chaining Complex Jobs with Export Dependencies","text":"<p>This document explains the <code>post_export_dependency.py</code> example script. This is an advanced script that shows how to make multiple tasks happen in a specific order, even if they take a long time.</p> <p>Target Audience: Novice Python programmers interested in \"Pipeline Engineering.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#1-the-concept-wait-for-me","title":"1. The Concept: \"Wait For Me\"","text":"<p>Sometimes, exporting a clip is only the first step. You might want to: 1. Export a clip as a sequence of images. 2. THEN Zip those images into one file. 3. THEN Send an email saying it's done.</p> <p>The problem? Step 2 cannot start until Step 1 is 100% finished. If Step 1 is happening on Backburner (in the background), your script needs a way to wait.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#2-using-backburner-dependencies","title":"2. Using Backburner Dependencies","text":"<p>The \"Magic\" in this script is the Job ID. When Flame sends an export to Backburner, it gets back a unique ID number (e.g., Job #1234). </p> <p>Our script tells Backburner: \"I want to run a Zip command, but DO NOT START until Job #1234 is finished successfully.\" This is called a Dependency.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#3-key-workflows-in-the-script","title":"3. Key Workflows in the Script","text":"<p>The script demonstrates several \"Chain Reactions\":</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#a-export-zip","title":"A. Export &amp; Zip","text":"<p>It exports files and then automatically sends a command to the computer's <code>zip</code> tool.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#b-export-transcode-ffmpeg","title":"B. Export &amp; Transcode (FFmpeg)","text":"<p>It exports high-quality images and then triggers FFmpeg (a famous video tool) to create a small preview movie automatically. - Tip: Look for <code>cmd = \"/usr/local/bin/ffmpeg ...\"</code>. This is how Flame talks to other software on your computer!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#c-export-re-import","title":"C. Export &amp; Re-Import","text":"<p>This is the most advanced. It uses an Idle Loop (<code>flame.schedule_idle_event</code>). - The script checks every 1 second: \"Is the background job done yet?\" - As soon as the answer is \"Yes\", it automatically imports the file back into Batch.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#4-why-use-flameexecute_command","title":"4. Why Use <code>flame.execute_command</code>?","text":"<p>The script mentions a special function <code>flame.execute_command</code>.  - Beginner Tip: In regular Python, people use <code>os.system</code> or <code>subprocess</code>. - Flame Tip: In Flame, using <code>flame.execute_command</code> is much safer and faster because it doesn't \"fork\" (copy) the entire memory of Flame just to run a tiny command.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-post_export_dependency/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>This script shows that Flame isn't just a creative tool; it can be the \"Brain\" of your whole studio. By chaining jobs together using Dependencies, you can build complex, automated workflows that run while you sleep!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/","title":"Insight: Protecting Your Projects with Hooks","text":"<p>This document explains the <code>project_protection.py</code> example script. It shows how to create \"Safety Locks\" that prevent people from accidentally editing or deleting important Flame projects.</p> <p>Target Audience: Novice Python programmers interested in system administration and data safety.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/#1-what-is-project-protection","title":"1. What is Project Protection?","text":"<p>In a busy studio, you might have a project named \"Final_Master_Render\". You don't want a junior artist or a tired editor to accidentally delete it or change its settings.</p> <p>The Solution: A script that automatically blocks certain actions if the project name matches a \"Restricted\" list.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/#2-the-abort-mechanism","title":"2. The \"Abort\" Mechanism","text":"<p>Flame has hooks that run before a project is edited, deleted, or converted: - <code>project_pre_edition</code> - <code>project_pre_delete</code> - <code>project_pre_conversion</code></p> <p>These hooks are special because they allow you to Cancel the action before it happens.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/#3-how-the-script-works","title":"3. How the Script Works","text":"<p>The script defines a list of \"Danger\" names:</p> <pre><code>restricted_project_names = [\"final\", \"final_final\"]\n</code></pre> <p>Then, it creates a <code>check</code> function that looks at the current project:</p> <pre><code>def check(info):\n    # If the name is in our list, set 'abort' to True\n    info[\"abort\"] = info[\"project_name\"] in restricted_project_names\n\n    # Give the user a reason why it failed\n    info[\"abort_message\"] = \"This project is flagged as restricted.\"\n</code></pre> <p>When <code>info[\"abort\"]</code> is set to <code>True</code>, Flame stops whatever it was doing and pops up a message box with your <code>abort_message</code>.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Zero Accidents: It's impossible to delete a \"protected\" project while this script is active.</li> <li>Workflow Control: You can ensure that only specific projects (like those following a naming convention) can be modified.</li> <li>Peace of Mind: You don't have to rely on \"Common Sense\" when you have a script enforcing the rules!</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-project_protection/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Hooks with an <code>abort</code> option are like Security Guards. They stand at the door and check IDs before letting anyone change your important data. </p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/","title":"Insight: Talking to the User (Console vs. Dialogs)","text":"<p>This document explains the <code>show_messages.py</code> example script. It shows how your Python script can \"talk\" back to the person using Flame, either quietly in the corner or with a pop-up window.</p> <p>Target Audience: Novice Python programmers interested in User Experience (UX).</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#1-two-ways-to-communicate","title":"1. Two Ways to Communicate","text":"<p>When your script runs, it often needs to tell the user something. Flame provides two main channels for this:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#a-the-console-message-bar-show_in_console","title":"A. The Console / Message Bar (<code>show_in_console</code>)","text":"<p>This is the small text bar at the bottom of the Flame screen. Use this for non-critical info that doesn't need to stop the user's flow. - Example: A countdown or a status update. - Code: <code>python   flame.messages.show_in_console(\"Processing clip...\", \"info\", duration=5)</code> - Types: You can use <code>\"info\"</code>, <code>\"warning\"</code>, or <code>\"error\"</code> to change the color/priority.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#b-the-dialog-box-show_in_dialog","title":"B. The Dialog Box (<code>show_in_dialog</code>)","text":"<p>This is a \"modal\" pop-up. It stops everything and waits for the user to click a button. Use this for critical errors or when you need the user to make a choice. - Example: Telling the user they forgot to select a clip. - Code: <code>python   flame.messages.show_in_dialog(       title=\"Error\",       message=\"Please select a clip first!\",       type=\"error\",       buttons=[\"OK\"]   )</code></p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#2-practical-examples-in-the-script","title":"2. Practical Examples in the Script","text":""},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#the-countdown","title":"The Countdown","text":"<p>The <code>countdown</code> function shows how you can update the console in real-time. It uses <code>time.sleep(1)</code> to wait one second between numbers.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#the-disk-space-checker","title":"The Disk Space Checker","text":"<p>The <code>freespace</code> function uses a standard Python tool (<code>shutil</code>) to check your hard drive.  - If you have plenty of space, it shows an Info message (usually green/white). - If space is low, it shows a Warning message (usually yellow/orange).</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#the-error-catcher","title":"The Error Catcher","text":"<p>The <code>set_batch_duration</code> function tries to set the length of a Batch group. If it fails (because there's no clip), it uses a Dialog Box to explain exactly what went wrong.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-show_messages/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<ul> <li>Use the Console for \"FYI\" messages (Status updates, progress).</li> <li>Use Dialogs for \"STOP\" messages (Errors, confirmations, questions).</li> </ul> <p>Always try to give the user helpful information. A script that fails silently is frustrating; a script that says \"No Clip Found\" is helpful!</p>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/","title":"Insight: Managing Version Compatibility","text":"<p>This document explains the <code>version_scoping_hooks.py</code> example script. It shows how to ensure your Python tools only appear in versions of Flame where they actually work.</p> <p>Target Audience: Novice Python programmers sharing scripts with a team.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#1-the-version-headache","title":"1. The Version Headache","text":"<p>Sometimes, Autodesk adds a new feature to Flame 2026 that didn't exist in 2024. If you write a script using that new feature and give it to a friend using the older version, the script might crash or cause errors.</p> <p>The Solution: Version Scoping. You can tell Flame: \"Only show this menu item if the software version is between X and Y.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#2-two-ways-to-set-limits","title":"2. Two Ways to Set Limits","text":"<p>The script shows two different places where you can set version limits:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#a-inside-the-menu-dictionary-minimumversion","title":"A. Inside the Menu Dictionary (<code>minimumVersion</code>)","text":"<p>This is the most common way. You add it directly to the button definition.</p> <pre><code>{\n    \"name\": \"Super New Tool\",\n    \"execute\": my_function,\n    \"minimumVersion\": \"2026.1\" # Only shows up in 2026.1 or newer\n}\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#b-on-the-function-itself-minimum_version","title":"B. On the Function Itself (<code>minimum_version</code>)","text":"<p>This is a more \"global\" way to block an entire set of tools. You set it after the function is defined:</p> <pre><code>def get_batch_custom_ui_actions():\n    ...\n\nget_batch_custom_ui_actions.minimum_version = \"2023.0\"\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#3-how-version-numbers-work","title":"3. How Version Numbers Work","text":"<p>Flame version numbers follow a specific pattern: <code>Year.Minor.Patch</code> - <code>2026</code>: Works for any version of 2026. - <code>2026.1</code>: Only works for 2026 Update 1 or newer. - <code>2026.1.2</code>: Only works for a very specific bug-fix release.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Prevent Crashes: You don't have to worry about old versions of Flame trying to run code they don't understand.</li> <li>Easy Maintenance: You can keep one \"Super Script\" that has different buttons for different versions of the software.</li> <li>Professionalism: Your tools feel reliable and well-tested across the whole studio.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-version_scoping_hooks/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of Version Scoping as a \"System Requirement\" for your script. By setting these limits, you are protecting your users from seeing tools that won't work on their specific version of Flame.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/","title":"Insight: Managing the Wait Cursor","text":"<p>This document explains the <code>wait_cursor.py</code> example script. It shows how to control that spinning \"loading\" icon so your users don't get frustrated when using your tools.</p> <p>Target Audience: Novice Python programmers interested in User Experience (UX).</p>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#1-what-is-the-wait-cursor","title":"1. What is the Wait Cursor?","text":"<p>In Flame, when a script is running, the mouse cursor usually turns into a \"Wait\" icon (a spinning circle or watch). This tells the user: \"The computer is busy, please don't click anything.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#2-when-to-hide-it","title":"2. When to Hide It","text":"<p>Sometimes, you want the user to click something while your script is running! - Example: You pop up a window asking the user to \"Select a Folder.\" - The Problem: If the cursor is stuck in \"Wait\" mode, the user can't interact with your pop-up window properly.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#3-how-to-control-it","title":"3. How to Control It","text":"<p>In your menu definition, you can use the <code>waitCursor</code> key:</p>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#a-for-long-tasks-waitcursor-true","title":"A. For Long Tasks (<code>waitCursor: True</code>)","text":"<p>If your script is doing a lot of math or moving files, keep the wait cursor on.</p> <pre><code>{\n    \"name\": \"Process 1000 Clips\",\n    \"execute\": my_long_function,\n    \"waitCursor\": True # This is the default\n}\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#b-for-interactive-tasks-waitcursor-false","title":"B. For Interactive Tasks (<code>waitCursor: False</code>)","text":"<p>If your script shows a window or asks a question, turn the wait cursor off so the mouse works normally.</p> <pre><code>{\n    \"name\": \"Show My Custom Window\",\n    \"execute\": show_window_function,\n    \"waitCursor\": False # Gives control back to the user\n}\n</code></pre>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Reduced Frustration: There is nothing worse than a pop-up window you can't click because your mouse is \"stuck\" in a loading state.</li> <li>Clarity: It tells the user exactly when it's safe to interact with Flame and when they should wait.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-wait_cursor/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>If your script opens a window (using <code>PySide6</code> or <code>flame.messages.show_in_dialog</code>), you should almost always set <code>\"waitCursor\": False</code>. If your script runs in the background with no windows, keep it <code>True</code>.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/","title":"Insight: Creating a \"Watch Folder\" in Flame","text":"<p>This document explains the <code>watch_folder.py</code> example script. It shows how to make Flame perform background tasks without freezing the user interface.</p> <p>Target Audience: Novice Python programmers interested in automation and \"Background Tasks.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/#1-what-is-a-watch-folder","title":"1. What is a \"Watch Folder\"?","text":"<p>A Watch Folder is a folder on your computer that a script monitors. Whenever you drop a file into that folder, the script automatically \"wakes up\" and imports that file into Flame.</p>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/#2-the-secret-schedule_idle_event","title":"2. The Secret: <code>schedule_idle_event</code>","text":"<p>If you write a simple Python script that says <code>while True: look_for_files()</code>, Flame will freeze. This is because Python is taking up 100% of Flame's attention.</p> <p>The Solution: Use Flame's \"Idle\" loop. Flame has a special feature called <code>schedule_idle_event</code>. It tells Flame: \"Hey, next time the artist is NOT clicking anything, run this function for a split second.\"</p>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/#3-how-the-script-works","title":"3. How the Script Works","text":"<ol> <li>Start on Startup: The script uses the <code>app_initialized</code> hook to start looking for files as soon as Flame opens.</li> <li>The Check: It looks inside <code>/var/tmp/watch_folder</code>.</li> <li>The Import: If it finds a new file, it imports it into a library named \"Watch Folder.\"</li> <li>The Relay Race: After importing one file, the script doesn't just keep going. It says: \"I'm done for now. Flame, please call me again in 1 second.\" <code>python     flame.schedule_idle_event(do_watch_folder, delay=1)</code></li> </ol>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/#4-why-is-this-powerful","title":"4. Why is this powerful?","text":"<ul> <li>Zero Lag: Because the script only runs during \"Idle\" time, the artist can keep working, editing, and color grading without noticing the script is running.</li> <li>Workflow Speed: You can have an external assistant or another software (like a 3D renderer) drop files into the folder, and they magically appear in Flame without any manual work.</li> </ul>"},{"location":"insight/adsk/python_utilities/examples/insight-watch_folder/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>In Flame, never use long <code>while</code> loops. Instead, use <code>schedule_idle_event</code> to break your big task into tiny pieces that run only when Flame isn't busy. This keeps the software responsive and your workflow smooth!</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/","title":"Insight: Automating QuickTime Transcoding from Batch","text":"<p>This document explains the <code>batch_write_file_quicktime.py</code> script. It shows how to automatically create a QuickTime movie whenever a \"Write File\" node finishes rendering in Batch.</p> <p>Target Audience: Novice Python programmers interested in render automation.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#1-what-is-the-goal","title":"1. What is the Goal?","text":"<p>In Flame's Batch environment, a Write File node is often used to export image sequences (like OpenEXR). However, after the render is done, you might also need a QuickTime file for review.</p> <p>This script automates that second step. As soon as the Write File node finishes its work, this script picks up the images and converts them into a QuickTime movie.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#a-the-batch_export_end-hook","title":"A. The <code>batch_export_end</code> Hook","text":"<p>This is the \"trigger.\" Flame runs this function automatically when a Batch export completes. It provides an <code>info</code> dictionary containing the path to the newly rendered files.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#b-dynamic-preset-paths","title":"B. Dynamic Preset Paths","text":"<p>The script uses <code>flame.PyExporter.get_presets_dir()</code>. This is better than hardcoding a path because it asks Flame: \"Where do you keep your official Autodesk QuickTime presets?\" This makes the script work on any computer, regardless of where Flame is installed.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#3-how-the-script-works","title":"3. How the Script Works","text":"<ol> <li>Find the Media: It uses <code>os.path.join</code> to combine the export folder and the filename into one full path.</li> <li>Import: It tells Flame to \"look\" at those new files using <code>flame.import_clips(full_path)</code>.</li> <li>Setup the Exporter:<ul> <li>It creates an instance of <code>flame.PyExporter</code>.</li> <li>It sets <code>exporter.foreground = True</code>. This means Flame will focus entirely on making the QuickTime until it is finished.</li> </ul> </li> <li>Export: It runs the <code>export()</code> command using the official \"8-bit Uncompressed\" preset.</li> </ol>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Saves Time: You don't have to manually create a new export job after every render.</li> <li>Consistency: Every render automatically gets a matching QuickTime file in the same folder.</li> <li>Simplicity: For the artist, they just hit \"Render\" in Batch, and both the image sequence and the movie appear.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-batch_write_file_quicktime/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>This script is a perfect example of a \"Post-Process.\" By using the information provided by a hook (<code>info[\"exportPath\"]</code>), you can chain multiple Flame operations together into a single automated workflow.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/","title":"Insight: Automating Motion Vector Caching","text":"<p>This document explains the <code>cache_motion_vectors.py</code> script. It shows how to programmatically build a \"Node Tree\" in Batch to calculate and save motion vectors.</p> <p>Target Audience: Novice Python programmers learning how to manipulate the Batch Schematic.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#1-what-are-motion-vectors","title":"1. What are Motion Vectors?","text":"<p>Motion vectors are data that describe how pixels move from one frame to the next. In Flame, calculating this can be slow, so we often \"Cache\" (save) the results. </p> <p>The Goal: Instead of manually adding an \"Action\" node, adding a \"Motion Vectors Map,\" and clicking \"Cache,\" this script does it all in one click.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#a-node-creation-positioning","title":"A. Node Creation &amp; Positioning","text":"<p>The script uses <code>flame.batch.create_node(\"Action\")</code>.  - Coordinates: It uses <code>pos_x</code> and <code>pos_y</code> to place the nodes neatly in the schematic. It adds <code>400</code> to the X-position so the new node doesn't overlap the old one.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#b-connecting-nodes","title":"B. Connecting Nodes","text":"<p>To make the nodes work, they must be \"wired\" together.</p> <pre><code>flame.batch.connect_nodes(clip, \"Default\", media, \"Default\")\n</code></pre> <p>This is like dragging a line between two dots in the Batch interface.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#c-caching-a-range","title":"C. Caching a Range","text":"<p>The script finds the start and end frame of the clip and tells the node to render exactly that range:</p> <pre><code>motion_map.cache_range(start, end)\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#3-two-ways-to-use-the-script","title":"3. Two Ways to Use the Script","text":"<ol> <li>In Batch: Right-click a clip node and select \"Cache Motion Vectors Map.\"</li> <li>From the Desktop: Right-click your Desktop and select \"Create Batch and Cache...\".<ul> <li>This version is even more powerful! It opens a file browser, lets you pick a clip, creates a brand new Batch Group, imports the clip, and then sets up the motion vectors.</li> </ul> </li> </ol>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Standardization: It ensures that every Motion Vector Map is set up exactly the same way every time.</li> <li>Speed: It handles all the tedious clicking and dragging of nodes automatically.</li> <li>Batch Processing: You can use the \"Desktop\" version to process a file without even having a Batch group open yet.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-cache_motion_vectors/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>When you use the Python API, you are basically a \"Ghost Operator.\" Anything a human can do with a mouse (creating nodes, connecting them, clicking 'Cache'), you can do with code by calling the right functions.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/","title":"Insight: Deep-Cleaning Project Iterations","text":"<p>This document explains the <code>clean_batch_iteration.py</code> script. It shows how to save disk space by deleting old \"Iterations\" (saved versions) of your Batch work.</p> <p>Target Audience: Novice Python programmers interested in project maintenance and \"Recursion.\"</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/#1-what-are-batch-iterations","title":"1. What are Batch Iterations?","text":"<p>Every time you save your work in Batch, Flame creates an \"Iteration.\" Over a long project, these can add up to hundreds of files, taking up a lot of space on your storage.</p> <p>The Goal: A \"Nuclear Option\" to delete all iterations from a specific Folder, Library, or even your entire Desktop.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/#2-key-concept-recursion","title":"2. Key Concept: Recursion","text":"<p>This script uses a very important programming technique called Recursion.</p> <p>Imagine a Library contains a Folder, which contains another Folder, which finally contains a Batch Group. To find that Batch Group, the script has to \"dig\" through the folders.</p> <p>The <code>find_batch_group</code> function does this: 1. It looks for Batch Groups in the current folder and cleans them. 2. It then looks for more folders inside the current one. 3. If it finds a folder, it calls itself to look inside that new folder.</p> <pre><code>def find_batch_group(folder):\n    # ... clean things here ...\n    for folders in folder.folders:\n        find_batch_group(folders) # Calling itself!\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/#3-how-the-script-works","title":"3. How the Script Works","text":"<ul> <li>Multiple Scopes: The script is smart. It checks if you clicked on a Library, a Folder, or a Batch Group and uses the correct logic for each one.</li> <li>Silent Delete: It uses <code>flame.delete(iteration, confirm=False)</code>. </li> <li>Warning: Setting <code>confirm=False</code> means Flame won't ask \"Are you sure?\" It just deletes them instantly. This is fast, but dangerous!</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Storage Management: It's the fastest way to \"slim down\" a project before archiving it.</li> <li>Organization: It removes the clutter of old, failed experiments and keeps only the current work.</li> <li>Workflow Speed: Instead of opening 50 Batch Groups and deleting iterations manually, you click one button on the top-level Library.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-clean_batch_iteration/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Recursion is the best way to deal with \"Tree\" structures (like folders inside folders). Instead of writing complex logic to guess how deep the folders go, you just tell the function to keep digging until it hits the bottom.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/","title":"Insight: Personalized Shared Libraries","text":"<p>This document explains the <code>create_user_shared_library.py</code> script. It shows how to use the current user's name to automatically organize a project.</p> <p>Target Audience: Novice Python programmers interested in project management and user data.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#1-what-is-the-goal","title":"1. What is the Goal?","text":"<p>In a facility where many artists work on the same project, it's good practice for each artist to have their own Shared Library. This prevents people from accidentally overwriting each other's work.</p> <p>The Goal: Instead of manually creating a library and typing your name, this script finds out who is currently logged into Flame and builds a library for them automatically.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#a-fetching-the-current-user","title":"A. Fetching the Current User","text":"<p>Flame always knows who is using it. You can access this information through:</p> <pre><code>user_name = flame.users.current_user.name\n</code></pre> <p>This returns a simple string, like <code>\"JohnDoe\"</code>.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#b-creating-a-shared-library","title":"B. Creating a Shared Library","text":"<p>A Shared Library is special because other people on the network can see it.</p> <pre><code>flame.projects.current_project.create_shared_library(user_name)\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Zero Typos: The library name always matches the Flame user profile exactly.</li> <li>Speed: One click and your workspace is set up.</li> <li>Teamwork: It encourages everyone to use shared storage correctly from the start.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-create_user_shared_library/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>flame</code> module isn't just for clips and nodes; it also holds information about the Environment. By combining \"Environment Data\" (the User Name) with \"Project Actions\" (Creating a Library), you can build tools that feel personalized and intelligent.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/","title":"Insight: Exporting the \"Current Frame\"","text":"<p>This document explains the <code>export_current_frame.py</code> script. It shows how to grab exactly what you are looking at in the player and save it as a high-quality Jpeg.</p> <p>Target Audience: Novice Python programmers learning about non-destructive editing.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#1-the-challenge-single-frame-export","title":"1. The Challenge: Single Frame Export","text":"<p>Flame's exporter usually wants to export a whole clip. If you only want the frame your playhead is on, you have to be clever.</p> <p>The Strategy: 1. Find the current time. 2. Duplicate the clip (so we don't ruin the original). 3. Set the In/Out points of the duplicate to that single frame. 4. Export and then Delete the duplicate.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#a-clip-duplication","title":"A. Clip Duplication","text":"<pre><code>duplicate_clip = flame.duplicate(clip)\n</code></pre> <p>Why do this? If you change the In/Out marks on the original clip, the artist will lose their edit! Duplicating creates a \"disposable\" copy that we can change safely.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#b-mark-manipulation","title":"B. Mark Manipulation","text":"<pre><code>duplicate_clip.in_mark = clip.current_time.get_value()\nduplicate_clip.out_mark = clip.current_time.get_value() + 1\n</code></pre> <p>This tells the duplicate clip: \"Your start is the current frame, and your end is one frame later.\"</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#c-the-tryfinally-block","title":"C. The <code>try...finally</code> Block","text":"<p>This is a \"Safety Net.\"</p> <pre><code>try:\n    # Do the export...\nfinally:\n    flame.delete(duplicate_clip)\n</code></pre> <p>The <code>finally</code> part runs no matter what\u2014even if the export crashes. This ensures that Flame's memory doesn't get cluttered with thousands of hidden duplicate clips.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#3-finding-the-save-location","title":"3. Finding the Save Location","text":"<p>The script uses a neat trick to find where to save the file. It tries to use the path you currently have open in the MediaHub. This is very intuitive for the user!</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_current_frame/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Always be Non-Destructive. If your script needs to change a clip's settings just for a moment, consider creating a duplicate, doing the work, and then cleaning up after yourself.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/","title":"Insight: Bulk Export &amp; FFmpeg Integration","text":"<p>This document explains the <code>export_selection.py</code> script. This is a \"Power User\" script that handles everything from exporting thumbnails to talking to external software like FFmpeg.</p> <p>Target Audience: Intermediate Python programmers interested in external integrations.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#1-what-does-it-do","title":"1. What does it do?","text":"<p>This script provides several professional export options for your selection: 1. Thumbnail + Movie: Saves a Jpeg of the first frame AND a QuickTime file. 2. Recursive Export: If you select a folder, it digs through and exports everything inside it, keeping your folder structure organized. 3. FFmpeg Export: This is the most advanced part. It bypasses Flame's built-in exporter and uses a third-party tool (FFmpeg) to create movies.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#2-key-concepts-the-ffmpeg-bridge","title":"2. Key Concepts: The FFmpeg Bridge","text":"<p>How does Flame talk to FFmpeg? It's a three-step dance:</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#step-1-named-pipes-osmkfifo","title":"Step 1: Named Pipes (<code>os.mkfifo</code>)","text":"<p>The script creates a \"Pipe\"\u2014a virtual file that exists only in the computer's memory. It uses this to stream audio data from Flame directly into FFmpeg.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#step-2-read_frame-and-read_audio","title":"Step 2: <code>read_frame</code> and <code>read_audio</code>","text":"<p>Autodesk provides \"Command Line\" versions of Flame's engine called <code>read_frame</code> and <code>read_audio</code>. The script runs these in the background to pull raw data out of Flame's database.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#step-3-subprocess-piping","title":"Step 3: Subprocess Piping","text":"<p>The script \"pipes\" the video from <code>read_frame</code> into FFmpeg's input.</p> <pre><code>ffmpeg_process = subprocess.Popen(..., stdin=read_frame_process.stdout)\n</code></pre> <p>This is like connecting a fire hose from one machine (Flame) to another (FFmpeg).</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#3-foreground-vs-background","title":"3. Foreground vs. Background","text":"<ul> <li>Foreground: Your mouse turns into a wait cursor, and you wait for FFmpeg to finish.</li> <li>Background: The script creates a Backburner job. It actually writes a tiny Python script on the fly and tells Backburner to run it on a render node!</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Custom Formats: Flame's built-in exporter is great, but FFmpeg can do anything (like making tiny H.264 files for WhatsApp or adding custom text overlays).</li> <li>Efficiency: You can offload heavy transcoding to other computers on your network.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-export_selection/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Flame is an \"Open\" system. You aren't limited to the buttons inside the software. By using <code>subprocess</code> and external tools, you can bridge Flame to any other software on your computer.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/","title":"Insight: Injecting Metadata into OpenEXR Files","text":"<p>This document explains the <code>inject_metadata_write_file_exr.py</code> script. It shows how to embed important information (like the project name and user) directly into the headers of your rendered files.</p> <p>Target Audience: Novice Python programmers interested in pipeline data and metadata.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#1-why-inject-metadata","title":"1. Why Inject Metadata?","text":"<p>When you render a shot as an OpenEXR sequence, the files go onto a server where other artists (like compositors or colorists) pick them up. If they have a problem with a file, they need to know: - Which project did this come from? - Which version of Flame rendered it? - Who was the artist?</p> <p>This script automates that bookkeeping. It \"tags\" every frame with this info invisibly inside the file header.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#a-the-batch_export_begin-hook","title":"A. The <code>batch_export_begin</code> Hook","text":"<p>Unlike the <code>end</code> hook, this one runs before the first frame is written. This is the perfect time to set the \"Rules\" for the render.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#b-targeting-the-write-file-node","title":"B. Targeting the \"Write File\" Node","text":"<p>The script finds the specific node doing the work:</p> <pre><code>write_file = flame.batch.get_node(info.get(\"nodeName\"))\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#c-channel-specific-metadata","title":"C. Channel-Specific Metadata","text":"<p>OpenEXR files can have many channels (Red, Green, Blue, Alpha, Depth). The script iterates through every channel and injects the same metadata into all of them so the info is never lost.</p> <pre><code>write_file.set_metadata_value(channel_name, key, value)\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#3-what-information-is-saved","title":"3. What Information is Saved?","text":"<p>The script currently saves: - <code>flame/version</code>: The version of Flame used. - <code>flame/project</code>: The name of the project. - <code>flame/workspace</code>: The artist's workspace. - <code>flame/user</code>: The artist's name.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Traceability: You can always find the source of a file, even years later.</li> <li>Automation: Other software (like ShotGrid or Deadline) can read these headers to automatically organize files.</li> <li>Accuracy: It removes the need for artists to manually type notes into the render settings.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-inject_metadata_write_file_exr/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Metadata is the \"DNA\" of a digital file. By using the <code>set_metadata_value</code> function, you are ensuring that your files carry their history with them wherever they go.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/","title":"Insight: Managing Archived Clips","text":"<p>This document explains the <code>managed_archived_clips.py</code> script. It shows how to use Python to quickly see which of your clips have been safely backed up and which ones are still sitting on your local storage.</p> <p>Target Audience: Novice Python programmers interested in data management and visual feedback.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#1-the-challenge-what-is-archived","title":"1. The Challenge: What is Archived?","text":"<p>When working on a large project, you often archive (back up) clips to a tape or a server. Once they are archived, you might want to: 1. Identify them quickly without looking at a list. 2. Delete them to save local space, but only if you're sure they are safe.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#2-key-concepts-archive-properties","title":"2. Key Concepts: Archive Properties","text":"<p>Flame objects have hidden \"Archive\" properties that Python can read: - <code>item.archive_date</code>: Tells you when the clip was successfully backed up. - <code>item.archive_error</code>: Tells you if the backup failed.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#3-how-the-script-works","title":"3. How the Script Works","text":"<p>The script provides two professional tools:</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#a-visual-audit-color-coding","title":"A. Visual Audit (Color Coding)","text":"<p>It goes through your selection and changes the color of the clips in the Media Panel: - Green: Successfully Archived. - Red: Archive Failed (Error). - Default: Not yet archived.</p> <pre><code>if item.archive_error:\n    item.colour = (1.0, 0.0, 0.0) # Red\nelif item.archive_date:\n    item.colour = (0.0, 1.0, 0.0) # Green\n</code></pre>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#b-safe-cleanup","title":"B. Safe Cleanup","text":"<p>It removes clips from your project, but it uses a safety check:</p> <pre><code>if item.archive_date and not item.archive_error:\n    flame.delete(item)\n</code></pre> <p>This ensures you never delete a clip that hasn't been successfully backed up first.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Confidence: You can see at a glance that your work is safe.</li> <li>Organization: It makes it easy to keep your local project \"lean\" by removing old files.</li> <li>Troubleshooting: Red clips immediately show you where a backup failed, so you can fix it.</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-manage_archived_clips/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Using <code>item.colour</code> is a great way to give Visual Feedback to the user. Instead of just printing a text list, changing the UI colors makes your script much more intuitive and \"integrated\" into the Flame experience.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/","title":"Insight: Bridging Flame and the OS","text":"<p>This document explains the <code>path_of_selected_clips.py</code> script. It shows how to jump from inside Flame's MediaHub directly into your computer's file browser (like Finder or Nautilus).</p> <p>Target Audience: Novice Python programmers interested in Operating System (OS) integration.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#1-what-is-the-goal","title":"1. What is the Goal?","text":"<p>Sometimes you see a clip in Flame's MediaHub and you think: \"I need to see this file on my hard drive to rename it or copy it.\" Normally, you'd have to open a new window and manually browse to that folder.</p> <p>This script creates a shortcut. You right-click the clip in Flame, and the folder pops open on your desktop instantly.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#2-key-concepts","title":"2. Key Concepts","text":""},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#a-detecting-the-os","title":"A. Detecting the OS","text":"<p>Computers work differently. A Mac uses <code>open</code>, while Linux usually uses <code>nautilus</code>. The script checks which system you are on using <code>os.uname()</code>.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#b-flameexecute_command","title":"B. <code>flame.execute_command</code>","text":"<p>This is a high-performance way for Flame to talk to the rest of the computer.  - The \"Old\" way: Using <code>subprocess.call</code>. - The \"Flame\" way: <code>flame.execute_command</code>. This is better because it doesn't slow down Flame's memory while the external window is open.</p>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#3-how-the-script-works","title":"3. How the Script Works","text":"<ol> <li>Get the Path: It looks at the selected item and finds its location on the server/hard drive.</li> <li>Handle Files vs Folders: If you clicked a specific file, the script is smart enough to find the \"Parent Folder\" so it can open the right directory.</li> <li>Run the Browser: It builds a command like <code>/usr/bin/open /Volumes/Media/Shots</code> and tells the OS to run it.</li> </ol>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Speed: It saves you from the \"Deep Folder Dive\" through your OS.</li> <li>Verification: It's the fastest way to confirm exactly where a file lives on the physical server.</li> <li>Workflow Bridge: It makes it easy to move between Flame and other software (like checking files in a text editor or a specialized player).</li> </ul>"},{"location":"insight/adsk/python_utilities/scripts/insight-path_of_selected_clips/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Your Python scripts can be a \"Bridge\" between different worlds. By using a few simple OS commands, you can make Flame feel like it's deeply connected to the rest of your computer.</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/","title":"Insight: Autodesk Flame &amp; ComfyUI Integration","text":"<p>This document outlines the architectural strategies for connecting Autodesk Flame (a high-end VFX finishing system) with ComfyUI (a modular generative AI engine).</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#integration-philosophy","title":"Integration Philosophy","text":"<p>To maintain the professional standards of a VFX pipeline, the integration must prioritize High Dynamic Range (HDR) fidelity, frame accuracy, and stateless execution.</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#tier-1-shared-storage-the-pybox-standard","title":"Tier 1: Shared Storage (The \"Pybox\" Standard)","text":"<p>Status: Recommended for Production Finishing</p> <p>This method mimics the native Flame \"Pybox\" architecture. It relies on a shared, high-speed filesystem (NVMe or RAM Disk) accessible by both the Flame workstation and the ComfyUI worker.</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#workflow","title":"Workflow:","text":"<ol> <li>Render: Flame Batch/Timeline renders a segment to a shared directory.</li> <li>Signal: <code>fu_whisper</code> sends a JSON payload to ComfyUI's <code>/prompt</code> endpoint.</li> <li>Reference: The JSON contains the absolute file path to the image.</li> <li>Custom Node: ComfyUI uses a custom node (e.g., <code>LoadImageFromPath</code>) to pull the EXR directly into the tensor graph.</li> <li>Return: ComfyUI writes the result to a \"results\" folder, and Flame reads it back via a Clip node or Write File node.</li> </ol>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#why-this-is-optimal","title":"Why this is optimal:","text":"<ul> <li>HDR Preservation: Supports 16-bit Half-Float OpenEXR, maintaining ACEScg or ARRI LogC4 color space without clipping.</li> <li>Speed: Zero network overhead for large 4K/8K frames.</li> <li>Metadata: Metadata (Timecode, Shot Name) remains synchronized via the sidecar JSON.</li> </ul>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#tier-2-api-stream-httpwebsockets","title":"Tier 2: API-Stream (HTTP/WebSockets)","text":"<p>Status: Recommended for Remote/Cloud AI Workers</p> <p>Use this when ComfyUI is running on a remote GPU farm or a separate machine without a shared mount point.</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#workflow_1","title":"Workflow:","text":"<ol> <li>Upload: <code>fu_whisper</code> reads the frame from disk and sends an HTTP <code>POST</code> to ComfyUI's <code>/upload/image</code> endpoint.</li> <li>Execute: Submit the workflow JSON referencing the newly uploaded filename.</li> <li>Monitor: Use WebSockets to track progress and retrieve the final binary stream.</li> </ol>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#trade-offs","title":"Trade-offs:","text":"<ul> <li>Format Constraints: Often limited to 8-bit or 10-bit PNG/WebP to reduce transfer times.</li> <li>Latency: Dependent on local network speeds (10GbE recommended for VFX).</li> </ul>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#tier-3-live-buffer-ndi-raw-tensors","title":"Tier 3: Live Buffer (NDI / Raw Tensors)","text":"<p>Status: Experimental / Pre-viz Only</p> <p>For real-time \"AI Filter\" behavior in the Flame viewport.</p>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#workflow_2","title":"Workflow:","text":"<ul> <li>NDI: Flame outputs its viewport via an NDI sender. ComfyUI listens via an NDI receiver node, processes the latent noise, and sends it back.</li> <li>Direct Memory: Using Python's <code>mmap</code> or shared shared memory buffers (highly complex implementation).</li> </ul>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#trade-offs_1","title":"Trade-offs:","text":"<ul> <li>Quality: Usually restricted to 8-bit sRGB.</li> <li>Stability: Harder to guarantee frame-accuracy for final renders.</li> </ul>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#implementation-via-fu_whisper","title":"Implementation via <code>fu_whisper</code>","text":"<p>The MCP server (<code>fu_whisper</code>) should act as the orchestrator. A typical tool call would look like:</p> <pre><code># Conceptual fu_whisper tool\ndef trigger_comfy_workflow(workflow_id, source_frame_path):\n    # 1. Read the workflow JSON template\n    # 2. Inject source_frame_path into the 'LoadImage' node\n    # 3. Post to ComfyUI API\n    # 4. Wait for completion\n    # 5. Signal Flame to refresh the result clip\n</code></pre>"},{"location":"insight/comfyui/insight-flame-comfyui-integration/#recommended-data-formats","title":"Recommended Data Formats","text":"Purpose Format Bit Depth Final Finishing OpenEXR 16-bit Float Texture Gen TIFF or OpenEXR 16-bit Int/Float Pre-viz / Speed WebP (Lossless) 8-bit <p>Analysis performed on 2026-02-01.</p>"},{"location":"insight/flame_api/colour_management/","title":"Colour Management API","text":"<p>Source: Autodesk Flame Family 2026 Help | Colour Management API</p> <p>The Colour Management API allows you to control Flame's colour pipeline, including tagging clips, applying transforms, and managing OCIO context variables.</p>"},{"location":"insight/flame_api/colour_management/#core-concepts","title":"Core Concepts","text":"<ul> <li>Tagging: Setting the metadata that identifies the colour space of source media.</li> <li>Transforms: Converting from one space to another (Input, View, or Colour Transform).</li> <li>Context Variables: Changing OCIO variables (e.g., <code>SHOT</code>, <code>SEQ</code>) to dynamically load looks or transforms.</li> </ul>"},{"location":"insight/flame_api/colour_management/#workflows","title":"Workflows","text":""},{"location":"insight/flame_api/colour_management/#1-tagging-media","title":"1. Tagging Media","text":"<p>You can tag the colour space of clips in Batch, Timeline, or MediaHub.</p> <p>Batch:</p> <pre><code># Get a node's output colour space\ncs = flame.batch.get_node(\"Read\").colour_space\n\n# Tag a stream using a Colour Mgmt node\ntagger = flame.batch.create_node(\"Colour Mgmt\")\ntagger.mode = \"Tag Only\"\ntagger.tagged_colour_space = \"ACEScg\"\n</code></pre> <p>Timeline:</p> <pre><code># Get colour space at specific frame\nseq = flame.timeline.current_segment\ncs = seq.get_colour_space(flame.PyTime(10))\n\n# Apply Tagging FX\nfx = seq.create_effect(\"Source Colour Mgmt\")\nfx.mode = \"Tag Only\"\nfx.tagged_colour_space = \"ACEScct\"\n</code></pre> <p>MediaHub:</p> <pre><code>flame.mediahub.files.options.set_tagged_colour_space(\"ACES2065-1\")\n</code></pre>"},{"location":"insight/flame_api/colour_management/#2-applying-transforms","title":"2. Applying Transforms","text":"<p>Use the <code>Colour Mgmt</code> node or effect to apply transforms.</p> <pre><code>cm = flame.batch.create_node(\"Colour Mgmt\")\n\n# Method A: Standard Transforms\ncm.mode = \"Input Transform\"\ncm.tagged_colour_space = \"ACEScct\" # Input\ncm.working_space = \"ACEScg\"      # Output\n\n# Method B: View Transform\ncm.mode = \"View Transform\"\ncm.display = \"sRGB - Display\"\ncm.view = \"ACES 1.0 - SDR Video\"\n\n# Method C: Load External File (CTF/LUT)\ncm.import_transform(\"/path/to/transform.ctf\")\n</code></pre>"},{"location":"insight/flame_api/colour_management/#3-ocio-context-variables","title":"3. OCIO Context Variables","text":"<p>You can manipulate context variables at the Project level or Node level. This is powerful for shot-based look management.</p> <p>Project Level:</p> <pre><code>prj = flame.projects.current_project\nprj.set_context_variable(\"SHOT\", \"sh010\")\nprj.set_context_variable(\"SEQ\", \"sq02\")\n</code></pre> <p>Node Level:</p> <pre><code>node = flame.batch.get_node(\"LMT_Load\")\nnode.context_variables_from_project = False # Decouple from project\nnode.set_context_variable(\"SHOT\", \"sh020\")\n</code></pre>"},{"location":"insight/flame_api/colour_management/#ocio-python-binding","title":"OCIO Python Binding","text":"<p>Flame includes the <code>PyOpenColorIO</code> library, allowing you to inspect configs directly.</p> <pre><code>import PyOpenColorIO as ocio\nimport os\n\n# Load project config\nprj = flame.projects.current_project\nconfig_path = os.path.realpath(os.path.join(prj.setups_folder, \"colour_mgmt\", \"config.ocio\"))\ncfg = ocio.Config.CreateFromFile(config_path)\n\n# List available views\nprint(list(cfg.getViews(\"sRGB - Display\")))\n</code></pre>"},{"location":"insight/flame_api/console_workflow/","title":"Python Console and Script Execution","text":"<p>The Flame Python Console is the primary tool for writing, editing, and executing Python code within Flame.</p>"},{"location":"insight/flame_api/console_workflow/#the-python-console-ui","title":"The Python Console UI","text":"<p>Accessible via: Flame Menu &gt; Python &gt; Python Console</p>"},{"location":"insight/flame_api/console_workflow/#windows","title":"Windows","text":"<ul> <li>Terminal Window (Top/Left): Displays output from <code>print()</code> statements, <code>help()</code> calls, and error messages (in red).</li> <li>Editor Window (Bottom/Right): A text editor with syntax highlighting and tab support.<ul> <li>Add Tab: Click the <code>+</code> sign in the bottom right.</li> <li>Indentation: Select lines and use <code>Tab</code> (indent) or <code>Shift+Tab</code> (unindent). <code>Ctrl+/</code> (Linux) or <code>Cmd+/</code> (macOS) to comment/uncomment.</li> </ul> </li> </ul>"},{"location":"insight/flame_api/console_workflow/#icons","title":"Icons","text":"Icon Name Description Eraser Clears terminal output. Sound Wave Toggle echoing executed code to the terminal (Blue = On). Play Executes the script in the current tab (or selected code). Save Saves the current tab script to disk. Load Loads a script from disk into a new tab. Line Numbers Toggles line numbers in the editor."},{"location":"insight/flame_api/console_workflow/#execution-methods","title":"Execution Methods","text":""},{"location":"insight/flame_api/console_workflow/#1-from-the-console","title":"1. From the Console","text":"<ul> <li>Run All: Click Play to run the entire script in the active tab.</li> <li>Run Selection: Highlight a section of code and click Play.</li> </ul> <p>Important: <code>import flame</code> only needs to be run once per tab/session.</p>"},{"location":"insight/flame_api/console_workflow/#2-at-startup","title":"2. At Startup","text":"<p>You can execute a script automatically when Flame launches.</p> <p>Command line:</p> <pre><code>/opt/Autodesk/&lt;version&gt;/bin/startApplication -s /path/to/script.py\n</code></pre> <p>Note: The script must include <code>import flame</code>.</p>"},{"location":"insight/flame_api/console_workflow/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>flame.batch.go_to()</code> to ensure you are in the correct tab before manipulating Batch nodes.</li> <li>Use <code>flame.batch.organize()</code> to automatically layout nodes after creation.</li> <li>Catch exceptions to prevent scripts from failing silently:     <code>python     try:         flame.batch.import_clip(\"bad_path\", \"reel\")     except Exception as e:         print(e)</code></li> </ul>"},{"location":"insight/flame_api/cookbook/","title":"Flame Python API Cookbook","text":"<p>Source: Autodesk Flame Family 2026 Help | Flame Python API Code Samples</p>"},{"location":"insight/flame_api/cookbook/#clips-media","title":"Clips &amp; Media","text":""},{"location":"insight/flame_api/cookbook/#import-a-clip","title":"Import a Clip","text":"<pre><code>flame.import_clips(\"/var/tmp/clip.mov\", &lt;PyLibrary&gt;)\n</code></pre>"},{"location":"insight/flame_api/cookbook/#reformat-a-clip","title":"Reformat a Clip","text":"<pre><code>&lt;PyClip&gt;.reformat(width=1920, height=1080, ratio=1.778)\n</code></pre>"},{"location":"insight/flame_api/cookbook/#accessing-frame-metadata","title":"Accessing Frame Metadata","text":"<pre><code># Get In/Out Marks (Frames)\nprint(&lt;PyClip&gt;.in_mark.get_value().frame)\nprint(&lt;PyClip&gt;.out_mark.get_value().frame)\n\n# Get Duration\nprint(&lt;PyClip&gt;.duration.frame)\n</code></pre>"},{"location":"insight/flame_api/cookbook/#rendering","title":"Rendering","text":""},{"location":"insight/flame_api/cookbook/#render-timeline-fx","title":"Render Timeline FX","text":"<pre><code># Proxy resolution with Burn\n&lt;PyClip&gt;.render(render_mode=\"All\", render_option=\"Burn\", render_quality=\"Proxy Resolution\")\n</code></pre>"},{"location":"insight/flame_api/cookbook/#render-batch-fx","title":"Render Batch FX","text":"<pre><code>&lt;PyClip&gt;.render(effect_type=\"Batch FX\")\n</code></pre>"},{"location":"insight/flame_api/cookbook/#timeline-operations","title":"Timeline Operations","text":""},{"location":"insight/flame_api/cookbook/#select-segments","title":"Select Segments","text":"<pre><code># Select all segments on the bottom video track\nfor seg in &lt;PyVersion&gt;.tracks[0].segments:\n    seg.selected = True\n</code></pre>"},{"location":"insight/flame_api/cookbook/#markers","title":"Markers","text":"<pre><code># Create a marker at frame 10\n&lt;PyClip&gt;.create_marker(10)\n\n# Move a marker to the middle of a segment\nmarker.location = &lt;PySegment&gt;.record_in + (&lt;PySegment&gt;.record_duration.frame / 2)\n</code></pre>"},{"location":"insight/flame_api/cookbook/#batch-operations","title":"Batch Operations","text":""},{"location":"insight/flame_api/cookbook/#looping-over-nodes","title":"Looping Over Nodes","text":"<pre><code># Change blend mode of all Comp nodes to Add\nfor n in flame.batch.nodes:\n    if n.type == \"Comp\":\n        n.flame_blend_mode = \"Add\"\n</code></pre>"},{"location":"insight/flame_api/cookbook/#creating-specialized-nodes","title":"Creating Specialized Nodes","text":"<pre><code># Matchbox with Shader\nflame.batch.create_node(\"Matchbox\", \"Blur.mx\")\n\n# Pybox with Handler\nflame.batch.create_node(\"Pybox\", \"sendmail.py\")\n\n# OpenFX with Plugin\nofx = flame.batch.create_node(\"OpenFX\")\nofx.change_plugin(\"S_Distort\")\n</code></pre>"},{"location":"insight/flame_api/cookbook/#ui-views","title":"UI &amp; Views","text":""},{"location":"insight/flame_api/cookbook/#switching-views","title":"Switching Views","text":"<pre><code># Switch to Desktop Reels\nflame.projects.current_project.current_workspace.desktop.set_desktop_reels()\n</code></pre>"},{"location":"insight/flame_api/cookbook/#controlling-the-media-panel","title":"Controlling the Media Panel","text":"<pre><code># Hide Media Panel\nflame.media_panel.visible = False\n\n# Set to Dual Mode\nflame.media_panel.dual = True\n</code></pre>"},{"location":"insight/flame_api/examples/","title":"Advanced Python API Workflows","text":"<p>Source: Autodesk Flame Family 2026 Help | Python API Examples</p>"},{"location":"insight/flame_api/examples/#1-importing-and-compositing-multi-channel-clips","title":"1. Importing and Compositing Multi-Channel Clips","text":"<p>This workflow demonstrates how to import a multi-channel OpenEXR clip and automatically break it out into a composite using the extracted channels.</p> <pre><code>import flame\n\n# 1. Setup\nschematicReels = ['Multi-Channel_Clip']\nshelfReels = ['Extra_Data']\n\nflame.batch.create_batch_group(\n    'Learning_Multi-Channel',\n    start_frame = 1001,\n    duration = 5,\n    reels = schematicReels,\n    shelf_reels = shelfReels\n)\nflame.batch.go_to()\n\n# 2. Import\nclip1 = flame.batch.import_clip(\"/var/tmp/robot_CGI.clip\", \"Multi-Channel_Clip\")\nclip1.name = \"CGI_Render\"\n\n# 3. Create Nodes\naction1 = flame.batch.create_node(\"Action\")\naction1.name = \"Comping_CGI\"\nwriteFile = flame.batch.create_node(\"Write File\")\n\n# 4. Extract Channels (Add Media inputs to Action)\n# Create input sockets on the Action node for specific passes\npasses = [\n    (\"Direct_Diffuse\", \"robot_direct_diffuse\"),\n    (\"Indirect_Diffuse\", \"robot_indirect_diffuse\"),\n    (\"Direct_Specular\", \"robot_direct_specular\"),\n    (\"Indirect_Specular\", \"robot_indirect_specular\"),\n    (\"Reflection\", \"robot_reflection\")\n]\n\nfor pass_name, channel_name in passes:\n    media_node = action1.add_media()\n    media_node.name = pass_name\n    # Connect the multi-channel clip's specific socket to the new Action media input\n    flame.batch.connect_nodes(clip1, channel_name, media_node, \"Front\")\n\n# 5. Output\nflame.batch.connect_nodes(action1, \"output1 [ Comp ]\", writeFile, \"Front\")\nflame.batch.organize()\n</code></pre>"},{"location":"insight/flame_api/examples/#2-multi-pass-render-setup-manual-comp","title":"2. Multi-Pass Render Setup (Manual Comp)","text":"<p>This example manually reconstructs a beauty pass from separate file sequences using standard Comp nodes.</p> <pre><code>import flame\n\n# Setup\nflame.batch.create_batch_group('RenderPasses_Setup', start_frame=1001, duration=5)\nflame.batch.go_to()\n\n# Import separate pass files\ndiffuse = flame.batch.import_clip(\"/tmp/diffuse.[001-005].exr\", \"Schematic Reel 1\")\nspec = flame.batch.import_clip(\"/tmp/spec.[001-005].exr\", \"Schematic Reel 1\")\nreflection = flame.batch.import_clip(\"/tmp/refl.[001-005].exr\", \"Schematic Reel 1\")\n\n# Create Comps\ncomp_diff = flame.batch.create_node(\"Comp\")\ncomp_diff.flame_blend_mode = \"Add\"\n\ncomp_final = flame.batch.create_node(\"Comp\")\ncomp_final.flame_blend_mode = \"Screen\"\n\n# Connect\nflame.batch.connect_nodes(diffuse, \"BGR\", comp_diff, \"Front\")\nflame.batch.connect_nodes(spec, \"BGR\", comp_diff, \"Back\")\n\nflame.batch.connect_nodes(comp_diff, \"Result\", comp_final, \"Back\")\nflame.batch.connect_nodes(reflection, \"BGR\", comp_final, \"Front\")\n\nflame.batch.organize()\n</code></pre>"},{"location":"insight/flame_api/getting_started/","title":"Getting Started with the Flame Python API","text":"<p>Source: Autodesk Flame Family 2026 Help | Write Your First Python API Script</p>"},{"location":"insight/flame_api/getting_started/#your-first-script-creating-a-batch-setup","title":"Your First Script: Creating a Batch Setup","text":"<p>This guide walks through creating a simple script that sets up a Batch group, creates nodes, and connects them.</p>"},{"location":"insight/flame_api/getting_started/#1-import-the-module","title":"1. Import the Module","text":"<p>Every script must start by importing the core module.</p> <pre><code>import flame\n</code></pre>"},{"location":"insight/flame_api/getting_started/#2-create-a-batch-group","title":"2. Create a Batch Group","text":"<p>Define your reels and create the group.</p> <pre><code>schematicReels = ['SchematicReel1', 'SchematicReel2']\nshelfReels = ['ShelfReel1']\n\nflame.batch.create_batch_group(\n    'MyFirstScript',\n    start_frame = 1,\n    duration = 100,\n    reels = schematicReels,\n    shelf_reels = shelfReels\n)\n</code></pre>"},{"location":"insight/flame_api/getting_started/#3-switch-context","title":"3. Switch Context","text":"<p>Ensure you are in the Batch tab.</p> <pre><code>flame.batch.go_to()\n</code></pre>"},{"location":"insight/flame_api/getting_started/#4-create-and-connect-nodes","title":"4. Create and Connect Nodes","text":"<p>Create nodes and store them in variables to reference them later.</p> <pre><code># Create nodes\ncomp = flame.batch.create_node(\"Comp\")\nwriteFile = flame.batch.create_node(\"Write File\")\n\n# Connect them: output node, output socket, input node, input socket\nflame.batch.connect_nodes(comp, \"Result\", writeFile, \"Front\")\n</code></pre> <p>Tip: Socket names are case-sensitive. Use the exact name seen in the Flame UI.</p>"},{"location":"insight/flame_api/getting_started/#5-organize","title":"5. Organize","text":"<p>Clean up the node layout.</p> <pre><code>flame.batch.organize()\n</code></pre>"},{"location":"insight/flame_api/getting_started/#full-script","title":"Full Script","text":"<pre><code>import flame\n\n# Define Reels\nschematicReels = ['SchematicReel1', 'SchematicReel2']\nshelfReels = ['ShelfReel1']\n\n# Create Group\nflame.batch.create_batch_group(\n    'MyFirstScript',\n    start_frame = 1,\n    duration = 100,\n    reels = schematicReels,\n    shelf_reels = shelfReels\n)\n\n# Go to Batch\nflame.batch.go_to()\n\n# Create Nodes\ncomp = flame.batch.create_node(\"Comp\")\nwriteFile = flame.batch.create_node(\"Write File\")\n\n# Connect\nflame.batch.connect_nodes(comp, \"Result\", writeFile, \"Front\")\n\n# Organize\nflame.batch.organize()\n</code></pre>"},{"location":"insight/flame_api/hooks_workflow/","title":"Python Hooks Workflow &amp; Best Practices","text":"<p>Source: Autodesk Flame Family 2026 Help | Python Hooks Tips</p>"},{"location":"insight/flame_api/hooks_workflow/#development-workflow","title":"Development Workflow","text":""},{"location":"insight/flame_api/hooks_workflow/#hot-reloading","title":"Hot reloading","text":"<p>You do not need to restart Flame to test hook changes. -   Shortcut: <code>Ctrl+Shift+P+H</code> (Default) -   Action: \"Scan for python hooks\" in the hotkey editor.</p>"},{"location":"insight/flame_api/hooks_workflow/#debugging","title":"Debugging","text":"<p>Enable verbose logging to see exactly when hooks are loaded and called.</p> <pre><code>export DL_DEBUG_PYTHON_HOOKS=1\n/opt/Autodesk/&lt;version&gt;/bin/startApplication\n</code></pre>"},{"location":"insight/flame_api/hooks_workflow/#common-patterns","title":"Common Patterns","text":""},{"location":"insight/flame_api/hooks_workflow/#passing-data-between-hooks","title":"Passing Data Between Hooks","text":"<p>Hooks are stateless function calls. To share data (e.g., project name) between different hooks, use a global variable populated by <code>app_initialized</code>.</p> <pre><code>current_project = None\n\ndef app_initialized(project_name):\n    global current_project\n    current_project = project_name\n\ndef some_other_hook(info):\n    print(f\"Running in project: {current_project}\")\n</code></pre>"},{"location":"insight/flame_api/hooks_workflow/#threading-long-operations","title":"Threading Long Operations","text":"<p>Hooks block the UI. For long tasks (like uploading to ShotGrid or copying large files), spawn a thread.</p> <p>Critical: You must join threads at exit to prevent zombie processes or crashes.</p> <pre><code>from threading import Thread\nimport atexit\nimport time\n\nactive_threads = []\n\ndef cleanup_threads():\n    for t in active_threads:\n        t.join()\n\natexit.register(cleanup_threads)\n\ndef heavy_task(asset_name):\n    time.sleep(5)\n    print(f\"Finished processing {asset_name}\")\n\ndef render_ended(moduleName, sequenceName, elapsedTime):\n    t = Thread(target=heavy_task, args=(sequenceName,))\n    t.start()\n    active_threads.append(t)\n</code></pre>"},{"location":"insight/flame_api/hooks_workflow/#context-aware-actions","title":"Context-Aware Actions","text":"<p>Custom UI actions receive the current selection. Use this to enable/disable actions dynamically.</p> <pre><code>def is_video_clip(selection):\n    # Only show if one item is selected and it is a Clip\n    return len(selection) == 1 and isinstance(selection[0], flame.PyClip)\n\ndef get_media_panel_custom_ui_actions():\n    return ([\n        {\n            \"name\": \"Process Clip\",\n            \"execute\": process_func,\n            \"isVisible\": is_video_clip\n        }\n    ])\n</code></pre>"},{"location":"insight/flame_api/hooks_workflow/#wiretap-external-libraries","title":"Wiretap &amp; External Libraries","text":"<p>Flame bundles its own Python environment. -   Wiretap: Use <code>from adsk import libwiretapPythonClientAPI</code>. -   Pip: Install packages using <code>/opt/Autodesk/python/&lt;VERSION&gt;/bin/pip</code>.</p>"},{"location":"insight/inference_builder_api/insight-inference_builder/","title":"Insight: The Inference Builder API (AI Model Packaging)","text":"<p>This document explains the Inference Builder, a specialized tool in Autodesk Flame that allows you to bring your own Artificial Intelligence (AI) models into your creative workflow.</p> <p>Target Audience: Novice Python programmers and technical artists interested in Machine Learning (ML).</p>"},{"location":"insight/inference_builder_api/insight-inference_builder/#1-what-is-the-inference-builder","title":"1. What is the Inference Builder?","text":"<p>Autodesk Flame can run custom AI models (like tools that remove backgrounds, upscale low-res video, or clean up digital noise). These models are usually saved in a standard format called ONNX.</p> <p>However, Flame needs a bit more information to use these models correctly\u2014like knowing which socket is \"Video\" and which is \"Alpha.\" The Inference Builder is the tool that packages an AI model into a single, encrypted file called an .inf file (similar to how Matchbox uses <code>.mx</code> files).</p>"},{"location":"insight/inference_builder_api/insight-inference_builder/#2-the-three-part-package","title":"2. The Three-Part Package","text":"<p>To create a professional AI tool for Flame, you need three files with the same name: 1.  <code>MyModel.onnx</code>: The actual \"Brain\" (the trained AI model). 2.  <code>MyModel.json</code>: The \"Instruction Manual\" (the sidecar file that explains how to use the brain). 3.  <code>MyModel.png</code>: The \"Cover Art\" (a 128x94 thumbnail for the Flame file browser).</p>"},{"location":"insight/inference_builder_api/insight-inference_builder/#3-the-instruction-manual-json-file","title":"3. The \"Instruction Manual\" (JSON File)","text":"<p>The <code>.json</code> file is where you do most of your work. It tells Flame how to connect its inputs to the AI model's inputs.</p>"},{"location":"insight/inference_builder_api/insight-inference_builder/#key-settings-to-know","title":"Key Settings to Know:","text":"<ul> <li><code>ScalingFactor</code>: If your AI model makes a 1080p image into a 4K image, you set this to <code>2.0</code>. This tells Flame to prepare a larger canvas for the result.</li> <li><code>Channels</code>: AI models are very picky. One model might want \"Red, Green, Blue,\" while another wants \"Blue, Green, Red.\" You use the <code>Channels</code> setting (like <code>\"RGB\"</code> or <code>\"BGR\"</code>) to translate between them.</li> <li><code>Padding</code>: Some AI models can only work on images that are multiples of 8 or 16 pixels. If you set <code>Padding: 8</code>, Flame will automatically add invisible pixels to the edges to make the AI happy, then trim them off when it's done.</li> </ul>"},{"location":"insight/inference_builder_api/insight-inference_builder/#4-the-workflow","title":"4. The Workflow","text":"<ol> <li>Generate: Run the <code>inference_builder -j</code> command to create a \"starting\" JSON file based on your model.</li> <li>Edit: Open the JSON in a text editor and fill in the descriptions and channel types.</li> <li>Test: Load your <code>.onnx</code> and <code>.json</code> files into an Inference Node in Batch.</li> <li>Package: Once it's working perfectly, run <code>inference_builder -p</code> to turn everything into a single, encrypted <code>.inf</code> file.</li> </ol>"},{"location":"insight/inference_builder_api/insight-inference_builder/#5-why-is-this-useful","title":"5. Why is this useful?","text":"<ul> <li>Custom Tools: You can download open-source AI models from the internet (like those on HuggingFace) and turn them into native Flame tools.</li> <li>IP Protection: Packaging into an <code>.inf</code> file encrypts your model, so you can share your tool with other studios without them seeing your secret AI \"Brain\" code.</li> <li>User Friendly: It turns a complex technical process into a simple \"Node\" that any Flame artist can use without knowing anything about AI.</li> </ul>"},{"location":"insight/inference_builder_api/insight-inference_builder/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>Think of the Inference Builder as a \"Gift Wrapper.\" You take a raw AI model (the gift), write a card explaining how to use it (the JSON), add a nice picture (the thumbnail), and wrap it all into a professional package (the <code>.inf</code> file) that works perfectly inside Flame.</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/","title":"Insight: The Open Clip Creator","text":"<p>This document explains the Open Clip Creator, a tool used to build special XML files that Flame uses to manage complex media.</p> <p>Target Audience: Novice technical artists and pipeline developers.</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/#1-what-is-an-open-clip","title":"1. What is an Open Clip?","text":"<p>Think of an Open Clip (<code>.clip</code> file) as a \"Smart Folder.\" </p> <p>Instead of Flame just looking at one movie file, an Open Clip tells Flame:</p> <p>\"This clip actually has 3 different versions (V1, V2, V3), a separate Left/Right eye for 3D, and it's made up of 5,000 individual DPX images stored on a server.\"</p> <p>It \"wraps\" all that complexity into one single file that Flame can load as a regular clip.</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/#2-the-hierarchy-from-small-to-large","title":"2. The Hierarchy (From Small to Large)","text":"<p>The Open Clip is built like a pyramid: 1.  Span: The lowest level. It's just a path to a piece of media on your hard drive. 2.  Feed: A collection of spans that make up one version of a track. 3.  Track: All the versions and information about a single channel (like \"Video\" or \"Audio\"). 4.  Clip: The top level. It brings all the tracks together into one object.</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/#3-powerful-features-patterns","title":"3. Powerful Features: Patterns","text":"<p>The most useful part of Open Clips for programmers is Patterns.  Instead of typing every single filename, you can use Tokens like: - <code>{name}</code>: The name of the clip. - <code>{version}</code>: The version number (e.g., v01, v02). - <code>{frame}</code>: The frame number in a sequence.</p> <p>Why? If you drop a new file named <code>Shot01_v02.mov</code> into a folder, an Open Clip using patterns will automatically see it as a new version inside Flame without you doing anything!</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/#4-how-to-create-them","title":"4. How to Create Them","text":"<p>You have three options: 1.  In Flame: Select clips in the MediaHub, right-click, and choose \"Create Open Clip.\" 2.  The App: Use the standalone \"Open Clip Creator\" application. 3.  Command Line: Use the <code>openclip_creator</code> tool in your terminal to automate the process for thousands of shots at once.</p>"},{"location":"insight/openclip_api/insight-open_clip_creator/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Open Clips are the \"Glue\" of a professional pipeline. They allow you to organize messy folders of renders and movie files into neat, versioned clips that Flame understands perfectly. If you find yourself manually importing \"v02\" every time a render finishes, you should probably be using an Open Clip!</p>"},{"location":"insight/openclip_api/insight-open_clip_reference/","title":"Insight: Open Clip XML Reference","text":"<p>This document explains the technical structure of an Open Clip XML file. It is the \"Dictionary\" for how Flame reads the instructions inside a <code>.clip</code> file.</p> <p>Target Audience: Novice programmers interested in XML and data structure.</p>"},{"location":"insight/openclip_api/insight-open_clip_reference/#1-what-is-inside-an-open-clip","title":"1. What is inside an Open Clip?","text":"<p>An Open Clip file is basically an XML list of directions. It tells Flame: - Where the files are (File paths). - When they start and end (Timecodes). - How they are organized (Tracks and Versions).</p> <p>Important Note: An Open Clip is NOT a timeline like an EDL or AAF. It doesn't contain \"edits\" or \"effects.\" It only describes the media itself.</p>"},{"location":"insight/openclip_api/insight-open_clip_reference/#2-key-components-the-xml-tags","title":"2. Key Components (The XML Tags)","text":"<p>When you open a <code>.clip</code> file in a text editor, you will see several standard tags:</p> <ul> <li><code>&lt;clip&gt;</code>: The main container.</li> <li><code>&lt;tracks&gt;</code>: Groups together all the different channels (Video, Audio).</li> <li><code>&lt;versions&gt;</code>: Lists the different revisions of the media.</li> <li><code>&lt;feeds&gt;</code>: The specific media streams for a version.</li> <li><code>&lt;spans&gt;</code>: The actual links to files on your hard drive.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_reference/#3-version-history","title":"3. Version History","text":"<p>Open Clip has evolved over the years. The most current version is Version 7.  - Newer versions support things like Nested Dictionaries (for complex metadata) and Resolved Color Spaces (so Flame knows exactly what color management to apply).</p>"},{"location":"insight/openclip_api/insight-open_clip_reference/#4-learning-by-example","title":"4. Learning by Example","text":"<p>The best way to understand the XML is to look at existing files. Flame installs several examples on your system: <code>/opt/Autodesk/openclip_examples</code></p> <p>Try opening these in a text editor like VS Code to see how the tags fit together.</p>"},{"location":"insight/openclip_api/insight-open_clip_reference/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of the Open Clip Reference as the \"Syntax Guide\" for Flame's media language. If you want to write a script that automatically generates these files, you need to follow these rules exactly so Flame can read your instructions correctly.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_clip/","title":"Insight: The Root Container () <p>This document explains the <code>&lt;clip&gt;</code> tag, which is the \"Main Envelope\" of an Open Clip XML file. Everything else in the file lives inside this tag.</p> <p>Target Audience: Novice programmers learning XML structure.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_clip/#1-what-is-the-clip-tag","title":"1. What is the <code>&lt;clip&gt;</code> tag?","text":"<p>The <code>&lt;clip&gt;</code> tag is the Root Element. This means it is the first tag you open and the last tag you close. It defines the basic identity of the clip.</p> <pre><code>&lt;clip type=\"clip\" version=\"7\"&gt;\n    ... everything else ...\n&lt;/clip&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_clip/#2-key-information-inside-clip","title":"2. Key Information inside <code>&lt;clip&gt;</code>","text":"<p>Inside the clip tag, you can define \"Global\" settings that apply to the whole object:</p> <ul> <li><code>&lt;name&gt;</code>: What the clip is called in Flame.</li> <li><code>&lt;tracks&gt;</code>: The list of all video and audio channels.</li> <li><code>&lt;versions&gt;</code>: The list of all available versions (V1, V2, etc.).</li> <li><code>&lt;startTimecode&gt;</code>: Where the clip starts on a clock (e.g., 01:00:00:00).</li> <li><code>&lt;duration&gt;</code>: How long the clip is.</li> <li><code>&lt;userData&gt;</code>: A secret compartment where you can store your own custom notes or tracking IDs.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_clip/#3-why-is-it-useful","title":"3. Why is it useful?","text":"<p>The <code>&lt;clip&gt;</code> tag acts as a \"Summary.\"  If you don't define a specific duration or start time, Flame is smart. It looks inside the clip at all the media and infers the information automatically. This means your XML can be very short if you just want to point to one file, or very detailed if you need to override specific settings.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_clip/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Think of the <code>&lt;clip&gt;</code> tag as the \"Header\" of a document. It sets the version of the \"Open Clip Language\" you are using (currently Version 7) and provides the overall context for Flame to understand the media streams hidden inside.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_dict/","title":"Insight: Custom Data Containers () <p>This document explains the <code>&lt;dict&gt;</code> tag (short for \"Dictionary\"). It is a flexible container that lets you store almost any kind of custom information inside an Open Clip.</p> <p>Target Audience: Novice programmers learning about \"Key-Value Pairs.\"</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_dict/#1-what-is-a-dictionary","title":"1. What is a Dictionary?","text":"<p>In programming, a Dictionary is like a real-world dictionary: you have a Key (the word) and a Value (the definition).</p> <p>In an Open Clip, you might want to save info that Flame doesn't have a standard button for\u2014like \"Artist Name,\" \"Lens Info,\" or \"Colorist Notes.\"</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_dict/#2-how-it-works-in-xml","title":"2. How it works in XML","text":"<p>Inside a <code>&lt;userData&gt;</code> tag, you use a <code>&lt;dict&gt;</code> to list your custom keys:</p> <pre><code>&lt;userData type=\"dict\"&gt;\n    &lt;Artist type=\"string\"&gt;John Doe&lt;/Artist&gt;\n    &lt;Status type=\"string\"&gt;Approved&lt;/Status&gt;\n    &lt;RenderTime type=\"int32\"&gt;120&lt;/RenderTime&gt;\n&lt;/userData&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_dict/#3-supported-data-types","title":"3. Supported Data Types","text":"<p>The <code>&lt;dict&gt;</code> is very versatile. You can tell Flame exactly what kind of data you are storing using the <code>type</code> attribute: - <code>string</code>: Text (names, notes). - <code>int</code> / <code>float</code>: Numbers (versions, frame rates). - <code>bool</code>: Yes/No switches. - <code>time</code>: Timecodes. - <code>dict</code>: You can even put a dictionary inside another dictionary! (This is called \"Nesting\").</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_dict/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Pipeline Tracking: Your studio's render manager can write a unique ID into the <code>&lt;dict&gt;</code>. Later, Flame can read that ID to find the original 3D project.</li> <li>Automation: You can write a Python script that looks at the <code>userData</code> to decide how to process a clip.</li> <li>Organization: It keeps your custom notes bundled right inside the media file, so they never get lost.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_dict/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;dict&gt;</code> tag is your \"Miscellaneous\" folder. If Flame doesn't have a specific tag for the data you want to save, just create your own key inside a dictionary. It's the best way to make the Open Clip work for your specific studio needs.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feed/","title":"Insight: The Media Stream () <p>This document explains the <code>&lt;feed&gt;</code> tag. It is the part of the Open Clip that points to a specific stream of media for a specific version.</p> <p>Target Audience: Novice programmers interested in versioning and media streams.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_feed/#1-what-is-a-feed","title":"1. What is a Feed?","text":"<p>If a Track is like a channel on a TV, a Feed is the actual show playing on that channel right now. </p> <p>Specifically, a <code>&lt;feed&gt;</code> represents one version of a track. If you have \"Version 1\" and \"Version 2\" of a shot, each one will have its own <code>&lt;feed&gt;</code> tag inside the track.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feed/#2-connecting-feeds-to-versions","title":"2. Connecting Feeds to Versions","text":"<p>The most important part of a feed is the <code>vuid</code> (Version Unique ID). - All feeds that belong to \"Version 1\" (across all your video and audio tracks) must share the same <code>vuid</code> (e.g., <code>vuid=\"v1\"</code>). - This is how Flame knows that when you switch the clip to \"Version 2,\" it should switch the Video Feed AND the Audio Feed at the same time.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feed/#3-key-information-inside-a-feed","title":"3. Key Information inside a Feed","text":"<ul> <li><code>uid</code>: A unique name for this specific stream.</li> <li><code>&lt;spans&gt;</code>: This is where the actual links to the files on your hard drive are stored.</li> <li><code>&lt;sampleRate&gt;</code>: The frame rate of the media (e.g., 24 or 30).</li> <li><code>&lt;startOffset&gt;</code>: A way to slide the media forward or backward in time without changing the original file.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_feed/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>Feeds allow you to have Heterogeneous Media.  - Version 1 could be a low-res Proxy (<code>.mov</code>). - Version 2 could be a high-res master (<code>.exr</code>). Because they are in separate <code>&lt;feed&gt;</code> tags, Flame can manage them both inside the same clip perfectly.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feed/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;feed&gt;</code> tag is the bridge between the high-level organization (Tracks and Versions) and the low-level files (Spans). It tells Flame: \"For Version X of this track, use these specific files.\"</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feeds/","title":"Insight: Managing Version Lists () <p>This document explains the <code>&lt;feeds&gt;</code> tag (note the 's' at the end!). It is a simple container that holds all the different versions available for a single track.</p> <p>Target Audience: Novice programmers learning about XML lists.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_feeds/#1-what-is-the-feeds-tag","title":"1. What is the <code>&lt;feeds&gt;</code> tag?","text":"<p>Think of <code>&lt;feeds&gt;</code> as a Folder. Inside this folder, you put all the individual <code>&lt;feed&gt;</code> tags (the specific versions) for a track.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feeds/#2-the-active-version","title":"2. The \"Active\" Version","text":"<p>The most important job of the <code>&lt;feeds&gt;</code> tag is to tell Flame which version to show first. It does this using the <code>currentVersion</code> attribute.</p> <pre><code>&lt;feeds currentVersion=\"v2\"&gt;\n    &lt;feed vuid=\"v1\" ... /&gt;\n    &lt;feed vuid=\"v2\" ... /&gt; &lt;!-- This one is active! --&gt;\n&lt;/feeds&gt;\n</code></pre> <ul> <li>If you don't specify a <code>currentVersion</code>, Flame will usually just pick the last one in the list.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_feeds/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>It allows for Instant Switching.  Because all the versions are listed inside the <code>&lt;feeds&gt;</code> container, an artist in Flame can just click a button to swap between \"v1\" and \"v2\" instantly. The <code>&lt;feeds&gt;</code> tag keeps those options organized and ready to go.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_feeds/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;feeds&gt;</code> tag is the Manager of a track's history. It doesn't hold any media itself; it just keeps a list of every version that has been rendered for that track and marks which one is the \"Current Master.\"</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_handler/","title":"Insight: The Media Interpreter () <p>This document explains the <code>&lt;handler&gt;</code> tag. It is the part of the Open Clip that acts as a \"Driver\" or \"Interpreter\" for the media files.</p> <p>Target Audience: Novice programmers interested in how software reads files.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_handler/#1-what-is-a-handler","title":"1. What is a Handler?","text":"<p>When Flame looks at a file (like a DPX sequence), it needs to know how to read the metadata inside it\u2014like the frame rate or the timecode. The <code>&lt;handler&gt;</code> tag tells Flame which \"Logic Engine\" to use.</p> <p>Common handlers include: - MIO Clip: The standard engine for reading modern media files.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_handler/#2-dynamic-discovery-scanpattern","title":"2. Dynamic Discovery (ScanPattern)","text":"<p>One of the most powerful things a handler can do is Scan.  Instead of you listing every single file path in the XML, you can give the handler a \"Search Pattern\" using the <code>&lt;ScanPattern&gt;</code> option.</p> <pre><code>&lt;ScanPattern&gt;Media/Shot_v{version}.{frame}.exr&lt;/ScanPattern&gt;\n</code></pre> <ul> <li>How it works: Flame will look at the <code>Media</code> folder. If it finds <code>Shot_v01.001.exr</code> and <code>Shot_v02.001.exr</code>, it will automatically create Version 1 and Version 2 for you.</li> <li>Why use it? It makes your Open Clips \"Self-Updating.\" As soon as a 3D artist renders a new version, Flame sees it instantly.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_handler/#3-handler-options","title":"3. Handler Options","text":"<p>Inside the handler, you can also set \"Rules\" for how to interpret the media: - <code>RateMode</code>: Should Flame trust the \"Header\" of the file for the frame rate, or should you force a specific number? - <code>AlignToZero</code>: Should the first frame of the file always be treated as \"Frame 0\"?</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_handler/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>The handler removes the manual labor of building complex clips. By setting up a good Scan Pattern, you can create a single <code>.clip</code> file that acts as a window into a messy folder of renders, organizing them into a neat, versioned interface for the artist.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_handler/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of the <code>&lt;handler&gt;</code> as the \"Smart Assistant.\" You give it a general rule (the Scan Pattern), and it does the tedious work of finding files and identifying versions so you don't have to write thousands of lines of XML.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_path/","title":"Insight: Linking to Files () <p>This document explains the <code>&lt;path&gt;</code> tag. It is the lowest level of an Open Clip and tells Flame exactly where to find the physical media on your computer or server.</p> <p>Target Audience: Novice programmers interested in file systems and patterns.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_path/#1-what-is-a-path","title":"1. What is a Path?","text":"<p>A path is just an address. In an Open Clip, it can be two things: 1.  A Single File: Like a QuickTime movie (<code>video.mov</code>). 2.  A Pattern: Like a sequence of images (<code>shot_[001-100].dpx</code>).</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_path/#2-encoding-types","title":"2. Encoding Types","text":"<p>The <code>encoding</code> attribute tells Flame how to read the text inside the tag: - <code>encoding=\"file\"</code>: Take the text literally. Don't look for brackets or numbers. - <code>encoding=\"pattern\"</code>: Look for special characters like <code>[]</code> or <code>{frame}</code> to find a range of files.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_path/#3-absolute-vs-relative-paths","title":"3. Absolute vs. Relative Paths","text":"<ul> <li>Absolute: The full address from the root of the computer (e.g., <code>/Volumes/Media/Shot01.mov</code>).</li> <li>Relative: The address starting from where the <code>.clip</code> file is saved (e.g., <code>Media/Shot01.mov</code>).</li> <li>Tip: Relative paths are better because you can move the entire project folder to a new drive without breaking the links!</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_path/#4-range-patterns","title":"4. Range Patterns","text":"<p>Open Clip supports a shorthand for image sequences: - <code>shot_[0001-0010].exr</code> will automatically find frames 1 through 10. - <code>shot_{frame}.exr</code> will find every frame in that folder that matches the name, no matter what the numbers are.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_path/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;path&gt;</code> tag is the \"Street Address\" for your media. Whether you are pointing to one big movie file or 10,000 individual images, the <code>&lt;path&gt;</code> tag is where you give Flame the specific coordinates to find those bits and bytes.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_paths/","title":"Insight: Multiple Views () <p>This document explains the <code>&lt;paths&gt;</code> tag (with an 's'). It is a special container used when you have multiple \"Views\" of the exact same moment in time\u2014the most common example being Stereo 3D.</p> <p>Target Audience: Novice programmers interested in 3D and stereoscopic media.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_paths/#1-what-is-the-paths-tag","title":"1. What is the <code>&lt;paths&gt;</code> tag?","text":"<p>Sometimes, one path isn't enough to describe a single moment of video. In a 3D movie, you need a path for the Left Eye and a different path for the Right Eye. </p> <p>The <code>&lt;paths&gt;</code> tag groups these two links together so Flame knows they are two halves of the same stereoscopic image.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_paths/#2-using-subfeedid","title":"2. Using <code>subFeedId</code>","text":"<p>Inside the <code>&lt;paths&gt;</code> tag, you list multiple <code>&lt;path&gt;</code> tags. You use the <code>subFeedId</code> attribute to label them:</p> <pre><code>&lt;paths&gt;\n    &lt;path subFeedId=\"Left\" encoding=\"file\"&gt;Media/shot_L.mov&lt;/path&gt;\n    &lt;path subFeedId=\"Right\" encoding=\"file\"&gt;Media/shot_R.mov&lt;/path&gt;\n&lt;/paths&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_paths/#3-why-is-this-different-from-tracks","title":"3. Why is this different from Tracks?","text":"<ul> <li>Tracks are for different things (like Video vs. Audio). They can have different lengths and frame rates.</li> <li>Paths (inside a Feed) are for different views of the same thing. The Left and Right eyes must have the exact same duration and frame rate to work together.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_paths/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>It simplifies the artist's life. Instead of having two separate clips (one for each eye), the artist just sees one \"Stereo Clip.\" Flame handles the complexity of reading both files in the background and keeping them perfectly in sync.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_paths/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;paths&gt;</code> tag is the \"Stereo Pair\" container. Use it whenever you have media that needs to be \"Joined at the Hip\"\u2014different files that represent different angles or views of the exact same sequence of frames.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rate/","title":"Insight: Precision Frame Rates () <p>This document explains the <code>&lt;rate&gt;</code> tag. It is used to tell Flame exactly how many frames (images) should play every second.</p> <p>Target Audience: Novice programmers interested in video timing and math.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_rate/#1-why-not-just-use-decimals","title":"1. Why Not Just Use Decimals?","text":"<p>In the movie world, frame rates are often messy. For example, \"23.98 fps\" is actually 23.976023976... infinitely. If a computer uses a simple decimal, it will eventually lose sync over a long movie.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rate/#2-the-rational-solution-numerator-denominator","title":"2. The Rational Solution (Numerator &amp; Denominator)","text":"<p>To keep things 100% precise, Open Clip uses Fractions. </p> <pre><code>&lt;rate type=\"rate\"&gt;\n    &lt;numerator&gt;24000&lt;/numerator&gt;\n    &lt;denominator&gt;1001&lt;/denominator&gt;\n&lt;/rate&gt;\n</code></pre> <ul> <li>Numerator: The top number.</li> <li>Denominator: The bottom number.</li> <li>Result: <code>24000 / 1001</code> equals exactly 23.976... without any rounding errors.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_rate/#3-simplified-decimal-format","title":"3. Simplified Decimal Format","text":"<p>If you aren't worried about extreme precision (like for a short 5-second clip), you can still use a simple number:</p> <pre><code>&lt;rate type=\"rate\"&gt;24&lt;/rate&gt; &lt;!-- Exactly 24 frames per second --&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_rate/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>Precision frame rates ensure that your audio and video stay perfectly in sync, even if the movie is 3 hours long. By using the <code>&lt;numerator&gt;</code> and <code>&lt;denominator&gt;</code>, you are giving Flame the most accurate \"Clock\" possible.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rate/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;rate&gt;</code> tag is the \"Metronome\" of your clip. Using the fraction format (<code>24000/1001</code>) is the professional way to handle frame rates, ensuring that every single frame plays at exactly the right micro-second.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rational/","title":"Insight: Precise Fractions () <p>This document explains the <code>&lt;rational&gt;</code> tag. It is very similar to the <code>&lt;rate&gt;</code> tag, but it's used for general math instead of just frame rates.</p> <p>Target Audience: Novice programmers learning about data precision.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_rational/#1-what-is-a-rational-number","title":"1. What is a Rational number?","text":"<p>In mathematics, a Rational number is any number that can be written as a fraction (one number divided by another). </p> <p>In an Open Clip, we use this for things like Aspect Ratio (the shape of the screen).</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rational/#2-using-the-fraction-format","title":"2. Using the Fraction Format","text":"<p>Instead of saying \"The screen is 1.777 wide,\" we use the exact fraction for 16:9:</p> <pre><code>&lt;rational type=\"rational\"&gt;\n    &lt;numerator&gt;16&lt;/numerator&gt;\n    &lt;denominator&gt;9&lt;/denominator&gt;\n&lt;/rational&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_rational/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>Just like frame rates, using fractions prevents \"Rounding Errors.\"  If a computer rounds <code>1.777777</code> to <code>1.78</code>, your image might look slightly stretched or squashed. By giving Flame the exact numbers (<code>16</code> and <code>9</code>), the math stays perfect.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_rational/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;rational&gt;</code> tag is used whenever you need to be 100% accurate about a ratio or fraction. Use it for aspect ratios or any other setting where a simple decimal isn't precise enough for professional filmmaking.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_span/","title":"Insight: The File Link () <p>This document explains the <code>&lt;span&gt;</code> tag. It is the part of the Open Clip that describes a single continuous piece of media.</p> <p>Target Audience: Novice programmers interested in how software links to files.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_span/#1-what-is-a-span","title":"1. What is a Span?","text":"<p>In the real world, a \"Span\" is a distance between two points. In an Open Clip, a <code>&lt;span&gt;</code> is a continuous segment of time that points to a specific physical location on your hard drive.</p> <p>A <code>&lt;feed&gt;</code> is made up of one or more spans.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_span/#2-key-information-inside-a-span","title":"2. Key Information inside a Span","text":"<ul> <li><code>&lt;path&gt;</code>: The address of the file (e.g., <code>Media/video.mov</code>).</li> <li><code>&lt;duration&gt;</code>: How many frames this specific file lasts.</li> <li><code>&lt;trackIndex&gt;</code>: If you are pointing to a file with many tracks (like a multi-channel OpenEXR), this tells Flame which specific channel to look at (e.g., Index 0 for Red, Index 1 for Green).</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_span/#3-why-use-multiple-spans","title":"3. Why use multiple spans?","text":"<p>Imagine you have a long movie that was recorded by a camera that split the file into 4GB chunks (<code>part1.mov</code>, <code>video2.mov</code>, <code>final.mov</code>).  Instead of joining them in an editing program, you can just list three <code>&lt;span&gt;</code> tags inside your Open Clip. Flame will play them back-to-back as if they were one single, perfect file!</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_span/#4-creating-gaps","title":"4. Creating Gaps","text":"<p>If you have a <code>&lt;span&gt;</code> with a duration but no path, Flame treats it as a Gap. It will just show black for that amount of time. This is a great way to \"Pad\" a clip if you know more media is coming later.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_span/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;span&gt;</code> tag is the \"Building Block\" of your media stream. By stacking multiple spans together, you can bridge multiple files into one continuous clip without ever needing to render a new file.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_spans/","title":"Insight: Joining Segments () <p>This document explains the <code>&lt;spans&gt;</code> tag (with an 's'). It is a simple list that holds all the individual links (spans) for a media stream.</p> <p>Target Audience: Novice programmers learning about sequential data.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_spans/#1-what-is-the-spans-tag","title":"1. What is the <code>&lt;spans&gt;</code> tag?","text":"<p>Think of <code>&lt;spans&gt;</code> as a Playlist. It defines the order in which individual files should be played to make up one version of a track.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_spans/#2-order-matters","title":"2. Order Matters","text":"<p>The order in which you list the <code>&lt;span&gt;</code> tags inside the <code>&lt;spans&gt;</code> container is exactly how Flame will play them. 1.  First <code>&lt;span&gt;</code> = The beginning of the clip. 2.  Second <code>&lt;span&gt;</code> = Joined immediately after the first. 3.  ...and so on.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_spans/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>It allows for \"Virtual Assembly.\"  You can join dozens of files together without moving them or renaming them. As long as they are listed in the <code>&lt;spans&gt;</code> tag, Flame handles the transition between the files invisibly in the background. This is common for \"Spanned\" camera recordings where one long take is saved as multiple smaller files.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_spans/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;spans&gt;</code> tag is the \"Sequential List\" of your media. It takes individual building blocks (spans) and glues them together into a single, seamless stream of frames for Flame to play.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_time/","title":"Insight: Measuring Time () <p>This document explains the <code>&lt;time&gt;</code> tag. It is how Flame calculates where a clip sits on a timeline and how long it lasts.</p> <p>Target Audience: Novice programmers interested in timecodes and duration.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_time/#1-how-is-time-measured-in-flame","title":"1. How is Time measured in Flame?","text":"<p>In digital video, time isn't just \"minutes and seconds.\" It's a combination of two things: 1.  A Count: How many frames (samples) are there? 2.  A Speed: How fast do those frames play?</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_time/#2-the-anatomy-of-the-time-tag","title":"2. The Anatomy of the <code>&lt;time&gt;</code> tag","text":"<p>The <code>&lt;time&gt;</code> tag combines these two parts:</p> <ul> <li><code>&lt;nbTicks&gt;</code>: The number of \"Ticks\" or Frames. (e.g., 240 frames).</li> <li><code>&lt;rate&gt;</code>: The speed (e.g., 24 frames per second).</li> <li><code>&lt;dropMode&gt;</code>: For certain broadcast standards (like NTSC), you might need \"Drop Frame\" (<code>DF</code>) or \"Non-Drop Frame\" (<code>NDF</code>) mode to keep the clock accurate.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_time/#3-calculating-seconds","title":"3. Calculating Seconds","text":"<p>To find out how many seconds a clip is, Flame does a simple math problem: <code>nbTicks</code> divided by <code>rate</code> = <code>seconds</code></p> <p>Example: <code>48 frames</code> / <code>24 fps</code> = <code>2 seconds</code>.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_time/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Flexibility: You can define time in frames, or you can get extremely precise using fractional rates (like <code>24000/1001</code>).</li> <li>Communication: It allows the Open Clip to speak the \"Language of Timecode,\" which is essential for editors who need to know exactly which hour, minute, and second a shot belongs to.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_time/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Time in an Open Clip is a Calculation. The <code>&lt;time&gt;</code> tag gives Flame the two ingredients it needs (Count and Speed) to correctly place your media on the timeline.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/","title":"Insight: Organizing Channels ()","text":"<p>This document explains the <code>&lt;track&gt;</code> tag. It is used to separate different streams of data\u2014like Video and Audio\u2014inside a single Open Clip.</p> <p>Target Audience: Novice programmers interested in multi-channel media.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/#1-what-is-a-track","title":"1. What is a Track?","text":"<p>In Flame, a clip isn't just a movie; it's a collection of channels.  The <code>&lt;track&gt;</code> tag allows you to define these channels individually. Common examples include: - A Video track. - An Audio track (you can have many of these). - A Matte (Alpha) track. - A Layer from a Photoshop or OpenEXR file.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/#2-key-attributes-of-a-track","title":"2. Key Attributes of a Track","text":"<ul> <li><code>uid</code> (Unique ID): Every track must have a name that makes it unique (e.g., \"t0\", \"audio_left\", \"Beauty_Pass\").</li> <li><code>&lt;trackType&gt;</code>: Usually <code>video</code> or <code>audio</code>.</li> <li><code>&lt;feeds&gt;</code>: This is where the actual media links live for this specific track.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/#3-advanced-overrides","title":"3. Advanced Overrides","text":"<p>Normally, a track is as long as the movie file it points to. But you can use the <code>&lt;track&gt;</code> tag to force a specific timing:</p> <ul> <li><code>&lt;startTimecode&gt;</code>: You can tell Track 1 to start at 01:00:00:00 even if the file itself starts at zero.</li> <li><code>&lt;duration&gt;</code>: You can make a track appear longer or shorter than the physical media. If you make it longer, Flame will automatically show a \"No Media\" slate for the extra time.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/#4-why-use-multiple-tracks","title":"4. Why use multiple tracks?","text":"<p>Imagine a 3D artist renders a scene. They give you one OpenEXR file that contains the \"Beauty\" pass, a \"Shadow\" pass, and a \"Reflection\" pass.  By using three <code>&lt;track&gt;</code> tags in your Open Clip, Flame will see these as three separate, perfectly synced layers that you can edit independently!</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_track/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>&lt;track&gt;</code> tag is like a \"Channel Strip\" on a mixer. It doesn't hold the media itself (that's the job of the <code>feed</code>), but it organizes the media into a logical stream that Flame can play back and edit.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_tracks/","title":"Insight: The Channel Manager () <p>This document explains the <code>&lt;tracks&gt;</code> tag (with an 's'). It is the part of the Open Clip that organizes all the different \"Layers\" or \"Channels\" of your media.</p> <p>Target Audience: Novice programmers interested in multi-layer media organization.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_tracks/#1-what-is-the-tracks-tag","title":"1. What is the <code>&lt;tracks&gt;</code> tag?","text":"<p>Think of <code>&lt;tracks&gt;</code> as the Backbone of the clip. It is a container that holds all the individual <code>&lt;track&gt;</code> tags (the specific video, audio, or metadata channels).</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_tracks/#2-global-track-management","title":"2. Global Track Management","text":"<p>While each individual track has its own settings, the <code>&lt;tracks&gt;</code> tag allows you to see the \"Big Picture\" of what the clip is made of. - Does it have 1 video and 2 audio channels? - Does it have 50 layers from a complex 3D render? All of those will be listed neatly inside this one tag.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_tracks/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>It allows for Multi-Channel Workflows.  By grouping everything inside <code>&lt;tracks&gt;</code>, you ensure that Flame sees all the components of a shot together. For example, if you have a \"Beauty\" layer, a \"Depth\" layer, and an \"Ambient Occlusion\" layer, they all live inside the <code>&lt;tracks&gt;</code> container, perfectly synced and ready for compositing.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_tracks/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;tracks&gt;</code> tag is the \"Master List\" of every channel in your clip. It provides the high-level structure that allows Flame to understand that several different media streams are actually parts of the same single object.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_version/","title":"Insight: Version Metadata () <p>This document explains the <code>&lt;version&gt;</code> tag. It is used to store information about a specific iteration of your work\u2014like \"V1\" or \"Final_Master.\"</p> <p>Target Audience: Novice programmers interested in creative workflow metadata.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_version/#1-what-is-a-version","title":"1. What is a Version?","text":"<p>In filmmaking, we never get it right the first time. We render \"Version 1\", then \"Version 2,\" and so on. The <code>&lt;version&gt;</code> tag allows you to add specific Notes to those iterations.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_version/#2-key-information-inside-a-version","title":"2. Key Information inside a Version","text":"<ul> <li><code>uid</code>: The unique link (like \"v1\") that connects this metadata to the actual media in the tracks.</li> <li><code>&lt;name&gt;</code>: A friendly name for the version (e.g., \"Roto Version\").</li> <li><code>&lt;comment&gt;</code>: A place for instructions (e.g., \"Added more blur to the edges\").</li> <li><code>&lt;creationDate&gt;</code>: When this version was rendered.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_version/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Communication: An artist can see exactly why a new version was created by looking at the comments inside the Open Clip.</li> <li>Audit Trail: You can keep track of who worked on a shot and when it was finished.</li> <li>Pipeline Logic: You can use the <code>creationDate</code> to automatically show the most recent render to the artist.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_version/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;version&gt;</code> tag is the \"Artist's Notebook\" for a clip. While other tags focus on technical things like file paths and frame rates, the <code>&lt;version&gt;</code> tag is where you store the human history of the shot.</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_versions/","title":"Insight: The Master Version List () <p>This document explains the <code>&lt;versions&gt;</code> tag. It is the \"Master Registry\" that tells Flame exactly which versions exist for the entire clip.</p> <p>Target Audience: Novice programmers interested in high-level media organization.</p>","text":""},{"location":"insight/openclip_api/insight-open_clip_xml_versions/#1-the-global-list","title":"1. The Global List","text":"<p>While each Track has a list of feeds, the Clip needs one central list that summarizes every version available across the whole project. That is the <code>&lt;versions&gt;</code> tag.</p> <p>It usually looks like this:</p> <pre><code>&lt;versions currentVersion=\"v2\"&gt;\n    &lt;version uid=\"v1\"/&gt;\n    &lt;version uid=\"v2\"/&gt;\n    &lt;version uid=\"v3\"/&gt;\n&lt;/versions&gt;\n</code></pre>"},{"location":"insight/openclip_api/insight-open_clip_xml_versions/#2-how-it-connects-everything","title":"2. How it Connects Everything","text":"<p>The <code>uid</code> inside a <code>&lt;version&gt;</code> tag acts as a Link.  When you switch the clip to \"v2\" in Flame, the software looks at this list and then goes to every track and says: \"Find me the feed that also has the ID 'v2'.\"</p>"},{"location":"insight/openclip_api/insight-open_clip_xml_versions/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Consistency: It ensures that \"Version 2\" means the same thing for the Video track as it does for the Audio track.</li> <li>Easy UI: Flame uses this list to build the dropdown menu that the artist uses to pick a version.</li> <li>Safety: It prevents Flame from trying to load a version that doesn't actually exist.</li> </ul>"},{"location":"insight/openclip_api/insight-open_clip_xml_versions/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>&lt;versions&gt;</code> tag is the \"Global Table of Contents\" for your clip. It doesn't contain links to files; it just defines the \"Names\" of the versions so that the Tracks can stay in sync when an artist switches between them.</p>"},{"location":"insight/pybox_api/insight-pybox_api/","title":"Comprehensive Insight: Autodesk Flame Pybox","text":"<p>Source: Autodesk Flame Family 2026 Help | Pybox Context: This document synthesizes knowledge from the official Pybox documentation and analysis of shipping handler scripts.</p>"},{"location":"insight/pybox_api/insight-pybox_api/#what-is-pybox","title":"What is Pybox?","text":"<p>Pybox is a specialized node type in Autodesk Flame's Batch and Timeline environments. It acts as a bridge, allowing third-party applications (typically renderers) or custom Python scripts to integrate directly into the compositing pipeline.</p> <p>Unlike standard Batch nodes which are hardcoded C++ operators, a Pybox node is driven by a Python Handler. This handler defines the node's UI, manages its sockets (inputs/outputs), and orchestrates the execution of external processes.</p>"},{"location":"insight/pybox_api/insight-pybox_api/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>External Rendering: Use Maya, Nuke, or command-line tools (like ImageMagick) to process images within a Batch tree.</li> <li>Custom UI: Build dynamic user interfaces with tabs, sliders, color pots, and file browsers directly in the Flame node menu.</li> <li>Pipeline Integration: Inject metadata, manage assets, or \"radio-control\" other software from within Flame.</li> </ul>"},{"location":"insight/pybox_api/insight-pybox_api/#core-architecture-stateless-synchronous","title":"Core Architecture: Stateless &amp; Synchronous","text":"<p>Pybox operates on a stateless, synchronous model.</p> <ol> <li>JSON Payload: Communication between Flame and the Python handler is exclusively through a JSON payload.<ul> <li>Flame writes the current state (metadata, UI values, socket paths) to a JSON file.</li> <li>The Python handler reads this JSON, performs actions, updates the JSON structure, and writes it back.</li> <li>Flame reads the updated JSON to update its UI or get the status of a render.</li> </ul> </li> <li>State Machine: The handler is responsible for managing its own state transitions. Flame does not drive the handler; it only reacts to the state set by the handler (<code>initialize</code>, <code>setup_ui</code>, <code>execute</code>, <code>teardown</code>).</li> <li>Disk I/O: Image exchange is done via the filesystem. Flame writes input frames to disk, the external process reads them, renders, and writes output frames to disk, which Flame then reads back. Performance Tip: Use fast storage (NVMe) or RAM disks for these intermediate paths.</li> </ol>"},{"location":"insight/pybox_api/insight-pybox_api/#the-pybox_v1-module","title":"The <code>pybox_v1</code> Module","text":"<p>All Pybox handlers rely on the <code>pybox_v1</code> Python module. -   Location: <code>/opt/Autodesk/presets/&lt;version&gt;/shared/pybox/pybox_v1.py</code> -   Availability: This module is automatically added to the Python path by Flame when a Pybox node is loaded. You do not need to manually configure <code>sys.path</code> for it.</p>"},{"location":"insight/pybox_api/insight-pybox_api/#handler-lifecycle","title":"Handler Lifecycle","text":"<p>A standard Pybox handler inherits from <code>pybox_v1.BaseClass</code> and overrides four key methods:</p>"},{"location":"insight/pybox_api/insight-pybox_api/#1-initializeself","title":"1. <code>initialize(self)</code>","text":"<ul> <li>Trigger: Called when the node is first loaded or reset.</li> <li>Tasks:<ul> <li>Set the image format (<code>self.set_img_format(\"exr\")</code>).</li> <li>Define Input sockets (<code>self.set_in_socket(...)</code>) - where Flame writes source images.</li> <li>Define Output sockets (<code>self.set_out_socket(...)</code>) - where Flame expects results.</li> <li>Set next state: <code>self.set_state_id(\"setup_ui\")</code>.</li> </ul> </li> </ul>"},{"location":"insight/pybox_api/insight-pybox_api/#2-setup_uiself","title":"2. <code>setup_ui(self)</code>","text":"<ul> <li>Trigger: Called after initialization.</li> <li>Tasks:<ul> <li>Create UI widgets (<code>pybox.create_float_numeric</code>, <code>pybox.create_toggle_button</code>, etc.).</li> <li>Categorize widgets:<ul> <li>Global Elements: Trigger Python execution immediately (e.g., \"Load Setup\").</li> <li>Render Elements: Only read during processing (e.g., \"Blur Amount\").</li> </ul> </li> <li>Define layout (<code>pybox.create_page</code>, <code>self.set_ui_pages</code>).</li> <li>Set next state: <code>self.set_state_id(\"execute\")</code>.</li> </ul> </li> </ul>"},{"location":"insight/pybox_api/insight-pybox_api/#3-executeself","title":"3. <code>execute(self)</code>","text":"<ul> <li>Trigger: Called when Flame needs a frame (rendering) or a Global UI element is changed.</li> <li>Tasks:<ul> <li>Read UI values (<code>self.get_render_element_value</code>).</li> <li>Check if processing is needed (<code>self.is_processing()</code>).</li> <li>Build command lines for external apps (e.g., <code>nuke -x ...</code>).</li> <li>Execute the external process.</li> <li>Set next state: <code>self.set_state_id(\"teardown\")</code>.</li> </ul> </li> </ul>"},{"location":"insight/pybox_api/insight-pybox_api/#4-teardownself","title":"4. <code>teardown(self)</code>","text":"<ul> <li>Trigger: Called when the node is deleted or the handler is changed.</li> <li>Tasks: Cleanup temporary files or close connections.</li> </ul>"},{"location":"insight/pybox_api/insight-pybox_api/#examples-and-use-cases","title":"Examples and Use Cases","text":""},{"location":"insight/pybox_api/insight-pybox_api/#minimalist-handler-hello-world","title":"Minimalist Handler (\"Hello World\")","text":"<p>The simplest handler just moves through the states without doing real work.</p> <pre><code>import sys\nimport pybox_v1 as pybox\n\nclass HelloWorld(pybox.BaseClass):\n    def initialize(self):\n        self.set_state_id(\"setup_ui\")\n        self.setup_ui()\n    def setup_ui(self):\n        self.set_state_id(\"execute\")\n        self.execute()\n    def execute(self):\n        self.set_state_id(\"teardown\")\n        self.teardown()\n    def teardown(self):\n        pass\n\ndef _main(argv):\n    p = HelloWorld(argv[0])\n    p.dispatch()\n    p.write_to_disk(argv[0])\n\nif __name__ == '__main__':\n    _main(sys.argv[1:])\n</code></pre>"},{"location":"insight/pybox_api/insight-pybox_api/#imagemagick-integration","title":"ImageMagick Integration","text":"<p>Common use case: Use ImageMagick to process frames. -   Inputs: Flame writes <code>Front</code> to <code>/tmp/in.exr</code>. -   Process: Handler calls <code>convert /tmp/in.exr -blur 0x8 /tmp/out.exr</code>. -   Outputs: Flame reads <code>Result</code> from <code>/tmp/out.exr</code>.</p>"},{"location":"insight/pybox_api/insight-pybox_api/#nuke-integration","title":"Nuke Integration","text":"<p>Allows controlling a Nuke script from Flame. -   Knob Exposure: Nuke knobs named <code>adsk_*</code> can be auto-exposed in the Pybox UI. -   Execution: The handler typically launches Nuke in command-line mode (<code>-x</code>) to render the specific frame requested by Flame.</p>"},{"location":"insight/pybox_api/insight-pybox_api/#best-practices","title":"Best Practices","text":"<ol> <li>Error Handling: Use <code>self.set_error_msg(\"Message\")</code> to print errors to the Flame console. Wrap execution logic in <code>try...except</code> blocks.</li> <li>Performance:<ul> <li>Minimize startup time for external processes (e.g., keep a daemon running if possible, though Pybox is naturally stateless/one-shot).</li> <li>Use fast SSDs for the socket paths.</li> </ul> </li> <li>Debugging:<ul> <li>Use <code>self.set_debug_msg()</code> to log info.</li> <li>Remember that <code>Change Handler</code> reloads the code from disk, allowing for rapid iteration without restarting Flame.</li> </ul> </li> <li>Distribution: Distribute the <code>.py</code> file. If you have dependencies, they must be standard libraries or co-located in the Pybox presets folder.</li> </ol>"},{"location":"insight/pybox_api/insight-pybox_api/#file-locations","title":"File Locations","text":"<ul> <li>Handlers: <code>/opt/Autodesk/presets/&lt;version&gt;/pybox/</code> (or any user path).</li> <li>Shared Modules: <code>/opt/Autodesk/shared/presets/pybox/</code> (Place custom libraries here).</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/","title":"Insight: Lightbox Shader Examples","text":"<p>This document provides a summary of the official Lightbox examples provided by Autodesk. These are the best place to start if you want to learn by \"deconstructing\" existing code.</p> <p>Location in Flame: <code>/opt/Autodesk/presets/&lt;version&gt;/action/lightbox/EXAMPLES</code></p>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#1-the-learning-path","title":"1. The Learning Path","text":""},{"location":"insight/shader_builder_api/insight-lightbox_examples/#level-1-the-basics","title":"Level 1: The Basics","text":"<ul> <li><code>LightboxBasics.glsl</code>: The simplest possible Lightbox. It just multiplies the color by a \"Gain\" value. Use this to see the minimum code required to make a Lightbox work.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#level-2-replicating-flame","title":"Level 2: Replicating Flame","text":"<ul> <li><code>SimpleLight.glsl</code>: Shows you how to manually recreate the math of a standard \"Point Light.\" It's a great lesson in 3D math and how Flame calculates brightness based on distance.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#level-3-interaction-with-3d-space","title":"Level 3: Interaction with 3D Space","text":"<ul> <li><code>LightboxAPISimple.glsl</code>: Shows how to ask Flame for information about the 3D scene, like the position of the light and the position of the pixels (vertices). This allows for \"Decay\" effects where the light gets weaker as it gets further away.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#level-4-advanced-material-science","title":"Level 4: Advanced Material Science","text":"<ul> <li><code>PhysicallyBasedIBL</code> and <code>GGXMaterial</code>: These are complex shaders. They use \"Physically Based Rendering\" (PBR) to make surfaces look like real metal, plastic, or glass. They show how a Lightbox can completely change the \"look\" of an object's material.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#2-key-code-snippets-to-look-for","title":"2. Key Code Snippets to Look For","text":"<p>When you open these files, look for these specific API calls:</p> <ul> <li><code>adsk_getLightPosition()</code>: Where is the light?</li> <li><code>adsk_getVertexPosition()</code>: Where is the object?</li> <li><code>adsk_rgb2yuv()</code>: A built-in helper to change color spaces quickly.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#3-how-to-use-these-examples","title":"3. How to use these Examples","text":"<p>Don't try to write a complex shader from scratch.  1. Copy an example that is close to what you want. 2. Modify one or two lines of code. 3. Run <code>shader_builder</code> to see if it still works. 4. Load it into Action to see the result.</p>"},{"location":"insight/shader_builder_api/insight-lightbox_examples/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The EXAMPLES folder is your \"Cheat Sheet.\" Most professional shaders are just variations of these basic patterns. If you want to build a tool that relights a scene, start with <code>SimpleLight</code> and build from there!</p>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/","title":"Insight: Creating Lightbox Shaders","text":"<p>This document explains the Lightbox framework in Autodesk Flame. It shows how you can write your own 3D lighting effects using GLSL (OpenGL Shading Language).</p> <p>Target Audience: Novice programmers and technical artists interested in 3D compositing and GLSL.</p>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#1-what-is-a-lightbox","title":"1. What is a Lightbox?","text":"<p>A Lightbox is a custom shader that lives inside Action (Flame's 3D engine). Think of it as a \"Smart Filter\" for a light. </p> <p>Usually, a light just makes things brighter. A Lightbox can make a light do anything\u2014like inverting colors, adding texture, or changing the way a surface reacts to distance.</p>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#2-the-basic-structure","title":"2. The Basic Structure","text":"<p>A Lightbox shader is a small piece of code written in GLSL. It always has a specific function:</p> <pre><code>vec4 adskUID_lightbox(vec4 source)\n{\n    // 'source' is the pixel color before this light hits it.\n    // Your code goes here...\n    return source;\n}\n</code></pre> <ul> <li><code>adskUID_</code>: This prefix is mandatory. It stands for \"Unique ID\" and prevents your shader from clashing with others when multiple Lightboxes are loaded.</li> <li><code>source</code>: This represents the color and transparency (RGBA) of the object being lit.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#3-writing-and-testing","title":"3. Writing and Testing","text":"<ol> <li>Code: Write your shader in a text editor and save it as <code>.glsl</code>.</li> <li>Validate: Use the <code>shader_builder</code> utility in your terminal:     <code>shader_builder -l -x my_shader.glsl</code><ul> <li><code>-l</code> tells it this is a Lightbox.</li> <li><code>-x</code> tells it to generate an XML file (this creates the buttons and sliders in Flame).</li> </ul> </li> <li>Fix: If there are errors (like a missing <code>;</code>), <code>shader_builder</code> will tell you exactly which line is broken.</li> </ol>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#4-key-concepts-to-remember","title":"4. Key Concepts to Remember","text":"<ul> <li>Pre vs. Post: In Flame, a Lightbox can run before the light hits the object (to modify the surface) or after the light (to modify the final lit result).</li> <li>The Alpha Rule: Always return a valid Alpha (<code>source.a</code>). If you set Alpha to 0, the object will disappear!</li> <li>Namespacing: You must use the <code>adskUID_</code> prefix for every variable you create (like <code>adskUID_gain</code>). If you don't, you can only load one copy of your shader at a time.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#5-why-use-lightbox-instead-of-matchbox","title":"5. Why use Lightbox instead of Matchbox?","text":"<ul> <li>Matchbox is for 2D image processing (like blurs or color corrections).</li> <li>Lightbox is for 3D interactions. It has access to things like the position of the light, the direction of the surface (normals), and the 3D depth of the scene.</li> </ul>"},{"location":"insight/shader_builder_api/insight-lightbox_shader_builder/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>Lightbox allows you to \"hijack\" Flame's 3D lighting pipeline. Whether you want to make a light that only affects blue objects or a light that adds a custom glow pattern, the <code>adskUID_lightbox</code> function is where you build that logic.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/","title":"Insight: Matchbox Shader Examples","text":"<p>This document provides a summary of the official Matchbox examples provided by Autodesk. These files demonstrate the wide variety of technical tricks you can use in your own shaders.</p> <p>Location in Flame: <code>/opt/Autodesk/presets/&lt;version&gt;/matchbox/shaders/EXAMPLES/</code></p>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/#1-ui-and-interaction-examples","title":"1. UI and Interaction Examples","text":"<ul> <li><code>Curves.glsl</code>: Shows how to add a graph editor to your node. This is perfect for custom color grading or complex easing.</li> <li><code>ColourWheel.glsl</code>: Shows how to use the standard \"Lift/Gamma/Gain\" style wheels in your UI.</li> <li><code>ConditionalUI.glsl</code>: Shows how to make a button appear or disappear based on another setting (e.g., hiding a \"Size\" slider when \"Auto-Scale\" is checked).</li> </ul>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/#2-technical-feature-examples","title":"2. Technical Feature Examples","text":"<ul> <li><code>Accumulate.glsl</code>: Shows how to \"remember\" the previous frame. This is essential for trails, echoes, or temporal noise reduction.</li> <li><code>TemporalSampling.glsl</code>: Shows how to look at the frames immediately before and after the current one.</li> <li><code>Mipmaps.glsl</code>: Shows how to use Flame's built-in \"low-res\" versions of an image to create very fast, high-quality blurs.</li> </ul>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/#3-real-world-tool-examples","title":"3. Real-World Tool Examples","text":"<ul> <li><code>TransitionShader.glsl</code>: A template for building your own timeline transitions (like wipes, dissolves, or glitched cuts).</li> <li><code>DecodeZDepthHQ.glsl</code>: An advanced example that shows how to take technical data from Action (depth information) and use it to build a 3D-aware 2D effect (like Depth of Field).</li> <li><code>ImagePosition/Rotation/Scaling</code>: These show the core math for basic image transforms. If you've ever wondered how a computer \"moves\" an image, look at these files.</li> </ul>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/#4-how-to-use-these-examples","title":"4. How to use these Examples","text":"<p>The EXAMPLES folder is a \"Library of Parts.\"  - Need a blur? Check <code>PyramidBlur</code>. - Need a dropdown list? Check <code>BuildList</code>. - Need to blend two images? Check <code>Blending</code>.</p> <p>Pro Tip: Don't try to memorize the code. Just remember that these examples exist, and copy-paste the sections you need into your own project!</p>"},{"location":"insight/shader_builder_api/insight-matchbox_examples/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The strength of Matchbox is its versatility. These examples prove that you can build everything from a simple color filter to a complex 3D-aware compositing tool. If you can't figure out how to do something in GLSL, there is probably an example in this folder that shows you the way.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/","title":"Insight: Creating Matchbox Shaders","text":"<p>This document explains the Matchbox framework in Autodesk Flame. It is the most common way to build custom 2D image effects (like blurs, color corrections, or distortions) using GLSL.</p> <p>Target Audience: Novice programmers and technical artists interested in image processing and 2D compositing.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#1-what-is-a-matchbox","title":"1. What is a Matchbox?","text":"<p>A Matchbox is a standalone image processor. Unlike a Lightbox (which lives inside 3D space), a Matchbox takes an input image, does some math to every pixel, and spits out a new result. </p> <p>You can use Matchboxes in: - Batch: As a node in your compositing tree. - Timeline: As a transition between two clips. - Action: As a post-processing filter.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#2-the-basic-structure","title":"2. The Basic Structure","text":"<p>A Matchbox shader is a GLSL file. Unlike Lightbox, it uses the standard <code>main()</code> function:</p> <pre><code>uniform float adsk_result_w, adsk_result_h;\nuniform sampler2D input1;\n\nvoid main()\n{\n   // 1. Get the current pixel's coordinate\n   vec2 coords = gl_FragCoord.xy / vec2(adsk_result_w, adsk_result_h);\n\n   // 2. Read the color from the input\n   vec4 color = texture2D(input1, coords);\n\n   // 3. Output the final color\n   gl_FragColor = color;\n}\n</code></pre> <ul> <li><code>adsk_result_w/h</code>: These are built-in variables that Flame fills with the width and height of your output.</li> <li><code>input1</code>: This represents the first image socket on the node.</li> </ul>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#3-key-features","title":"3. Key Features","text":""},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#a-multiple-inputs","title":"A. Multiple Inputs","text":"<p>A Matchbox can have up to 6 input sockets. You can define what these sockets are for (Front, Back, Matte) in your XML file so they are color-coded correctly in Batch.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#b-multi-pass-rendering","title":"B. Multi-pass Rendering","text":"<p>If your effect is complex (like a heavy blur), you can split it into multiple \"Passes.\" You write several GLSL files (e.g., <code>Blur.1.glsl</code>, <code>Blur.2.glsl</code>), and Flame runs them in sequence.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#c-selective-fx","title":"C. Selective FX","text":"<p>This is a specialized Matchbox that can interact with Flame's \"Selective\" node. It allows you to isolate a specific area (like a person's face) and apply the effect only there, with a perfect soft edge.</p>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#4-writing-and-testing","title":"4. Writing and Testing","text":"<ol> <li>Code: Write your GLSL and save it.</li> <li>Validate: Run <code>shader_builder -m -x my_shader.glsl</code>.<ul> <li><code>-m</code> tells it this is a Matchbox.</li> </ul> </li> <li>Package: Use <code>shader_builder -m -p my_shader.glsl</code> to create an encrypted <code>.mx</code> file for sharing.</li> </ol>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#5-why-use-matchbox","title":"5. Why use Matchbox?","text":"<ul> <li>Custom Filters: Build a specific look that doesn't exist in Flame's standard library.</li> <li>Performance: GLSL runs on the GPU, making it extremely fast for complex math.</li> <li>Universal: Once you build a Matchbox, you can use it anywhere in the Flame family (Flame, Flare, Flame Assist).</li> </ul>"},{"location":"insight/shader_builder_api/insight-matchbox_shader_builder/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>Matchbox is your \"Custom Node Factory.\" If you can imagine a mathematical formula for how a pixel should change based on its color or position, you can turn that into a Matchbox tool.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/","title":"Insight: The Shader API (Helper Functions)","text":"<p>This document explains the built-in Shader API. These are special \"shortcuts\" (functions) that Autodesk provides to help you write complex shaders without doing all the hard math yourself.</p> <p>Target Audience: Novice programmers learning GLSL syntax.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#1-what-is-the-shader-api","title":"1. What is the Shader API?","text":"<p>When you write a shader for Flame, you don't have to calculate things like \"How bright is this light?\" or \"Convert this color to Grayscale\" from scratch. Flame has a library of pre-written functions you can \"call\" in your code.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#2-lighting-3d-helpers-lightbox","title":"2. Lighting &amp; 3D Helpers (Lightbox)","text":"<p>These are for interacting with the 3D scene in Action: - <code>adsk_getLightPosition()</code>: Tells you exactly where the light is in 3D space. - <code>adsk_getNormal()</code>: Tells you which way the surface of an object is facing. - <code>adsk_getLightColour()</code>: Tells you the color and brightness of the light. - <code>adsk_getVertexPosition()</code>: Tells you the 3D coordinate of the pixel you are currently coloring.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#3-color-space-helpers-matchbox-lightbox","title":"3. Color Space Helpers (Matchbox &amp; Lightbox)","text":"<p>Moving between different color \"languages\" is easy with these functions: - <code>adsk_rgb2hsv()</code>: Converts standard Red/Green/Blue into Hue/Saturation/Value (great for making \"Hue Shift\" tools). - <code>adsk_scene2log()</code>: Converts linear light into \"Log\" (Cineon) space. - <code>adsk_getLuminance()</code>: Quickly turns a color image into a perfect black-and-white (grayscale) image.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#4-blending-helpers","title":"4. Blending Helpers","text":"<p>Instead of writing complex math for \"Overlay\" or \"Screen\" modes, you can just use: - <code>adsk_getBlendedValue(blendType, foreground, background)</code> By changing the <code>blendType</code> number (e.g., 0 for Add, 2 for Multiply), you can replicate any Photoshop-style blending mode.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#5-built-in-variables-uniforms","title":"5. Built-in Variables (Uniforms)","text":"<p>Flame also automatically gives you these \"Magic Variables\": - <code>adsk_time</code>: The current frame number (useful for making things animate or flicker). - <code>adsk_result_w</code> / <code>h</code>: The width and height of your image.</p>"},{"location":"insight/shader_builder_api/insight-shader_api/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>The Shader API is like a \"Toolbox.\" Before you try to write a complex mathematical formula, check the API documentation first. There is a high chance that Autodesk has already written a one-line function that does exactly what you need!</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/","title":"Insight: Shader Builder Overview (High-Level)","text":"<p>This document provides a birds-eye view of the Shader Builder workflow. It is the master process for turning raw code into a professional tool for Autodesk Flame.</p> <p>Target Audience: Novice programmers and technical artists.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/#1-the-workflow-in-5-steps","title":"1. The Workflow in 5 Steps","text":"<p>Creating a custom tool follows a specific sequence:</p> <ol> <li>Write: Create your graphics code in GLSL (The math of the effect).</li> <li>Generate: Use the <code>shader_builder</code> tool to create an XML file (The design of the buttons).</li> <li>Refine: Edit the XML to add better names, tooltips, and organized pages for your sliders.</li> <li>Preset: Open your shader in Flame, make a \"Cool Look,\" and save it as a Preset.</li> <li>Package: Use <code>shader_builder</code> again to encrypt your code into a single .mx (Matchbox) or .lx (Lightbox) file.</li> </ol>"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/#2-matchbox-vs-lightbox","title":"2. Matchbox vs. Lightbox","text":"Feature Matchbox Lightbox Dimension 2D (Flat Images) 3D (Inside Action) Main Function <code>main()</code> <code>adskUID_lightbox()</code> Location Batch, Timeline, Action Attached to a Light in Action Best For Blurs, CC, Distortions Relighting, Materials, 3D Glows"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/#3-the-power-of-shader_builder","title":"3. The Power of <code>shader_builder</code>","text":"<p><code>shader_builder</code> is a command-line utility. You use it in your terminal to: - Check for Errors: It tries to \"compile\" your code. If you forgot a semicolon, it will tell you exactly where. - Auto-UI: It looks at your variables and automatically builds a \"Best Guess\" user interface. - IP Protection: It encrypts your code so other people can use your tool without seeing your secret formulas.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/#4-why-build-your-own-shaders","title":"4. Why build your own shaders?","text":"<ul> <li>Unique Identity: Make your studio's work stand out with looks that no one else has.</li> <li>Speed: Custom nodes can combine 10 standard nodes into one single, fast button.</li> <li>Community: You can join sites like Logik Matchbook to download shaders from other professional artists around the world.</li> </ul>"},{"location":"insight/shader_builder_api/insight-shader_builder_overview/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The Shader Builder API is the \"Secret Sauce\" of Autodesk Flame. It allows you to transform the software from a standard editing tool into a specialized, high-performance visual effects engine tailored exactly to your needs.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/","title":"Insight: Designing Shader Interfaces (XML)","text":"<p>This document explains the sidecar XML file that accompanies Matchbox and Lightbox shaders. It is the \"Blueprint\" for the user interface (UI) you see inside Flame.</p> <p>Target Audience: Novice programmers who want to make their shaders easy for others to use.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#1-why-do-i-need-an-xml-file","title":"1. Why do I need an XML file?","text":"<p>When you write a shader (<code>.glsl</code>), Flame can guess some simple buttons for you. But if you want a professional UI with organized pages, custom names, dropdown menus, or color wheels, you need an XML sidecar file.</p> <p>You generate this file by running: <code>shader_builder -x my_shader.glsl</code></p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#2-anatomy-of-the-ui","title":"2. Anatomy of the UI","text":"<p>The XML file is broken down into a hierarchy:</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#a-shadernodepreset-the-root","title":"A. <code>&lt;ShaderNodePreset&gt;</code> (The Root)","text":"<p>This is the main container. It holds the name of your effect and settings like whether it supports 3D or if it provides a Matte.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#b-uniform-the-controls","title":"B. <code>&lt;Uniform&gt;</code> (The Controls)","text":"<p>Every slider, checkbox, or color pot in Flame is a Uniform. - <code>DisplayName</code>: What the user sees (e.g., \"Glow Strength\" instead of <code>adskUID_strength</code>). - <code>Min</code> / <code>Max</code> / <code>Default</code>: Sets the safe range for the slider. - <code>Tooltip</code>: The helpful text that appears when a user hovers over the control.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#c-page-and-col-the-layout","title":"C. <code>&lt;Page&gt;</code> and <code>&lt;Col&gt;</code> (The Layout)","text":"<p>These organize your controls so the UI isn't just one long list. - Pages: Tabs at the bottom of the node. - Columns: Vertical groups within a page.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#3-special-control-types","title":"3. Special Control Types","text":"<p>The XML allows you to change how a value is presented: - <code>PopUp</code>: Turns a number into a dropdown list (e.g., 0 = \"Linear\", 1 = \"Log\"). - <code>Colour</code>: Adds a color picker instead of three separate R, G, B sliders. - <code>Curve</code>: Provides a graph editor for complex changes over time.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#4-smart-ui-conditional-logic","title":"4. Smart UI (Conditional logic)","text":"<p>You can make your UI \"smart\" using UIConditions. For example, you can hide the \"Blur Amount\" slider unless the \"Enable Blur\" checkbox is checked. This keeps the interface clean and prevents users from changing settings that don't do anything.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#5-key-tip-the-adsk_-prefix","title":"5. Key Tip: The <code>adsk_</code> Prefix","text":"<p>If you name a variable in your GLSL starting with <code>adsk_</code> (like <code>adsk_time</code>), Flame will hide it from the UI. This is useful for internal math that the user shouldn't touch.</p>"},{"location":"insight/shader_builder_api/insight-shader_builder_xml/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>The XML file is your way of communicating with the artist. A well-organized XML makes a complex shader feel like a simple, built-in tool. If you can't find a setting, look for the <code>shader_builder -x</code> command\u2014it's the best way to start building your custom interface.</p>"},{"location":"insight/shader_builder_api/insight-shader_presets/","title":"Insight: Creating Shader Presets","text":"<p>This document explains how to create Presets for your Matchbox or Lightbox shaders. Presets allow you to save specific settings (like a \"Sepia\" look or a \"Heavy Blur\" look) so users don't have to start from scratch.</p> <p>Target Audience: Novice programmers and tool creators.</p>"},{"location":"insight/shader_builder_api/insight-shader_presets/#1-what-is-a-preset","title":"1. What is a Preset?","text":"<p>A preset is a small XML file that tells Flame: \"When this shader loads, set the 'Gain' to 0.5 and the 'Color' to Blue.\"</p> <p>In the Flame UI, these appear in the \"Presets\" dropdown menu at the top of the node settings.</p>"},{"location":"insight/shader_builder_api/insight-shader_presets/#2-the-print-to-shell-workflow","title":"2. The \"Print to Shell\" Workflow","text":"<p>You don't have to write preset code by hand. Flame can write it for you!</p> <ol> <li>Adjust Settings: Load your shader in Flame and move the sliders until you have a \"look\" you like.</li> <li>Print XML: Go to the Node Prefs menu and click the UI XML Shell Printout button.</li> <li>Find the Code: Look at the terminal/shell window where you launched Flame. You will see a block of XML code starting with <code>&lt;Presets&gt;</code>.</li> <li>Save: Copy that code into a new text file.</li> </ol>"},{"location":"insight/shader_builder_api/insight-shader_presets/#3-saving-the-file","title":"3. Saving the File","text":"<p>To make the preset work, you must name the file correctly: - Rule: <code>&lt;shader_name&gt;.preset.xml</code> - Example: If your shader is <code>MyGlow.glsl</code>, your preset file must be <code>MyGlow.preset.xml</code>.</p> <p>Place this file in the same folder as your <code>.glsl</code> and <code>.xml</code> files.</p>"},{"location":"insight/shader_builder_api/insight-shader_presets/#4-organizing-multiple-presets","title":"4. Organizing Multiple Presets","text":"<p>You can have many looks inside one file. Just add more <code>&lt;Preset&gt;</code> blocks:</p> <pre><code>&lt;Presets&gt;\n   &lt;Preset Name=\"Warm Glow\"&gt;\n      ... settings for warm glow ...\n   &lt;/Preset&gt;\n   &lt;Preset Name=\"Cool Blue\"&gt;\n      ... settings for cool blue ...\n   &lt;/Preset&gt;\n&lt;/Presets&gt;\n</code></pre>"},{"location":"insight/shader_builder_api/insight-shader_presets/#5-why-use-presets","title":"5. Why use Presets?","text":"<ul> <li>Efficiency: Give artists a head start by providing common settings.</li> <li>Guidance: Show what your shader is capable of by creating a few extreme \"demo\" looks.</li> <li>Sharing: Artists can send you their shell printouts to include in your next update!</li> </ul>"},{"location":"insight/shader_builder_api/insight-shader_presets/#6-key-takeaway-for-beginners","title":"6. Key Takeaway for Beginners","text":"<p>Presets are the \"Finishing Touch\" for a custom tool. By spending 5 minutes \"printing\" a few cool looks to the shell, you make your shader much more useful and professional for the final artist.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/","title":"Insight: Backburner Network Architecture","text":"<p>This document explains the \"Engine\" behind Flame's background rendering and how it coordinates multiple computers to get work done faster.</p> <p>Target Audience: Novice technical artists interested in render farms and distributed computing.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#1-the-three-main-players","title":"1. The Three Main Players","text":"<p>Backburner is a system that splits a big job into small pieces and sends them to different machines. It has three main components:</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#a-the-backburner-manager-the-boss","title":"A. The Backburner Manager (The Boss)","text":"<p>The Manager is the \"Brain\" of the operation.  - It receives jobs from Flame artists. - It looks at all the computers on the network and decides who is free to work. - It keeps a list of every job\u2014what is \"Active,\" \"Waiting,\" or \"Done.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#b-the-backburner-server-the-worker","title":"B. The Backburner Server (The Worker)","text":"<p>This is a program running on one or more machines (Render Nodes). - It waits for the Manager to give it a job. - When it gets a job, it starts the rendering engine (like Burn) and creates the actual frames.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#c-the-backburner-monitor-the-dashboard","title":"C. The Backburner Monitor (The Dashboard)","text":"<p>This is the interface the humans use.  - It allows you to see the progress of your renders. - You can use it to \"Pause,\" \"Restart,\" or \"Prioritize\" certain jobs if you are in a rush.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#2-how-a-job-moves","title":"2. How a Job Moves","text":"<ol> <li>Submit: The artist hits \"Render\" in Flame.</li> <li>Assign: The Manager finds an available Server.</li> <li>Execute: The Server renders the frames.</li> <li>Finish: The frames are saved to the server, and the Manager marks the job as \"Complete.\"</li> </ol>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>Backburner allows you to keep working in Flame while your computer renders in the background. Or, you can use 50 other computers on your network to render a long movie in minutes instead of hours!</p>"},{"location":"insight/wiretap_sdk/insight-backburner_architecture/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Backburner is a \"Traffic Cop\" for renders. It ensures that every computer in your studio is working as efficiently as possible, and it gives you a central place to track all that hard work.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_archive_metadata/","title":"Insight: Backburner Job Archive Metadata","text":"<p>This document explains how to quickly look at the history of everything your render farm has ever done.</p> <p>Target Audience: Novice programmers interested in database history and reporting.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_archive_metadata/#1-what-is-the-job-archive","title":"1. What is the Job Archive?","text":"<p>When a job is finished and old, Backburner moves it from the active <code>/jobs</code> folder to the <code>/archive</code> folder. This keeps the active list clean and fast.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_archive_metadata/#2-the-super-query","title":"2. The \"Super Query\"","text":"<p>Normally, if you want to know about 100 jobs, you have to ask 100 questions. That's slow!</p> <p>Wiretap has a \"Super Query\" for the archive. When you ask for metadata on the <code>/archive</code> node, it gives you a giant list of every archived job all at once.</p> <pre><code>&lt;info&gt;\n  &lt;job id=\"101\" name=\"Shot_01\" user=\"John\" ... /&gt;\n  &lt;job id=\"102\" name=\"Shot_02\" user=\"Jane\" ... /&gt;\n&lt;/info&gt;\n</code></pre>"},{"location":"insight/wiretap_sdk/insight-backburner_job_archive_metadata/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Auditing: You can see exactly what was rendered three months ago.</li> <li>Speed: It is much faster for your script to download one big list than to ask for jobs one-by-one.</li> <li>Cleanup: You can look at the <code>endTime</code> of all archived jobs and decide which ones are old enough to be deleted forever.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_job_archive_metadata/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The <code>/archive</code> node is the \"History Book\" of your studio. By using the <code>info</code> stream on this node, you can get a summary of months of work in just a few seconds. It is the most efficient way to build long-term reports.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/","title":"Insight: Backburner Job List Metadata","text":"<p>This document explains how to get a detailed status report of all Active renders currently happening in your studio.</p> <p>Target Audience: Novice programmers interested in high-performance data querying.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/#1-the-active-overview","title":"1. The Active Overview","text":"<p>Just like the archive, the active <code>/jobs</code> node has a \"Super Query\" feature. When you ask for its <code>info</code> metadata, it returns a list of every job currently waiting or rendering.</p> <p>It includes live details like: - <code>percentTasksCompleted</code>: How close is the job to being done? - <code>nbFailedServers</code>: Are any computers struggling with this specific job? - <code>order</code>: Where is this job in the \"Lineup\"?</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/#2-advanced-filtering-the-fields-trick","title":"2. Advanced Filtering (The \"Fields\" trick)","text":"<p>If you have 1,000 jobs, the XML file can get huge and slow. You can use Filters to ask for only the pieces you need.</p> <ul> <li>Example: \"I only want the Name and the ID, don't send me the whole description.\"</li> <li>The Filter Code: <code>&lt;Fields id='1' name='1'/&gt;</code></li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/#3-comparison-queries","title":"3. Comparison Queries","text":"<p>You can even ask complex questions using the <code>&lt;Comparison&gt;</code> tag: - \"Show me all jobs that are 'complete'.\" - \"Show me all jobs submitted by user 'JohnDoe'.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>This is the power behind every professional \"Render Monitor\" dashboard. Instead of clicking through a slow interface, your script can ask for a tiny, filtered list of \"Only failed jobs\" and alert you instantly when a render hits a snag.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_list_metadata/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>/jobs</code> node is the \"Live Status Board\". By using filters and comparisons, you can get exactly the data you need (like \"Only show me the progress of V2 shots\") without wasting time downloading information you don't care about.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/","title":"Insight: Backburner Job Metadata","text":"<p>This document explains the information (Tags) attached to a render job in Backburner. Understanding these tags allows you to track exactly how your renders are performing.</p> <p>Target Audience: Novice programmers interested in status monitoring and reporting.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#1-the-four-metadata-streams","title":"1. The Four Metadata Streams","text":"<p>Every job in Backburner has four different \"Folders\" of information:</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#a-info-the-overview","title":"A. <code>info</code> (The Overview)","text":"<p>This is the most important stream. It contains the basic \"ID Card\" for the job: - <code>percentTasksCompleted</code>: How much of the render is done? - <code>submittedTime</code>: When did the artist hit the button? - <code>lastError</code>: If it failed, why?</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#b-state-the-activity","title":"B. <code>state</code> (The Activity)","text":"<p>A simple tag that tells you what the job is doing right now: - <code>waiting</code>: Ready to work. - <code>active</code>: Currently rendering. - <code>complete</code>: Successfully finished. - <code>suspended</code>: On hold.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#c-tasks-the-granular-view","title":"C. <code>tasks</code> (The Granular View)","text":"<p>A job is often split into many small \"Tasks\" (like 10 frames each). This stream lists every single task, which machine worked on it, and how many milliseconds it took.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#d-details-xmldetails-custom-info","title":"D. <code>details</code> / <code>xmlDetails</code> (Custom Info)","text":"<p>A secret compartment for technical settings. This is where Flame stores specific render instructions like \"Use Motion Blur\" or \"Output at 4K.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#2-why-is-this-useful","title":"2. Why is this useful?","text":"<p>By reading the <code>info</code> and <code>tasks</code> streams, you can build a Studio Report. You can calculate exactly how many hours your render farm spent on a specific project, which machines are the fastest, and which artists are submitting the most jobs.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_job_metadata/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>Job Metadata is \"Live Intelligence.\" Instead of guessing if a render will be done by lunch, your script can read the <code>percentTasksCompleted</code> tag and tell you exactly how much work is left!</p>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/","title":"Insight: Backburner Manager Metadata","text":"<p>This document explains the \"Global Settings\" for your render farm. These settings control the behavior of the entire Backburner system.</p> <p>Target Audience: Novice technical artists and system administrators.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/#1-the-managers-rulebook","title":"1. The Manager's Rulebook","text":"<p>The Backburner Manager has an <code>info</code> stream that acts as the \"Rulebook\" for all computers on the farm. By changing these tags, you change how every job is handled.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/#key-rules","title":"Key Rules:","text":"<ul> <li><code>retryCount</code>: If a computer crashes during a render, how many times should the Manager try again? (Usually set to 3).</li> <li><code>maxConcurrentJobs</code>: How many jobs are allowed to run at the exact same time across the whole farm?</li> <li><code>archiveDays</code>: How long should a finished job sit in the \"Recent\" list before being moved to the \"Old\" archive?</li> <li><code>logLevel</code>: How much detail should the Manager write to its diary? (Set to <code>debug</code> if you are trying to find a bug).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/#2-security-and-admins","title":"2. Security and Admins","text":"<p>The Manager also keeps a list of <code>administrators</code>. These are the only users allowed to cancel someone else's render or change the global rules.</p> <ul> <li><code>restrictRoot</code>: A safety switch. If this is on, even the \"Superuser\" (Root) cannot send jobs from a remote computer.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>By reading the Manager's metadata, your script can verify the health of the farm.  - You can check if the <code>mailServer</code> is set up correctly so artists get their \"Render Done\" emails. - You can automatically increase the <code>retryCount</code> if the network is having a bad day.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_manager_metadata/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The Manager Metadata is the \"Control Panel\" for the studio. It defines the \"Policy\" for how work gets done. Understanding these tags is the first step to managing a professional, reliable render farm.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/","title":"Insight: Backburner Node Hierarchy","text":"<p>This document explains the organizational map of the Backburner Manager. Just like Flame projects, Backburner uses a tree structure to keep track of computers and tasks.</p> <p>Target Audience: Novice programmers interested in system organization.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#1-the-map-of-the-manager","title":"1. The Map of the Manager","text":"<p>The Backburner hierarchy has four main branches:</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#a-the-manager-manager","title":"A. The Manager (<code>MANAGER/</code>)","text":"<p>The root of the whole tree. It holds the overall settings for the entire render farm.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#b-the-server-list-serverlist","title":"B. The Server List (<code>SERVERLIST/</code>)","text":"<p>A list of every computer (Render Node) that has introduced itself to the Manager.  - Each computer has its own <code>SERVER</code> node. - If a computer disappears (unplugged or crashed), it is marked as \"Absent.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#c-the-server-group-list-servergrouplist","title":"C. The Server Group List (<code>SERVERGROUPLIST/</code>)","text":"<p>Where you can group computers together.  - Example: You might create a group called \"Super_Fast_Nodes\" that only contains the newest computers in the studio.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#d-the-job-list-joblist","title":"D. The Job List (<code>JOBLIST/</code>)","text":"<p>The most active part of the tree. It contains every <code>JOB</code> currently being processed. - When a job is completely finished and old, it moves to the Archive branch.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#2-using-metadata","title":"2. Using Metadata","text":"<p>Each node in this tree has \"Tags\" (Metadata).  - A Job Node has tags telling you the percentage finished. - A Server Node has tags telling you if the computer is currently \"Busy\" or \"Idle.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>By \"Walking\" through this tree, your Python script can build its own dashboard. You can write a script that says: \"Find all servers in the 'Super_Fast' group and tell me how many of them are currently Idle.\"</p>"},{"location":"insight/wiretap_sdk/insight-backburner_node_hierarchy/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Backburner's hierarchy is a Live Status Map. It gives you a birds-eye view of every worker and every task in your studio, organized into a simple tree that your code can easily read.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_overview/","title":"Insight: Backburner Overview","text":"<p>This document provides a high-level summary of Backburner, Flame's system for managing background work.</p> <p>Target Audience: Novice programmers and studio artists.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_overview/#1-what-is-backburner","title":"1. What is Backburner?","text":"<p>Rendering a movie can take hours. If you did this inside Flame, your computer would be \"Locked\" and you couldn't keep working.</p> <p>Backburner is the solution. It is a \"Background Manager\" that takes your render request and handles it on a different computer (or in the background of your own computer) so you can keep editing.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_overview/#2-why-is-it-in-the-wiretap-sdk","title":"2. Why is it in the Wiretap SDK?","text":"<p>The Backburner Manager is actually a Wiretap Server. This is great news for programmers! It means you can use the same code you use to find clips to also find render jobs.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_overview/#3-what-can-you-do-with-it","title":"3. What can you do with it?","text":"<p>Using the API, you can build your own custom tools to: - Monitor: See exactly which frame a render is on. - Control: Pause a job if you need more bandwidth, or Restart a job if it failed. - Automate: Submit hundreds of renders at once from a script.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_overview/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Backburner is the \"Task Manager\" for your entire studio. It coordinates the \"Heavy Lifting\" so that artists can stay focused on being creative. By mastering the Backburner API, you can build a pipeline that renders while you sleep.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_server_group_metadata/","title":"Insight: Server Group Metadata","text":"<p>This document explains how to organize your computers into teams (Groups) and how to manage those groups using Wiretap.</p> <p>Target Audience: Novice system administrators and pipeline developers.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_server_group_metadata/#1-what-is-a-server-group","title":"1. What is a Server Group?","text":"<p>A Server Group is a collection of computers that you can target as a single unit. Instead of sending a job to one specific machine, you send it to \"The Team.\"</p> <ul> <li>Example: You might create a group called \"GPU_FARM\" for jobs that need high-end graphics cards.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_server_group_metadata/#2-reading-the-group-info","title":"2. Reading the Group Info","text":"<p>Every group has an <code>info</code> stream that tells you: - <code>name</code>: The name of the team (e.g., \"Daily_Render_Nodes\"). - <code>servers</code>: A list of every computer currently in that team. - <code>editable</code>: Tells you if you have permission to change who is in the team.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_server_group_metadata/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Prioritization: You can reserve your fastest machines for \"Rush\" jobs by putting them in a special group.</li> <li>Organization: You can separate machines by OS (e.g., \"Linux_Nodes\" vs. \"Windows_Nodes\").</li> <li>Automation: Your pipeline script can look at a job's requirements and automatically pick the best Server Group to handle it.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_server_group_metadata/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Server Groups are the \"Teams\" of your render farm. By grouping your computers, you make it much easier to manage a large studio. Instead of managing 100 individual computers, you just manage 5 specialized groups.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_server_metadata/","title":"Insight: Backburner Server Metadata","text":"<p>This document explains the information (Tags) attached to the individual computers (Servers) in your render farm.</p> <p>Target Audience: Novice technical artists and system administrators.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_server_metadata/#1-monitoring-the-workers","title":"1. Monitoring the Workers","text":"<p>Every server in the Backburner farm has an <code>info</code> stream that tells you its health and status:</p> <ul> <li><code>state</code>: Is the computer Idle (waiting for work), Active (rendering), or Absent (turned off)?</li> <li><code>perfIndex</code>: A score from 0 to 1. A score of 1.0 means this is the fastest machine in the building.</li> <li><code>plugins</code>: A list of what this machine can do. For example, does it have Burn installed for rendering video?</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_server_metadata/#2-setting-a-schedule","title":"2. Setting a Schedule","text":"<p>One of the coolest features of Backburner is the <code>schedule</code> stream. You can tell a machine exactly when it is allowed to work.</p> <ul> <li>The Math: The schedule is stored as a 24-bit number (one bit for every hour of the day). </li> <li>Use Case: You can set a rule that says: \"Machine #10 is a powerful artist workstation. It should only render between 7 PM and 7 AM when the artist is home sleeping.\"</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_server_metadata/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Efficiency: You can ensure that heavy renders don't slow down artists while they are working.</li> <li>Troubleshooting: If a machine is constantly in an \"Error\" state, you can find it quickly in the metadata and fix it.</li> <li>Description: You can add custom notes like \"Node under the window\" or \"Needs more RAM\" to help you keep track of physical machines.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_server_metadata/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Server Metadata is the \"Health Report\" for your computers. By reading the <code>state</code> and <code>perfIndex</code>, you can make sure your studio's hardware is being used to its full potential without interrupting the creative team.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_terminology/","title":"Insight: Backburner Terminology","text":"<p>This document explains the specific \"Vocabulary\" used when talking about Flame's background rendering system.</p> <p>Target Audience: Novice programmers learning about distributed rendering.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_terminology/#1-the-core-components","title":"1. The Core Components","text":"<ul> <li>Backburner: The name of the entire system that manages background jobs.</li> <li>Job: A specific task (like \"Render the car commercial\"). A job is made up of many small parts.</li> <li>Backburner Manager: The \"Central Brain\" that decides which computer does which job.</li> <li>Backburner Server: The program on each computer that actually does the work.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_terminology/#2-technical-infrastructure","title":"2. Technical Infrastructure","text":"<ul> <li>Renderer / Rendering Engine: The \"Machine\" inside the computer that draws the pictures (e.g., Burn).</li> <li>Processing Engine: A machine that does non-picture tasks, like moving files or zipping folders.</li> <li>Plug-in / Adapter: The \"Translator\" that allows the Backburner Manager to talk to different software (like Flame, 3ds Max, or Maya).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-backburner_terminology/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>Knowing these terms helps you understand where a problem is happening.  - If your job won't start, the Manager might be down. - If the frames are coming out black, the Server or the Renderer might have a problem.</p>"},{"location":"insight/wiretap_sdk/insight-backburner_terminology/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Backburner is like a Construction Site. The Job is the building, the Manager is the foreman with the clipboard, and the Servers are the individual workers. The Adapters are the specific tools (hammers, saws) they use to get the job done.</p>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/","title":"Insight: Basic Programming Issues","text":"<p>This document explains the fundamental \"Rules of the Road\" when writing code for Wiretap.</p> <p>Target Audience: Novice programmers learning the API's syntax and behavior.</p>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/#1-the-wiretap-nameplate","title":"1. The \"WireTap\" Nameplate","text":"<p>Every class and function in the SDK starts with the word <code>WireTap</code>.  - Why? This is called Namespacing. it ensures that if your code uses other libraries (like a standard math library), the names won't clash and cause confusion for the computer.</p>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/#2-strings-and-the-wiretapstr-class","title":"2. Strings and the <code>WireTapStr</code> Class","text":"<p>In C++, \"Strings\" (text) can be tricky. Wiretap uses its own simplified version of text called <code>WireTapStr</code>. - Important: If you want to use Wiretap text in your own script, you usually have to \"Copy\" it into your own text variables first.</p>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/#3-error-handling-the-success-switch","title":"3. Error Handling (The Success Switch)","text":"<p>Every time you ask Wiretap to do something, it doesn't just \"do it\"\u2014it tells you True (I did it!) or False (I couldn't do it). - Pro Tip: Always wrap your Wiretap commands in an \"If Statement.\"</p> <pre><code>if handle.renameNode(\"NewName\") == False:\n    print(handle.lastError())\n</code></pre>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/#4-multi-threading-can-i-do-two-things-at-once","title":"4. Multi-Threading (Can I do two things at once?)","text":"<p>Wiretap allows you to use different threads (running different parts of your script simultaneously), but there is a catch: - The Rule: You can't share one \"Remote Control\" (Handle) between two threads.  - The Solution: If you have two threads, give each one its own unique handle to the clip.</p>"},{"location":"insight/wiretap_sdk/insight-basic_programming_issues/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The Wiretap API is built for Stability. It uses strict namespacing, custom text types, and a standard True/False success check to ensure that your studio's automation is reliable and doesn't crash when things get complicated.</p>"},{"location":"insight/wiretap_sdk/insight-clip_format_metadata/","title":"Insight: Clip Format Metadata","text":"<p>This document explains the technical \"DNA\" of a clip\u2014its format, resolution, and original source metadata.</p> <p>Target Audience: Novice programmers interested in technical metadata and file properties.</p>"},{"location":"insight/wiretap_sdk/insight-clip_format_metadata/#1-what-is-clip-format","title":"1. What is Clip Format?","text":"<p>Every video clip in Flame has a specific \"Identity\": - \"I am 1920x1080.\" - \"I am 10-bit color.\" - \"I play at 24 frames per second.\"</p> <p>The <code>WireTapClipFormat</code> class is the tool you use to read these specific properties.</p>"},{"location":"insight/wiretap_sdk/insight-clip_format_metadata/#2-accessing-the-source-data","title":"2. Accessing the Source Data","text":"<p>When you import a file (like an R3D or an OpenEXR) into Flame, Flame keeps a \"Receipt\" of where that file came from and all its original settings. This is called the <code>SourceData</code> stream.</p> <ul> <li>The Format: The <code>SourceData</code> is written in MIO XML, which is very similar to the \"Open Clip\" format.</li> <li>The Command: You use <code>getMetadata</code> with the <code>-s SourceData</code> flag to see it.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-clip_format_metadata/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<ul> <li>Verification: You can write a script that checks every clip in a library to make sure they are all the same resolution.</li> <li>Lineage: You can look at the <code>SourceData</code> to find the exact file path on the server where the original media lives, even if someone renamed the clip in Flame.</li> <li>Audio Info: For audio clips, there is a matching class called <code>WireTapAudioClipFormat</code> that tells you things like the sample rate (e.g., 48kHz).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-clip_format_metadata/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Think of Clip Format as the \"Spec Sheet\" for your video. While the <code>info</code> metadata tells you the name and date, the <code>ClipFormat</code> tells you the technical details you need to process the images correctly.</p>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/","title":"Insight: Clip Node Metadata (EDL)","text":"<p>This document explains the EDL (Edit Decision List) metadata stream inside a Flame clip. This is how Flame stores the \"Edit Instructions\" for a timeline.</p> <p>Target Audience: Novice technical artists interested in conforming and editorial workflows.</p>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/#1-what-is-a-wiretap-edl","title":"1. What is a Wiretap EDL?","text":"<p>In the old days of film editing, an EDL was a simple text file that told a machine: \"Take 5 seconds from Tape A and join it to 10 seconds from Tape B.\"</p> <p>Wiretap uses a modern version of this called the CMX 3600 format, but it adds special \"Autodesk Tags\" (starting with <code>DLEDL:</code>) to store extra info that normal EDLs can't handle.</p>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/#2-reading-the-map","title":"2. Reading the \"Map\"","text":"<p>When you look at a Wiretap EDL, you will see lines like these:</p> <ul> <li><code>FCM: NON-DROP FRAME</code>: Tells you if the clock skips numbers to stay accurate.</li> <li><code>DLEDL: SOURCEID</code>: A unique ID for the original clip. This is much more reliable than just using a name like \"v1.\"</li> <li><code>DLEDL: EDIT:0 FRAME</code>: A specific hex code (like <code>0x2581...</code>) that identifies every single image in the edit.</li> <li><code>DLEDL: REEL</code>: The full name of the tape or folder where the media lives.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/#3-transitions-and-virtual-sources","title":"3. Transitions and Virtual Sources","text":"<p>The EDL even handles complex things: - Dissolves: These are marked with a <code>D</code> followed by the number of frames (e.g., <code>D 004</code>). - Virtual Tapes: If a clip was generated inside Flame (like a solid Green color or SMPTE bars), the EDL gives it a \"Virtual\" tape name like <code>GREEN</code> or <code>COLOUR</code>.</p>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>By reading the EDL stream, your script can perfectly reconstruct a timeline in another application or database. You can see exactly which frames were used from which files without ever having to open the project in Flame.</p>"},{"location":"insight/wiretap_sdk/insight-clip_node_edl/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The EDL is the \"Recipe\" for your timeline. While the media files are the ingredients, the EDL tells Flame exactly how to \"Cook\" them\u2014which parts to cut, where to overlap them, and which frame IDs to pull from the server.</p>"},{"location":"insight/wiretap_sdk/insight-creating_backburner_jobs/","title":"Insight: Creating and Submitting Jobs","text":"<p>This document explains how your Python script can \"Hire\" Backburner to do a job for you.</p> <p>Target Audience: Novice programmers interested in task automation.</p>"},{"location":"insight/wiretap_sdk/insight-creating_backburner_jobs/#1-the-5-step-process","title":"1. The 5-Step Process","text":"<p>Submitting a job to the render farm follows a strict sequence:</p> <ol> <li>Create the Node: You build a new \"Empty\" job in the <code>/jobs</code> folder.</li> <li>Add General Info: You tell Backburner basic things like \"What is the name of this job?\" and \"Which plugin should I use (e.g., Burn)?\"</li> <li>Add Detailed Instructions: (Optional) You can give specific render settings, like \"Use 4x Anti-Aliasing.\"</li> <li>Attach Files: (Optional) If the job needs a specific setup file to run, you can \"push\" that file directly into the job node.</li> <li>Go!: When you first create a job, it is Suspended (Sleeping). You must change its status to Waiting to tell the farm to start working.</li> </ol>"},{"location":"insight/wiretap_sdk/insight-creating_backburner_jobs/#2-mandatory-info","title":"2. Mandatory Info","text":"<p>Backburner won't work unless you provide two key details: - <code>pluginName</code>: Which software should run this job? - <code>numTasks</code>: How many pieces should this job be split into?</p>"},{"location":"insight/wiretap_sdk/insight-creating_backburner_jobs/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>Normally, an artist has to hit \"Render\" manually inside Flame. With this API, you can write a script that says: \"Every night at midnight, find all finished edits and submit them to Backburner to create review movies.\" </p> <p>It turns manual \"Clicking\" into automatic \"Processing.\"</p>"},{"location":"insight/wiretap_sdk/insight-creating_backburner_jobs/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Creating a job is like Filling out a Form. You create the form (the node), fill in the blanks (the metadata), and then hand it to the manager (changing status to 'Waiting'). Once the manager has the form, the rest happens automatically!</p>"},{"location":"insight/wiretap_sdk/insight-gateway_formats/","title":"Insight: Supported Ingest Formats","text":"<p>This document explains the two main ways video is stored on your hard drive and how the Wiretap Gateway understands them.</p> <p>Target Audience: Novice programmers and technical artists.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_formats/#1-image-sequences-the-stack-of-photos","title":"1. Image Sequences (The \"Stack of Photos\")","text":"<p>An image sequence is a folder full of files, where each file is exactly one frame of video. - Common Formats: DPX, OpenEXR, TIFF, Cineon. - Easy to Identify: You can usually tell what's inside just by looking at the file extension (e.g., <code>.exr</code>).</p>"},{"location":"insight/wiretap_sdk/insight-gateway_formats/#2-container-formats-the-box-of-chocolate","title":"2. Container Formats (The \"Box of Chocolate\")","text":"<p>A container (or \"Wrapper\") is one single file that holds many different things inside it (Video, Audio, Metadata). - Common Formats: QuickTime (<code>.mov</code>), MXF, RED (<code>.r3d</code>). - The Catch: You can't tell what's inside just by the extension. A <code>.mov</code> file could be a low-res preview or a high-res master.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_formats/#3-how-the-gateway-helps","title":"3. How the Gateway Helps","text":"<p>The Wiretap Gateway is built to handle both. - It automatically \"Groups\" a stack of 10,000 DPX files into a single Clip node. - It \"Unwraps\" container files like ProRes or RED files so you can stream the video frames inside them across the network.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_formats/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The Gateway is your \"Universal Decoder.\" It doesn't matter if your footage is a giant list of EXR images or a single compressed QuickTime file\u2014the Gateway translates them all into the same \"Language\" so your Wiretap scripts can read them the same way.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_node_hierarchy/","title":"Insight: The Gateway Node Hierarchy","text":"<p>This document explains how the Wiretap Gateway looks at your computer's hard drive and turns it into a neat, organized list of clips.</p> <p>Target Audience: Novice programmers interested in file systems and media browsing.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_node_hierarchy/#1-what-is-the-gateway-hierarchy","title":"1. What is the Gateway Hierarchy?","text":"<p>The Gateway is like a Translator. It looks at a messy folder full of DPX or ProRes files and translates them into standard Wiretap Nodes.</p> <ul> <li><code>DIR</code>: A standard folder on your hard drive.</li> <li><code>CLIP</code>: A \"Smart\" node that groups multiple frames (like <code>shot.001.dpx</code> to <code>shot.100.dpx</code>) into a single object.</li> <li><code>HIRES</code>: The actual video data inside the clip.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-gateway_node_hierarchy/#2-multi-process-design","title":"2. Multi-Process Design","text":"<p>To keep everything fast, the Gateway uses two types of processes: 1.  The Main Process: The \"Boss\" that handles the startup. 2.  The Session Processes: A private \"Assistant\" created just for your script. This assistant keeps track of what you are doing so you don't interfere with other users on the network.</p>"},{"location":"insight/wiretap_sdk/insight-gateway_node_hierarchy/#3-warning-node-ids-are-black-boxes","title":"3. Warning: Node IDs are \"Black Boxes\"","text":"<p>A Node ID might look like a simple piece of text, but never try to guess what it means.  - The Rule: Always ask the \"Parent\" node for the list of its children. Don't try to build a Node ID manually, or your script will break when you update Flame!</p>"},{"location":"insight/wiretap_sdk/insight-gateway_node_hierarchy/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The Gateway is your \"Window\" to the outside world. It turns raw files on a hard drive into professional Flame clips that your scripts can read and process. Always use the <code>wiretap_get_children</code> command to explore this hierarchy safely.</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/","title":"Insight: Getting Started with Wiretap","text":"<p>This document explains the first steps to using the Wiretap SDK and the three different ways you can interact with it.</p> <p>Target Audience: Novice programmers and technical artists looking for the best \"Entry Point.\"</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#1-prerequisites","title":"1. Prerequisites","text":"<p>Before you can write code, you need to download and install the Wiretap Client SDK from Autodesk. This puts the necessary \"Tools\" and \"Libraries\" on your computer so your scripts can talk to Flame.</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#2-three-ways-to-play","title":"2. Three Ways to Play","text":"<p>Autodesk provides three ways to use the API, depending on your skill level and needs:</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#a-command-line-tools-for-everyone","title":"A. Command Line Tools (For Everyone)","text":"<p>These are pre-written programs you can run in your terminal. They allow you to \"See\" the API in action without writing a single line of code. - Best for: Quick tests, finding Node IDs, and seeing if your network is connected.</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#b-python-modules-for-rapid-scripting","title":"B. Python Modules (For Rapid Scripting)","text":"<p>Python is the most common way to use Wiretap. You don't have to compile your code, and you can see results instantly. - Best for: Automation, studio pipelines, and small utility tools.</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#c-c-classes-for-developers","title":"C. C++ Classes (For Developers)","text":"<p>This is for high-performance, professional application building. It is more complex but offers the most speed and control. - Best for: Building standalone apps that need to move massive amounts of video data very quickly.</p>"},{"location":"insight/wiretap_sdk/insight-getting_started/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>Start with the Command Line Tools!  Run a command like <code>wiretap_get_node_info</code> just to see how the computer responds. Once you understand how the system \"looks,\" moving to Python will be much easier because you'll already know what data to expect.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/","title":"Insight: The IFFFS Node Hierarchy","text":"<p>This document explains the tree-like structure inside a Flame project. Understanding this \"Map\" is essential for finding and modifying clips using the Wiretap API.</p> <p>Target Audience: Novice programmers interested in database structures.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/#1-the-tree-analogy","title":"1. The Tree Analogy","text":"<p>Think of a Flame project like a tree. You start at the trunk and follow the branches until you find the \"Leaves\" (the actual frames of video).</p> <p>The Hierarchy: 1.  PROJECT: The trunk. Contains everything for a specific job. 2.  WORKSPACE: A large branch. Usually one for every artist on the project. 3.  DESKTOP: A smaller branch. Where the current active work lives. 4.  LIBRARY: A folder where you store your clips. 5.  REEL: A group inside a library. 6.  CLIP: The final branch. 7.  HIRES / VERSION: The leaves. The actual images you see on the screen.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/#2-important-node-types","title":"2. Important Node Types","text":"<ul> <li><code>PROJECT</code>: The top level.</li> <li><code>LIBRARY</code>: The primary place where clips are organized.</li> <li><code>CLIP</code>: This node doesn't hold the pictures itself; it is a container for Versions.</li> <li><code>HIRES</code>: This is the child of a Clip that actually holds the high-resolution images.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/#3-the-commit-concept","title":"3. The \"Commit\" Concept","text":"<p>When you make a change via the API (like renaming a clip), Wiretap doesn't save it to the hard drive immediately. It waits 2 seconds to see if you have more changes. - Manual Save: You can force a save by sending a <code>COMMIT</code> command. This is like hitting \"Ctrl+S\" in a text editor.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>By knowing this hierarchy, you can write a script that says: \"Go to Project: 'Car_Ad', find Library: 'Daily_Renders', and list every CLIP inside it.\" Without this map, you'd be lost in thousands of files with no way to find the one you need.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_node_hierarchy/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Everything in Flame is a Node. To find anything, you just start at the top (The Project) and \"Walk\" down the tree using Node IDs until you reach your destination.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/","title":"Insight: IFFFS Troubleshooting (Unlinked Media)","text":"<p>This document explains a common \"Gotcha\" when using Wiretap to build timelines in Flame: why media sometimes appears \"Unlinked\" (Offline).</p> <p>Target Audience: Novice technical artists building automated conforming tools.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/#1-the-online-mystery","title":"1. The \"Online\" Mystery","text":"<p>You write a perfect script to build a timeline via Wiretap, but when you open Flame, the clips are all \"Checkerboard\" (No Media). Why?</p> <p>Flame is very strict about where it looks for files. When you create a timeline through the IFFFS Wiretap server, Flame uses two rules to find the media:</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/#rule-a-the-same-reel","title":"Rule A: The Same Reel","text":"<p>Flame expects the source clips to be in the Same Reel as the timeline you are building. If you put the sources in \"Reel 1\" but build the timeline in \"Reel 2,\" Flame might not look in the right place to link them.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/#rule-b-tape-name-match","title":"Rule B: Tape Name Match","text":"<p>Flame identifies clips by their Tape Name.  - If your media file says its tape name is <code>SHOT_01</code>, but your script tells the timeline to look for <code>Shot_01</code> (lowercase), they won't match!  - Tip: Always double-check your metadata for typos or case-sensitivity issues.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/#2-why-use-ifffs-for-timelines","title":"2. Why use IFFFS for Timelines?","text":"<p>Even with these rules, using IFFFS is the fastest way to build complex edits from the outside. Once you ensure your tape names are consistent and your organizational structure is clean, conforms happen instantly across the network.</p>"},{"location":"insight/wiretap_sdk/insight-ifffs_troubleshooting/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>If your media is offline after a Wiretap conform, check your Organization first. Make sure your source clips and your new timeline are \"Neighbors\" in the same reel, and that their Tape Names match exactly, character for character.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/","title":"Insight: Listing Backburner Jobs","text":"<p>This document explains how to get a simple list of everything currently happening on your render farm.</p> <p>Target Audience: Novice programmers interested in simple network queries.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/#1-where-do-the-jobs-live","title":"1. Where do the jobs live?","text":"<p>In the Backburner node hierarchy, all jobs are stored in a branch called <code>/jobs</code>. </p> <p>To see what's happening, you don't need to look at every machine; you just ask the Manager to show you the contents of that folder.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/#2-using-the-command-line","title":"2. Using the Command Line","text":"<p>The easiest way to see the list is using the <code>wiretap_get_children</code> tool in your terminal:</p> <p><code>wiretap_get_children -h localhost:Backburner -n /jobs</code></p> <ul> <li><code>-h</code>: The machine running the Backburner Manager.</li> <li><code>-n</code>: The folder you want to look at (<code>/jobs</code>).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/#3-what-you-get-back","title":"3. What you get back","text":"<p>The command will return a list of Node IDs. Each ID represents one job. You can then use those IDs to ask for more specific info (like the name or status) using the metadata commands.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>Listing jobs is the first step for any automated tool.  - You might write a script that counts how many jobs are currently \"Waiting.\" - You could create a tool that automatically deletes all \"Completed\" jobs every Friday.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_jobs/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Listing is the \"Discovery\" phase. Before you can monitor or control a job, you first have to find its ID. The <code>/jobs</code> folder is the central catalog where every task in the studio is recorded.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/","title":"Insight: Listing Backburner Servers","text":"<p>This document explains how to get a list of every computer (Render Node) currently registered with your Backburner farm.</p> <p>Target Audience: Novice technical artists and IT support.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/#1-where-do-the-workers-live","title":"1. Where do the workers live?","text":"<p>In the Backburner node hierarchy, all computers are listed in a branch called <code>/servers</code>. </p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/#2-using-the-command-line","title":"2. Using the Command Line","text":"<p>To see every computer on your farm, use the <code>wiretap_get_children</code> tool:</p> <p><code>wiretap_get_children -h localhost:Backburner -n /servers</code></p> <ul> <li><code>-h</code>: The machine running the Backburner Manager.</li> <li><code>-n</code>: The folder containing the computer list (<code>/servers</code>).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/#3-what-you-get-back","title":"3. What you get back","text":"<p>The command will return a list of Hostnames (e.g., <code>RenderNode01</code>, <code>ArtistWorkstation</code>, <code>BladeServer</code>). You can then use these hostnames to check the health of each machine individually.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<ul> <li>Network Audit: Quickly see if any computers have gone missing from the farm.</li> <li>Dynamic Targeting: You can write a script that finds every idle machine and assigns them a high-priority task.</li> <li>Troubleshooting: Confirm that a new computer has successfully \"Joined\" the farm after installation.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_servers/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The <code>/servers</code> node is the \"Staff Roster\" of your studio. It tells you exactly who is available to work. By querying this list, you can keep your studio's rendering resources organized and accounted for.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_wiretap_servers/","title":"Insight: Listing Backburner Wiretap Servers","text":"<p>This document explains the naming rules for Wiretap servers and how to find them on your network.</p> <p>Target Audience: Novice technical artists interested in network identification.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_wiretap_servers/#1-the-naming-formula","title":"1. The Naming Formula","text":"<p>Every Wiretap server ID is made of two parts joined by a colon: <code>Hostname : DatabaseType</code></p> <ul> <li><code>Hostname</code>: The name of the computer (e.g., <code>workstation01</code>).</li> <li><code>DatabaseType</code>: The \"Language\" it speaks. For background rendering, this is always <code>Backburner</code>.</li> </ul> <p>Example: <code>workstation01:Backburner</code></p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_wiretap_servers/#2-searching-the-network","title":"2. Searching the Network","text":"<p>You don't have to guess which machines are running Backburner. You can use the <code>wiretap_server_dump</code> command to \"Scan\" the network for specific types of servers:</p> <p><code>wiretap_server_dump -d Backburner</code></p> <p>This will return a list of every machine ready to receive render jobs.</p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_wiretap_servers/#3-testing-the-connection","title":"3. Testing the Connection","text":"<p>If you want to see if your own computer is ready, you can use the \"Loopback\" address:</p> <p><code>wiretap_ping -h localhost:Backburner</code></p>"},{"location":"insight/wiretap_sdk/insight-listing_backburner_wiretap_servers/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Think of the Wiretap ID as a Radio Station. The <code>Hostname</code> is the frequency, and the <code>DatabaseType</code> is the station name. By using the <code>-d Backburner</code> flag, you are tuning your radio to only hear the rendering stations on your network.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/","title":"Insight: Build Issues on macOS","text":"<p>This document explains a specific technical hurdle you might face when writing Wiretap tools on a Mac: managing dynamic library paths.</p> <p>Target Audience: Novice developers using macOS for studio automation.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#1-the-macos-hardcoded-path-rule","title":"1. The macOS \"Hardcoded Path\" Rule","text":"<p>On most computers (Linux/Windows), when you write a program, it looks for its \"Engine\" files (Libraries) in a standard list of folders. </p> <p>On macOS, libraries (<code>.dylib</code> files) often have their exact \"Home Address\" baked right into them. By default, the Wiretap library expects to live in <code>/Library/Frameworks</code>.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#2-the-problem","title":"2. The Problem","text":"<p>If you install the Wiretap SDK in a different folder (like your desktop or a custom project folder), your program will crash because it's still looking for the library in the \"Standard\" location.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#3-two-ways-to-fix-it","title":"3. Two Ways to Fix It","text":""},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#a-the-shortcut-environment-variable","title":"A. The \"Shortcut\" (Environment Variable)","text":"<p>You can tell your computer to look in a different place just for this session by setting the <code>DYLD_LIBRARY_PATH</code>. This is like giving the computer a temporary set of directions.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#b-the-surgery-install_name_tool","title":"B. The \"Surgery\" (<code>install_name_tool</code>)","text":"<p>You can use a built-in Mac tool to \"Rewrite\" the library's address permanently.  - Command: <code>install_name_tool -id /New/Path/libwiretap.dylib</code> - Verification: You can use the <code>otool -L</code> command to confirm the change. It's like checking the ID card of the library to make sure it has the new address.</p>"},{"location":"insight/wiretap_sdk/insight-macos_library_paths/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>If your Mac script won't run and says \"Library not found,\" it's probably because of this hardcoded path rule. Before you give up, try using <code>install_name_tool</code> to tell the library exactly where it is currently living on your hard drive.</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/","title":"Insight: Managing Clips","text":"<p>This document explains how to handle the most important part of Flame: the Clips.</p> <p>Target Audience: Novice programmers interested in media ingestion and organization.</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#1-anatomy-of-a-clip-node","title":"1. Anatomy of a Clip Node","text":"<p>In Wiretap, a \"Clip\" is actually a container that holds different versions of the same video:</p> <ul> <li><code>HIRES</code>: The full-quality original images.</li> <li><code>LOWRES</code>: The small \"Proxy\" versions used for fast playback.</li> <li><code>SLATE</code>: A shortcut to the smallest version available.</li> <li><code>AUDIOSTREAM</code>: The sound attached to the video.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#2-ingesting-media-three-methods","title":"2. Ingesting Media (Three Methods)","text":"<p>How do you get a movie into a Flame clip via the API?</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#method-a-writing-frames-the-copy-way","title":"Method A: Writing Frames (The \"Copy\" way)","text":"<p>You manually write raw pixels to a new clip.  - Use case: Creating a new clip from scratch inside a script.</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#method-b-soft-importing-the-reference-way","title":"Method B: Soft-Importing (The \"Reference\" way)","text":"<p>You tell Flame where the file is on your server. Flame doesn't copy the file; it just \"Points\" to it. - Use case: The standard way to bring camera footage (like R3D or ProRes) into a project.</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#method-c-path-linking-the-direct-way","title":"Method C: Path Linking (The \"Direct\" way)","text":"<p>You give Flame a list of file paths. This is the fastest way to build a clip from a sequence of images (like 10,000 DPX files).</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#3-the-no-overwrite-rule","title":"3. The \"No Overwrite\" Rule","text":"<p>Flame is very protective of its media. You cannot overwrite the frames of an existing clip via the API. - The Workflow: If you want to change a clip, you must create a NEW clip, write the new frames to it, and then delete the old one.</p>"},{"location":"insight/wiretap_sdk/insight-managing_clips/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Clips are the \"Leaves\" of the Flame tree. By using <code>WireTapClipFormat</code>, you define the technical specs, and by using <code>createClipNode</code>, you build the container. Remember: always prefer \"Soft-Importing\" (Method B) to save disk space and time!</p>"},{"location":"insight/wiretap_sdk/insight-managing_containers/","title":"Insight: Managing Containers","text":"<p>This document explains how to use \"Folders\" (Containers) to keep your Flame projects organized using the API.</p> <p>Target Audience: Novice programmers interested in project management and organization.</p>"},{"location":"insight/wiretap_sdk/insight-managing_containers/#1-what-are-containers","title":"1. What are Containers?","text":"<p>In Flame, you don't just dump all your clips in one big pile. You organize them using specialized containers:</p> <ul> <li><code>WORKSPACE</code>: A private area for an artist.</li> <li><code>DESKTOP</code>: The \"Current Work\" area.</li> <li><code>LIBRARY</code>: A permanent folder for storing clips.</li> <li><code>REEL</code>: A smaller group inside a library.</li> <li><code>BATCH</code>: A special container for complex compositing trees.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-managing_containers/#2-navigating-and-creating","title":"2. Navigating and Creating","text":"<p>Building a studio standard is easy with the API. You can write a script that says: 1.  <code>createNode</code>: Build a new Library called \"Renders_V01.\" 2.  <code>wiretap_print_tree</code>: Check to make sure it was built in the right place. 3.  <code>can_create_node</code>: Ask if it is legal to put a Reel inside this Folder (The API will tell you \"Yes\" or \"No\").</p>"},{"location":"insight/wiretap_sdk/insight-managing_containers/#3-the-exclusive-access-rule","title":"3. The \"Exclusive Access\" Rule","text":"<p>To keep data safe, Wiretap needs Exclusive Access to change a container. - If an artist has a Library open in Flame and is currently editing it, your script will fail if it tries to rename that Library. - Tip: Always check if the node is \"In Use\" before trying to change its structure.</p>"},{"location":"insight/wiretap_sdk/insight-managing_containers/#4-why-use-containers","title":"4. Why use Containers?","text":"<p>Standardization is key to a professional studio. By using the API to manage containers, you can ensure that every artist in the building has the exact same \"Daily\" and \"Archive\" folders, making it much easier for people to share work.</p>"},{"location":"insight/wiretap_sdk/insight-managing_containers/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Containers are the \"Infrastructure\" of your project. They don't hold video data directly; they hold the organization that makes the video data easy to find. Use <code>createNode</code> to build your studio's standardized roadmap!</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/","title":"Insight: Managing Projects and Setups","text":"<p>This document explains how to use the API to automatically create, configure, and manage Flame projects.</p> <p>Target Audience: Novice programmers interested in project administration.</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/#1-creating-a-new-project","title":"1. Creating a New Project","text":"<p>Creating a project through the API is like using the \"New Project\" window in Flame, but much faster. - Default Settings: If you just give it a name, Flame uses the standard studio defaults. - Custom Settings (XML): You can provide an XML file to specify exactly how the project should look (e.g., \"This job is 4K,\" or \"Use this specific color policy\").</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/#2-using-templates","title":"2. Using Templates","text":"<p>If your studio has a standard \"Master Template\" for all jobs, you can tell the API to use it:</p> <pre><code>&lt;Project&gt;\n    &lt;Template&gt;Studio_Commercial_Template&lt;/Template&gt;\n&lt;/Project&gt;\n</code></pre> <p>This ensures every project starts with the right resolution and folder structure.</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/#3-managing-setups","title":"3. Managing \"Setups\"","text":"<p>A Setup is a small file that saves the settings for a specific Flame tool (like a GMask or a Color Correction). - Streaming: Setups can be large. You use the <code>pushStream</code> and <code>pullStream</code> commands to upload or download these files from the project.</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/#4-deleting-projects","title":"4. Deleting Projects","text":"<p>Deleting a project is a two-step process: 1.  Empty the Project: You must delete all Libraries inside the project first. 2.  Destroy the Node: Once empty, you can permanently remove the project from the workstation.</p>"},{"location":"insight/wiretap_sdk/insight-managing_projects/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The Project API is the \"Architect\" of your workflow. Instead of artists wasting time setting up folders and choosing resolutions, your script can prepare everything perfectly before they even arrive at their desk.</p>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/","title":"Insight: Project Metadata (XML)","text":"<p>This document explains the XML structure Flame uses to store project settings like resolution, frame rate, and color management.</p> <p>Target Audience: Novice programmers interested in technical specifications and configuration.</p>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/#1-what-is-project-metadata","title":"1. What is Project Metadata?","text":"<p>When you create a new project in Flame, you set certain \"Rules\"\u2014for example, \"This project is 1920x1080 at 24fps.\" Wiretap stores these rules in an XML stream.</p>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/#2-key-settings-the-xml-tags","title":"2. Key Settings (The XML Tags)","text":"<p>When you look at a project's metadata, you will see these important tags:</p> <ul> <li><code>&lt;FrameWidth&gt;</code> / <code>&lt;FrameHeight&gt;</code>: The \"Size\" of your video.</li> <li><code>&lt;FrameRate&gt;</code>: How fast it plays (e.g., <code>24 fps</code> or <code>29.97 fps NDF</code>).</li> <li><code>&lt;AspectRatio&gt;</code>: The shape of the screen (e.g., <code>1.77778</code> for 16:9).</li> <li><code>&lt;ProxyQuality&gt;</code>: How Flame generates low-res \"Proxy\" versions of your media.</li> <li><code>&lt;OCIOConfigFile&gt;</code>: The path to your color management \"Rulebook.\"</li> </ul>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/#3-editable-vs-fixed","title":"3. Editable vs. Fixed","text":"<ul> <li>Creation Only: Some settings, like where the media is stored (<code>&lt;MediaDir&gt;</code>), can ONLY be set when the project is first created.</li> <li>Always Editable: You can change things like the <code>&lt;Description&gt;</code> or <code>&lt;FrameDepth&gt;</code> (8-bit vs 10-bit) any time you want using the <code>setMetaData</code> command.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>By reading this XML, a pipeline script can automatically check if a project is set up correctly according to studio standards. If a project is set to \"8-bit\" when it should be \"16-bit fp,\" the script can flag it or even fix it automatically.</p>"},{"location":"insight/wiretap_sdk/insight-project_metadata_xml/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Project XML is the \"Birth Certificate\" of a Flame project. It lists every important detail about how video should be handled. If you want to automate project creation, you must master these XML tags!</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/","title":"Insight: Raw Audio Format (DL)","text":"<p>This document explains how sound is \"Encoded\" when it travels through the Wiretap network.</p> <p>Target Audience: Novice programmers interested in audio engineering and data types.</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/#1-what-is-raw-audio","title":"1. What is Raw Audio?","text":"<p>Raw audio is just a long list of numbers representing sound waves. Wiretap calls this the <code>dlaudio</code> format.</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/#2-key-formats","title":"2. Key Formats","text":"<p>The API supports three main types of numbers for sound: - <code>int16</code>: CD Quality. - <code>int24</code>: Studio Quality. - <code>float</code>: High-end processing (Used for internal mixing).</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/#3-endianness-the-big-vs-little-rule","title":"3. Endianness (The \"Big vs Little\" rule)","text":"<p>Computers read numbers in different directions. - Big-endian: Reads the most important digit first. - Little-endian (<code>_le</code>): Reads the smallest digit first. Wiretap supports both, and your script must check which one the server is using so the sound doesn't come out as static!</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/#4-multi-channel-audio","title":"4. Multi-Channel Audio","text":"<p>If a clip has multiple tracks (like Stereo Left and Right), Wiretap Interlaces them.  - Instead of all the Left samples followed by all the Right samples, it sends them in pairs: <code>L, R, L, R, L, R</code>.  - This ensures that the left and right speakers stay perfectly in sync.</p>"},{"location":"insight/wiretap_sdk/insight-raw_audio_format/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>To read audio in Wiretap, you first ask for the <code>formatTag</code>. This tells you if the samples are Integers or Floats, and if they are Big- or Little-Endian. Once you know that, you just \"De-interlace\" the stream to separate the different speakers.</p>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/","title":"Insight: Raw RGB Video Format","text":"<p>This document explains the technical \"Architecture\" of an image frame when it moves through Wiretap.</p> <p>Target Audience: Novice programmers interested in low-level image data and memory management.</p>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/#1-pure-pixel-data","title":"1. Pure Pixel Data","text":"<p>When you ask Wiretap for a frame, it doesn't give you a file (like a .jpg). It gives you a Buffer\u2014a giant chunk of memory filled with raw color numbers.</p> <ul> <li>Orientation: Flame reads images from Bottom to Top. </li> <li>Components: Every pixel has 3 parts: Red, Green, and Blue.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/#2-bit-size-depth","title":"2. Bit Size (Depth)","text":"<p>The \"Bit Size\" tells you how much detail is in every color. Wiretap supports several levels: - 8-bit: Standard quality (256 levels of color). - 10-bit: Professional quality (1,024 levels). - 32-bit float: High-end visual effects (Used for complex lighting and HDR).</p>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/#3-the-padding-trick","title":"3. The \"Padding\" Trick","text":"<p>Computers like to read data in neat blocks of 32 bits. If your image width isn't a \"Perfect\" number, Wiretap adds invisible Filler Bits (Padding) to the end of every line. - Why? It makes the computer's CPU work much faster because it doesn't have to \"Guess\" where the next line starts.</p>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/#4-calculating-memory","title":"4. Calculating Memory","text":"<p>If you want to know how much RAM you need to hold a frame, use this formula: <code>Width</code> x <code>Height</code> x <code>Bytes per Pixel</code> = <code>Total Memory</code></p> <ul> <li>Example: A 1080p 8-bit frame is about 6 MB. </li> <li>Example: A 4K 32-bit float frame can be over 100 MB!</li> </ul>"},{"location":"insight/wiretap_sdk/insight-raw_rgb_format/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Raw RGB is like a \"Map of Numbers.\" There are no shortcuts or compression. To use it in your script, you need to know exactly how many bits each color uses and how many \"Filler\" bits are at the end of each line so you don't accidentally shift the image sideways!</p>"},{"location":"insight/wiretap_sdk/insight-sending_backburner_attachments/","title":"Insight: Sending Job Attachments","text":"<p>This document explains how to send large files (like 3D scenes or color LUTs) along with your render job to the farm.</p> <p>Target Audience: Novice programmers interested in data transfer and complex job submission.</p>"},{"location":"insight/wiretap_sdk/insight-sending_backburner_attachments/#1-metadata-vs-streams","title":"1. Metadata vs. Streams","text":"<ul> <li>Metadata (<code>details</code>): Use this for small text instructions (e.g., \"Render Frame 1 to 10\").</li> <li>Streams (<code>pushStream</code>): Use this for large or binary files (e.g., a 500MB project file or a complex texture).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-sending_backburner_attachments/#2-the-push-workflow","title":"2. The \"Push\" Workflow","text":"<p>If your render needs a specific file to work, you don't just tell Backburner where the file is on your computer. You Upload the file to the Backburner Manager.</p> <ol> <li>Prepare: Compress your file (e.g., zip it) to make the upload faster.</li> <li>Push: Use the <code>pushStream</code> command to send the file to the Manager.</li> <li>Deploy: When a worker computer (Server) starts your job, the Manager automatically hands it the attachment so it has everything it needs to render.</li> </ol>"},{"location":"insight/wiretap_sdk/insight-sending_backburner_attachments/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>It ensures that the render farm doesn't need access to your personal computer's hard drive. By \"Attaching\" the files to the job, you are making the job Self-Contained. This is the only way to reliably render complex projects on a large, multi-machine farm.</p>"},{"location":"insight/wiretap_sdk/insight-sending_backburner_attachments/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Attachments are the \"Backpack\" for your job. You fill the backpack with all the tools and maps the worker needs, then hand it to the Manager. No matter which machine in the studio does the work, they'll have the backpack ready to go.</p>"},{"location":"insight/wiretap_sdk/insight-server_discovery/","title":"Insight: Discovering Wiretap Servers","text":"<p>This document explains the \"Three IDs\" Wiretap uses to find and remember machines on your network.</p> <p>Target Audience: Novice technical artists interested in network persistence.</p>"},{"location":"insight/wiretap_sdk/insight-server_discovery/#1-the-server-id-the-nickname","title":"1. The Server ID (The \"Nickname\")","text":"<p>The Server ID is what you use to connect for the first time. - Formula: <code>Hostname : ServerType</code> (e.g., <code>Workstation01:IFFFS</code>). - Flexible: You can use the computer's name OR its IP address (e.g., <code>192.168.1.50:IFFFS</code>).</p>"},{"location":"insight/wiretap_sdk/insight-server_discovery/#2-the-host-uuid-the-social-security-number","title":"2. The Host UUID (The \"Social Security Number\")","text":"<p>A computer's name might change (e.g., if it moves to a different office), but its Host UUID never changes. - Why use it? If you have a script that needs to find the exact same computer every day, use the UUID. It identifies the hardware, not the network name.</p>"},{"location":"insight/wiretap_sdk/insight-server_discovery/#3-the-storage-id-the-briefcase-id","title":"3. The Storage ID (The \"Briefcase ID\")","text":"<p>A Storage ID identifies the Hard Drive Array connected to a server. - Persistence: If a studio moves a hard drive from \"Computer A\" to \"Computer B,\" the Storage ID stays the same.  - The Rule: Professional tools always remember the Storage ID. That way, if the network changes, the script can just scan the network and say: \"Who is holding the briefcase with ID #1234?\" and find the data instantly.</p>"},{"location":"insight/wiretap_sdk/insight-server_discovery/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>To connect to a server today, use the Server ID. To make your script work tomorrow (even if the computer is renamed), ask the server for its Storage ID and save that ID in your database.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/","title":"Insight: Setting up for C++ Developers","text":"<p>This document explains the technical \"Ingredients\" you need to build a high-performance Wiretap program in C++.</p> <p>Target Audience: Novice developers interested in low-level systems programming.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#1-the-ingredients-headers-and-libraries","title":"1. The Ingredients (Headers and Libraries)","text":"<p>To bake a C++ program, you need two things from the SDK: 1.  Headers (<code>.h</code> files): These are in the <code>api/</code> folder. They tell your code which functions are available. 2.  Libraries (<code>.a</code> or <code>.dylib</code> files): These are in the <code>lib/</code> folder. They are the \"Engine\" that does the work.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#2-compiling-your-code","title":"2. Compiling your Code","text":"<p>Compiling is the process of turning your human-readable code into a program the computer can run.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#on-linux-using-gcc","title":"On Linux (Using GCC):","text":"<p>You must link your code against the Wiretap library and standard network tools: <code>g++ my_code.C -o my_app -I ../api ../lib/libwiretapClientAPI.a -lpthread</code></p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#on-macos-using-clang","title":"On macOS (Using Clang):","text":"<p>It's very similar, but you also need to include Apple's \"Carbon\" and \"SystemConfiguration\" frameworks so Wiretap can talk to the Mac's network settings.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#3-why-use-c","title":"3. Why use C++?","text":"<p>C++ is the fastest way to talk to Flame. If your tool needs to move thousands of 4K frames every minute, C++ will give you much better performance than Python.</p>"},{"location":"insight/wiretap_sdk/insight-setup_cpp/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>C++ development is like \"Custom Engine Building.\" It's more complex than Python, and you have to manually \"Wire up\" the headers and libraries during compilation. But once it's built, you have the most powerful and efficient tool possible for managing your Flame studio.</p>"},{"location":"insight/wiretap_sdk/insight-setup_python/","title":"Insight: Setting up for Python Developers","text":"<p>This document explains the easiest way to start writing scripts for Flame using the Python language.</p> <p>Target Audience: Novice programmers interested in rapid automation.</p>"},{"location":"insight/wiretap_sdk/insight-setup_python/#1-the-easiest-way-use-flames-python","title":"1. The Easiest Way: Use Flame's Python","text":"<p>You don't need to install Python yourself! Every Flame workstation already has a professional Python environment installed. - Location: <code>/opt/Autodesk/python/&lt;version&gt;/bin/python</code> - Why use it? It already has the Wiretap libraries pre-installed and ready to go. You can just start writing code!</p>"},{"location":"insight/wiretap_sdk/insight-setup_python/#2-using-external-python","title":"2. Using External Python","text":"<p>If you want to use your own version of Python (like Python 3.11), you can do that too.  - You just need to \"Link\" the Wiretap library by copying the <code>libwiretapPythonClientAPI.so</code> file from the SDK into your Python's <code>site-packages</code> folder.</p>"},{"location":"insight/wiretap_sdk/insight-setup_python/#3-how-to-get-help-the-python-way","title":"3. How to get Help (The Python Way)","text":"<p>The SDK doesn't include a separate manual for Python. Instead, you can ask Python to \"Explain\" itself:</p> <ol> <li>Open Python in your terminal.</li> <li>Import the library: <code>import libwiretapPythonClientAPI as wiretap</code></li> <li>Ask for a list of classes: <code>dir(wiretap)</code></li> <li>Ask for instructions on a specific tool: <code>help(wiretap.WireTapNodeHandle)</code></li> </ol>"},{"location":"insight/wiretap_sdk/insight-setup_python/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Python is the \"Speed Demon\" of development. You don't have to compile your code, and you can get immediate answers using the <code>help()</code> command. If you want to build a tool quickly, always start with Python!</p>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/","title":"Insight: Traversing and Modifying Nodes","text":"<p>This document explains how to \"Walk\" through Flame's database and change things using the Wiretap SDK.</p> <p>Target Audience: Novice programmers learning about object manipulation and navigation.</p>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/#1-the-node-handle-wiretapnodehandle","title":"1. The Node Handle (<code>WireTapNodeHandle</code>)","text":"<p>In Wiretap, you don't \"touch\" a clip directly. Instead, you use a Handle.  - Think of a Handle like a Remote Control. You point it at a node (like a clip or project) and press buttons to \"Rename,\" \"Delete,\" or \"Copy\" it.</p> <p>Important Rule: Handles are not \"Live.\" If an artist in Flame renames a clip while your script is running, your handle won't know unless you specifically ask it to refresh.</p>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/#2-navigating-the-tree","title":"2. Navigating the Tree","text":"<p>To find a specific clip, you use these basic commands: - <code>wiretap_get_root_node</code>: Start at the very top (The Trunk). - <code>wiretap_get_children</code>: See everything \"inside\" the current node. - <code>wiretap_get_parent_node</code>: Move back up one level.</p>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/#3-creating-and-deleting","title":"3. Creating and Deleting","text":"<ul> <li><code>createNode</code>: Use this to build new Projects or Libraries.</li> <li><code>createClipNode</code>: A special command just for making clips.</li> <li><code>destroyNode</code>: The \"Delete\" button. Be careful\u2014this is permanent!</li> </ul>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/#4-metadata-reading-the-tag","title":"4. Metadata: Reading the \"Tag\"","text":"<p>Every node has a Metadata Stream. This is usually an XML file that describes the node. - <code>getMetaData</code>: Read the info (e.g., \"What is the frame rate of this clip?\"). - <code>setMetaData</code>: Write new info (e.g., \"Change the description of this project\").</p>"},{"location":"insight/wiretap_sdk/insight-traversing_nodes/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Think of traversing like using Finder or Windows Explorer, but with code. You \"Open folders\" (Nodes) and \"Read files\" (Metadata) until you find exactly what you are looking for. Once you have the right Node ID, you can use your Handle to modify it.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/","title":"Insight: Programming Typical Workflows","text":"<p>This document provides an overview of the \"Job Roles\" the Wiretap SDK can perform in your studio.</p> <p>Target Audience: Novice programmers and pipeline technical directors.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#1-what-can-you-automate","title":"1. What can you automate?","text":"<p>The Wiretap SDK isn't just for reading data; it's for Taking Action. The typical workflows are divided into three main categories:</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#a-managing-projects","title":"A. Managing Projects","text":"<p>Automatically create new projects, set their resolution and frame rate, and prepare the workspace for the artist.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#b-managing-containers","title":"B. Managing Containers","text":"<p>Organize your project by creating Libraries, Folders, and Reels. You can build a script that sets up a standardized folder structure for every new job.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#c-managing-clips","title":"C. Managing Clips","text":"<p>The most common task. Use the API to: - Soft-import media from a server. - Rename or delete old versions. - Build timelines automatically from an EDL.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#2-choosing-your-server","title":"2. Choosing your Server","text":"<p>The workflow you choose depends on which \"Librarian\" you talk to: - Talk to IFFFS to manage Flame's internal database. - Talk to Gateway to browse and ingest files from your hard drives. - Talk to Backburner to handle the rendering of your work.</p>"},{"location":"insight/wiretap_sdk/insight-typical_workflows_overview/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>Think of typical workflows as \"Tool Templates.\" Whether you want to build a \"Project Creator\" or a \"Media Browser,\" the SDK documentation provides the logical steps and sample code to get you started.</p>"},{"location":"insight/wiretap_sdk/insight-understanding_wiretap/","title":"Insight: Understanding Wiretap","text":"<p>This document explains the Wiretap framework in Autodesk Flame. It is the \"Communication Layer\" that allows different software and servers to talk to each other and share media.</p> <p>Target Audience: Novice programmers and technical artists interested in network storage and interoperability.</p>"},{"location":"insight/wiretap_sdk/insight-understanding_wiretap/#1-what-is-wiretap","title":"1. What is Wiretap?","text":"<p>Wiretap is a high-performance system used to move media (video/audio) and metadata (info about clips) across a network. </p> <p>Think of it as a \"Universal Language\" for the Flame ecosystem. Whether you are using a Python script, a web browser, or another Flame workstation, Wiretap allows you to \"reach into\" a database and grab exactly what you need without manually copying files.</p>"},{"location":"insight/wiretap_sdk/insight-understanding_wiretap/#2-the-core-pillars","title":"2. The Core Pillars","text":"<p>Wiretap is built on three main sections:</p> <ul> <li>Wiretap Terminology: The basic words you need to know (Servers, Clients, Nodes).</li> <li>Server/Client Roles: How the different parts of the system interact.</li> <li>Self-Discovery: How Wiretap \"finds\" other machines on your network automatically.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-understanding_wiretap/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>Without Wiretap, you would have to manually find clips on a hard drive, remember which folder they are in, and hope you don't break the database. </p> <p>With Wiretap: - You can write a script that says: \"Find me the 'Final Render' in the 'Summer Commercial' project.\" - Wiretap finds it instantly, no matter which server it is stored on. - You can stream that media directly into your script for processing.</p>"},{"location":"insight/wiretap_sdk/insight-understanding_wiretap/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Wiretap turns your studio from a collection of \"Hard Drives and Folders\" into a Unified Database. It is the technology that makes collaborative workflows possible in a professional post-production environment.</p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/","title":"Insight: Using Command Line Tools","text":"<p>This document explains how to use the pre-built programs included in the SDK to test your network and \"See\" inside Flame without writing any code.</p> <p>Target Audience: Novice developers and technical artists.</p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#1-where-are-the-tools","title":"1. Where are the tools?","text":"<p>Autodesk keeps the current version of the tools in a standard location on your computer: <code>/opt/Autodesk/wiretap/tools/current/</code></p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#2-three-essential-tools","title":"2. Three Essential Tools","text":""},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#a-wiretap_ping","title":"A. <code>wiretap_ping</code>","text":"<p>The \"Hello, World\" of Wiretap. It checks if a machine is alive and speaking the Wiretap language. - Command: <code>wiretap_ping -h &lt;machine_name&gt;</code></p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#b-wiretap_server_dump","title":"B. <code>wiretap_server_dump</code>","text":"<p>The \"Radar.\" it scans your entire network and shows you every Flame workstation, Gateway, and Backburner Manager. - Command: <code>wiretap_server_dump</code></p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#c-wiretap_print_tree","title":"C. <code>wiretap_print_tree</code>","text":"<p>The \"X-Ray.\" It prints out the entire organizational structure of a workstation, showing every Project, Library, and Clip. - Command: <code>wiretap_print_tree -h &lt;machine_name&gt; -d 2</code> (The <code>-d 2</code> tells it to only go two levels deep).</p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#3-how-to-get-help","title":"3. How to get help","text":"<p>Every tool has a manual built right in. Just type the command followed by <code>--help</code>: <code>wiretap_ping --help</code></p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#4-why-use-these-tools","title":"4. Why use these tools?","text":"<p>Before you start writing a complex script to delete old projects, use <code>wiretap_print_tree</code> to make sure you can \"See\" those projects first. It\u2019s the best way to verify that your network and permissions are set up correctly.</p>"},{"location":"insight/wiretap_sdk/insight-using_command_line_tools/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The command-line tools are your \"Sanity Check.\" If you can't see a workstation with <code>wiretap_server_dump</code>, your script won't be able to see it either. Always use these tools to confirm your network is working before you spend time writing custom code.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/","title":"Insight: Using Sample Programs","text":"<p>This document explains how to use the \"Ready-Made\" examples inside the SDK to learn the Wiretap language faster.</p> <p>Target Audience: Novice programmers looking for code templates.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#1-the-sdk-cheat-sheet","title":"1. The SDK \"Cheat Sheet\"","text":"<p>The SDK comes with a folder called <code>samples/</code>. These are small, focused scripts written by Autodesk engineers. They are the best way to see the \"Best Practices\" for using the API.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#2-two-recommended-first-samples","title":"2. Two Recommended First Samples","text":""},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#a-listallservers","title":"A. <code>listAllServers</code>","text":"<p>This sample does exactly what it says: it scans your network and prints a list of every workstation. - What you'll learn: How to initialize the API and how to use the \"Multicast\" discovery system.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#b-listchildren","title":"B. <code>listChildren</code>","text":"<p>This sample lets you \"Drill Down\" into a project. You give it a starting point (like a Project name), and it lists everything inside. - What you'll learn: How to navigate the tree-like structure of a Flame workstation.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#3-how-to-use-them","title":"3. How to use them","text":"<p>Don't just run them! Read them.  - Open the <code>.py</code> or <code>.C</code> files in a text editor.  - Look for the <code>WireTapClientInit()</code> function (The \"Start\" button) and the <code>WireTapClientUninit()</code> function (The \"Stop\" button). - You can literally \"Cut and Paste\" these blocks of code into your own project.</p>"},{"location":"insight/wiretap_sdk/insight-using_sample_programs/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The sample programs are your \"Building Blocks.\" You don't need to invent everything from scratch. If you want to build a tool that renames clips, find the sample that lists clips, copy that code, and then add your renaming logic on top of it.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_audio_io/","title":"Insight: Reading Audio Media","text":"<p>This document explains how Wiretap handles audio data and how it differs from video data.</p> <p>Target Audience: Novice programmers interested in audio processing and network efficiency.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_audio_io/#1-small-data-big-network","title":"1. Small Data, Big Network","text":"<p>Audio data is tiny compared to video.  - Video: 1 second of video can be 30MB or more. - Audio: 1 second of audio is only about 172KB.</p> <p>If you asked Wiretap for every single audio sample one-by-one, the network would get \"Clogged\" with thousands of tiny requests. </p>"},{"location":"insight/wiretap_sdk/insight-wiretap_audio_io/#2-the-block-solution","title":"2. The \"Block\" Solution","text":"<p>To keep things fast, Wiretap doesn't send audio sample-by-sample. Instead, it groups samples together into Blocks (called \"Frames\" in the API).</p> <ul> <li>When you ask for an \"Audio Frame,\" you are actually getting a chunk of sound\u2014usually enough to match exactly one frame of video.</li> <li>The size of these blocks is determined by the <code>WireTapClipFormat</code>. It tells your script: \"This block has 2,000 samples of 16-bit audio.\"</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_audio_io/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>This ensures that audio and video stay perfectly in sync. Because one \"Frame\" of audio matches one \"Frame\" of video, your script can process them together without having to do complex math to align the timing.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_audio_io/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>In Wiretap, Audio is treated like Video. You ask for a \"Frame\" of audio just like you would for a picture. The API handles the grouping of tiny samples into efficient blocks so your network stays fast and your sound stays in sync.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/","title":"Insight: Version Compatibility","text":"<p>This document explains how different versions of Flame and the Wiretap API work together without breaking your studio's pipeline.</p> <p>Target Audience: Novice developers concerned about software updates.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/#1-do-i-need-to-re-write-my-code","title":"1. Do I need to re-write my code?","text":"<p>The best thing about the Wiretap API is that it is Backward-Compatible.  - If you write a tool for Flame 2025, it will still work perfectly with Flame 2026. - You only need to update your script if you want to use a New Feature that was just added.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/#2-server-vs-client-versions","title":"2. Server vs. Client Versions","text":"<p>When your script (The Client) connects to a Flame workstation (The Server), they perform a \"Handshake\":</p> <ul> <li>Backburner: Always uses the newest version available on the machine.</li> <li>IFFFS / Gateway: They try to Match the version of your script. If your script says \"I am Version 2025,\" the server will try to act like a 2025 server to make sure your code understands the response.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/#3-forcing-a-version","title":"3. Forcing a Version","text":"<p>If you are working on a very old project, you can tell your script to \"Pretend\" to be an older version of Flame using this command: <code>WireTapClientSetVersion(year, minor, patch)</code></p>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>It allows you to build Long-Term Tools. You can write a single pipeline script that manages projects from five years ago and projects starting today, and Wiretap handles the translation between versions automatically.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_compatibility/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Don't be afraid of Flame updates! Your Wiretap scripts are built on a very stable foundation. As long as you aren't using \"Experimental\" features, your code will continue to work year after year as the software evolves.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/","title":"Insight: Wiretap Self-Discovery","text":"<p>This document explains how Wiretap finds other machines on your network automatically, almost like a \"Bluetooth pairing\" for video servers.</p> <p>Target Audience: Novice technical artists interested in network configuration.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#1-how-does-it-find-a-machine","title":"1. How does it find a machine?","text":"<p>When you run a Wiretap command, you need to tell it which machine to talk to. You have three ways to do this:</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#a-the-direct-way-ip-address","title":"A. The \"Direct\" Way (IP Address)","text":"<ul> <li>Format: <code>192.168.1.50:5555</code></li> <li>Pros: The fastest and most reliable. Bypasses all searching.</li> <li>Cons: Not flexible (if the machine's IP changes, your script breaks).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#b-the-name-way-dns","title":"B. The \"Name\" Way (DNS)","text":"<ul> <li>Format: <code>FlameWorkstation01:5555</code></li> <li>Pros: Easier for humans to read.</li> <li>Cons: Can be slow if your network's \"Name Server\" (DNS) is acting up.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#c-the-auto-way-multicast-discovery","title":"C. The \"Auto\" Way (Multicast Discovery)","text":"<ul> <li>Format: <code>IFFFS</code> or <code>Gateway</code> or <code>Backburner</code></li> <li>Pros: Extremely flexible. You don't need to know the IP or port. </li> <li>How it works: Your script shouts: \"Is there an IFFFS server here?\" and the first workstation to respond sends back its full details.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#2-when-auto-discovery-fails","title":"2. When Auto-Discovery Fails","text":"<p>In complex setups (like cloud servers or different office floors), the \"shouting\" might not reach every machine.  - The Fix: You can \"hardcode\" the network map in a file called <code>services.cfg</code>. This acts like a phone book that tells Wiretap exactly where everyone lives without having to shout for them.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_discovery/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>Self-discovery is great for small offices, but for professional studio pipelines, using a specific IP Address or a Services Config file is much safer. It ensures your scripts always connect to the right machine instantly every time.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/","title":"Insight: Wiretap Error Handling &amp; Threading","text":"<p>This document explains how to handle failures and how to use multiple threads safely when writing Wiretap scripts.</p> <p>Target Audience: Novice programmers interested in robust code and performance.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/#1-handling-errors-the-lasterror-pattern","title":"1. Handling Errors (The <code>lastError</code> pattern)","text":"<p>In Wiretap, functions don't usually \"Throw Errors\" that crash your script. Instead, they return a simple True (Success) or False (Failure).</p> <p>If a function returns <code>False</code>, you must immediately ask for the \"Librarian's Note\" to see what went wrong: - Command: <code>handle.lastError()</code> - Rule: Read the error message immediately. The next time you call any function, the old error message is erased!</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/#2-is-it-thread-safe","title":"2. Is it Thread-Safe?","text":"<p>Thread-safety means \"Can two parts of my script talk to the same object at the same time?\"  - The Answer: Mostly No. - The Rule: Each thread in your script should have its own \"Remote Control\" (Handle). You should never share a single <code>WireTapNodeHandle</code> between two threads, or they will get confused and crash.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/#3-improving-performance","title":"3. Improving Performance","text":"<p>If you want to move media faster, you might think \"I'll use 10 threads!\"  - The Reality: This usually doesn't help. Because all threads are trying to squeeze through the same network \"Pipe,\" they just end up waiting for each other. - The Best Way: Process frames one after another (Sequentially). The Wiretap server is smart\u2014it \"Reads Ahead\" and prepares the next frame for you before you even ask for it.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/#4-why-did-my-script-crash-on-exit","title":"4. Why did my script crash on exit?","text":"<p>Wiretap uses background threads to keep the connection alive.  - The Fix: You must always call <code>WireTapClientUninit()</code> before your script finishes. This tells Wiretap to \"Park the car and turn off the engine\" safely.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_error_handling/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Wiretap is a \"Polite\" API. It won't crash your script if something goes wrong; it will just say \"False.\" It's your job as the programmer to check that value and read the <code>lastError()</code> message to explain the problem to the user.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_faq_troubleshooting/","title":"Insight: FAQs and Troubleshooting","text":"<p>This document provides a summary of the most common questions and hurdles people face when starting with the Wiretap SDK.</p> <p>Target Audience: Novice developers looking for quick solutions to common problems.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_faq_troubleshooting/#1-where-do-i-start","title":"1. Where do I start?","text":"<p>If you are stuck, the first thing to check is the General API issues. This covers things like how Wiretap handles errors and how to use threads safely.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_faq_troubleshooting/#2-common-troubleshooting-areas","title":"2. Common Troubleshooting Areas","text":"<p>The documentation is split into several \"Problem Zones\":</p> <ul> <li>IFFFS Issues: Problems with Flame's internal database (like unlinked clips).</li> <li>Network Issues: Why can't I see all the servers on my network? (Check your router's \"Multicast\" settings!).</li> <li>Media Issues: Problems reading or writing specific video or audio formats.</li> <li>Mac Issues: Specific hurdles for macOS users, like library paths.</li> <li>Permissions: Why is the \"Root\" user blocked from accessing media over the network?</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_faq_troubleshooting/#3-key-pro-tip-multicast-ping","title":"3. Key Pro-Tip: Multicast Ping","text":"<p>If your script can't find any servers, try this command in your terminal: <code>ping 224.0.0.1</code> - If every machine on your network responds, your network is healthy. - If no one responds, your router is blocking Wiretap's \"Auto-Discovery\" messages.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_faq_troubleshooting/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>Troubleshooting is a process of Elimination.  1.  Check the network first (Ping). 2.  Check the server next (Is it running?). 3.  Check your script last (Are you handling the <code>lastError</code> correctly?). Most problems are solved by simply following these three steps in order.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/","title":"Insight: Media and Metadata Formats","text":"<p>This document provides an overview of the different \"Languages\" Wiretap speaks when it moves images, sounds, and data across your network.</p> <p>Target Audience: Novice programmers interested in technical specifications and data types.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/#1-moving-raw-media","title":"1. Moving Raw Media","text":"<p>Wiretap is designed for high performance. When it sends video or audio to your script, it usually converts it into a \"Raw\" format that is easy for a computer to understand:</p> <ul> <li>Raw Video (RGB): Images are sent as a simple buffer of Red, Green, and Blue pixels. There are no complex headers or compression\u2014just pure color data.</li> <li>Raw Audio (DL): Sound is sent in blocks of samples (similar to a WAVE file but simplified for the network).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/#2-moving-metadata-info","title":"2. Moving Metadata (Info)","text":"<p>Metadata is the \"Instructions\" for the media. Wiretap uses two main formats for this:</p> <ul> <li>XML (The Modern Way): Projects, Managers, and Servers use XML to store settings. It's easy for humans to read and for computers to search.</li> <li>EDL (The Editorial Way): Timelines use an augmented version of the CMX 3600 EDL format to store edit instructions and transitions.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/#3-specialized-formats","title":"3. Specialized Formats","text":"<ul> <li>Clip Format: A specialized metadata stream that describes the technical DNA of a clip (Resolution, Bit Depth, etc.).</li> <li>Source Data: The original \"Receipt\" for an imported file, stored in MIO XML format.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>By understanding these formats, you can decide how to best \"Listen\" to the Wiretap network.  - If you want to build a Dashboard, you listen to the XML streams. - If you want to build an Auto-Editor, you listen to the EDL streams. - If you want to build a Transcoder, you listen to the Raw RGB streams.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_media_formats/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Wiretap is a Translator. It takes the complex, proprietary databases inside Flame and translates them into standard formats like XML, EDL, and Raw RGB so your own scripts can easily understand them.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_os_support/","title":"Insight: Supported OS and Platforms","text":"<p>This document explains which computers can run the Wiretap SDK.</p> <p>Target Audience: Novice developers planning their studio infrastructure.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_os_support/#1-professional-foundations","title":"1. Professional Foundations","text":"<p>Wiretap is designed for high-end film and TV workstations. Because of this, it is only built for the two most common professional operating systems:</p> <ul> <li>Linux (x86-64): The industry standard for large render farms and high-end workstations.</li> <li>macOS (Intel &amp; Apple Silicon): The standard for creative editing and design. Wiretap supports both the older Intel chips and the new M1/M2/M3 (arm64) chips.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_os_support/#2-why-no-windows","title":"2. Why no Windows?","text":"<p>Autodesk Flame's main core runs on Linux and macOS. Since the Wiretap SDK is used to \"Reach Inside\" Flame, it stays on the same platforms to ensure the best possible performance and security.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_os_support/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>You can write your Wiretap tools on a Mac and they will work perfectly when talking to a Linux server. This \"Cross-Platform\" support allows you to build a studio where different types of computers can all work together on the same projects.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/","title":"Insight: Users, Groups, and Permissions","text":"<p>This document explains how Wiretap decides if your script is \"Allowed\" to touch a file or project.</p> <p>Target Audience: Novice system administrators and security-conscious programmers.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/#1-the-id-rule-posix","title":"1. The ID Rule (POSIX)","text":"<p>Wiretap works across a network of computers. To keep permissions simple, it assumes that every computer in the studio uses the same User IDs. - If your ID is <code>501</code> on your laptop, the server expects you to be ID <code>501</code> there too. - As long as these IDs match, the server will \"Honor\" your credentials and let you edit your projects.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/#2-fallback-the-anonymous-user","title":"2. Fallback: The \"Anonymous\" User","text":"<p>If your script connects from a computer that the server doesn't recognize, it won't just block you. It will treat you as an Anonymous User. - IFFFS Server: Falls back to a user named <code>IFFFS_user</code>. - Gateway Server: Falls back to a user named <code>wtguser</code>. - Note: These anonymous users usually have very limited power (e.g., they can see files but not delete them).</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/#3-the-root-restriction","title":"3. The \"Root\" Restriction","text":"<p>By default, the \"Superuser\" (Root) is Blocked from accessing Wiretap over the network. - Why? This is a safety feature to prevent someone from accidentally deleting every project in the studio with one command.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/#4-why-is-this-useful","title":"4. Why is this useful?","text":"<p>This system allows you to build a secure pipeline where artists can only see and edit their own work, while managers can see everything\u2014just like in a normal computer file system.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_permissions/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>Wiretap permissions are based on Identity. If your script can't access a project, it's usually because the server doesn't recognize your User ID. Always check the <code>[Authentication]</code> section of the server's config file if you are having permission issues.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/","title":"Insight: Roles of the Wiretap Server and Client","text":"<p>This document explains how the \"Brain\" (Client) and the \"Library\" (Server) work together in the Wiretap system.</p> <p>Target Audience: Novice programmers interested in software architecture.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/#1-the-division-of-labor","title":"1. The Division of Labor","text":"<p>Wiretap uses a \"Client-Server\" model. This means the work is split into two distinct roles to keep everything running fast.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/#a-the-wiretap-server-the-librarian","title":"A. The Wiretap Server (The Librarian)","text":"<p>The server's only job is to expose data. It sits on the machine where the media is stored and waits for questions. - It doesn't do heavy work like rendering or converting files. - It provides a \"Uniform View\" of the data so the client doesn't need to know if it's talking to a database or a hard drive. - Goal: Stay responsive and lightweight.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/#b-the-wiretap-client-the-artistresearcher","title":"B. The Wiretap Client (The Artist/Researcher)","text":"<p>The client is the program you write (like a Python script). It does the heavy lifting. - If a file needs to be converted from one format to another, the client does it. - If a frame needs to be rendered, the client does it. - Goal: Process the data without slowing down the server.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/#2-why-this-matters","title":"2. Why this matters","text":"<p>By making the Client do all the work, Autodesk ensures that the Flame Workstation (the server) never slows down just because a background script is asking for information. The artist stays happy, and the pipeline stays fast.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_roles/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>In Wiretap, the Server is the \"Source of Truth\" and the Client is the \"Engine of Action.\" When you write a script, remember that you are the Client\u2014you are responsible for downloading the data and doing something useful with it!</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_components/","title":"Insight: Components of the SDK","text":"<p>This document explains what you get inside the Wiretap SDK package and where to find the tools you need to start programming.</p> <p>Target Audience: Novice developers interested in software installation and file structure.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_components/#1-whats-in-the-box","title":"1. What's in the Box?","text":"<p>The SDK is organized into five main folders:</p> <ul> <li><code>api/</code>: The \"Instruction Manual\" for the compiler. It contains the C++ header files (<code>.h</code>) that your code needs to \"include.\"</li> <li><code>doc/</code>: The technical reference guide (HTML). This is where you look up specific function names and parameters.</li> <li><code>lib/</code>: The \"Engines.\" These are the actual libraries (<code>.a</code> or <code>.so</code>) that do the work of connecting to the servers.</li> <li><code>samples/</code>: The \"Cheat Sheets.\" This folder contains example programs written by Autodesk engineers. </li> <li><code>tools/</code>: The \"Power Tools.\" These are pre-made command-line programs like <code>wiretap_ping</code> or <code>wiretap_get_metadata</code> that you can use for testing.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_components/#2-a-warning-about-tools","title":"2. A Warning about Tools","text":"<p>Autodesk includes the <code>tools/</code> folder for testing and troubleshooting.  - The Rule: Don't build your studio's mission-critical automation around these tools!  - Why? Autodesk might change how the tools work in the future. If you want to build something permanent, you should write your own script using the Python or C++ API directly.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_components/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>The SDK folder is your \"Laboratory.\" Start by looking at the <code>samples/</code> to see how professionals write Wiretap code, and use the <code>tools/</code> to double-check that your network is working before you start writing your own complex scripts.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/","title":"Insight: Wiretap SDK Overview","text":"<p>This document provides a birds-eye view of the Wiretap SDK. It is the master framework for automating Autodesk Flame.</p> <p>Target Audience: Novice programmers and studio technical directors.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/#1-what-is-the-sdk-for","title":"1. What is the SDK for?","text":"<p>The Wiretap SDK allows you to write your own standalone programs that can reach inside Flame's database from the outside. </p> <p>Normally, you have to open Flame to change a project or render a clip. With the SDK, you can do all of that from a simple script, even if Flame isn't running on your machine!</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/#2-the-three-flavors-of-servers","title":"2. The Three Flavors of Servers","text":"<p>The SDK allows you to talk to three specialized servers:</p> <ol> <li>IFFFS Server: Handles projects and clips. Use this to automatically create new jobs or organize footage into libraries.</li> <li>Gateway Server: Handles \"Ingest.\" Use this to stream raw video from hard drives (like R3D or ProRes files) directly into your pipeline.</li> <li>Backburner Server: Handles \"Rendering.\" Use this to submit and monitor background render jobs on the farm.</li> </ol>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/#3-platform-support","title":"3. Platform Support","text":"<p>Wiretap is Cross-Platform. You can write a script on a Linux machine that reaches across the network to modify a project on a macOS Flame workstation.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/#4-why-use-the-sdk","title":"4. Why use the SDK?","text":"<ul> <li>Workflow Automation: Eliminate repetitive tasks like creating folders and naming projects.</li> <li>Custom Monitoring: Build your own custom dashboards to see which projects are taking up the most disk space.</li> <li>Pipeline Integration: Bridge Flame with other studio software (like ShotGrid or a custom web portal).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_sdk_overview/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>The Wiretap SDK is the \"Master Key\" to the Autodesk Flame ecosystem. It gives you the power to manage your media and renders using code, transforming Flame from a creative tool into a fully automated production engine.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/","title":"Insight: Wiretap Terminology","text":"<p>This document explains the basic words and concepts you need to know to work with the Wiretap SDK.</p> <p>Target Audience: Novice programmers learning the \"Language\" of Flame networking.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/#1-servers-and-clients","title":"1. Servers and Clients","text":"<ul> <li>Wiretap Server: A program running on a machine that \"exposes\" a database to the network. It's like a librarian who knows where all the books are.</li> <li>IFFFS: Exposes Flame's clip library.</li> <li>Gateway: Exposes regular files on your hard drive.</li> <li>Backburner: Exposes render jobs and status.</li> <li>Wiretap Client: A program (like your Python script) that asks the server for information. It's like the person asking the librarian for a book.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/#2-nodes-and-node-ids","title":"2. Nodes and Node IDs","text":"<ul> <li>Node: A single \"Item\" in the Wiretap tree. A project is a node, a library is a node, and a clip is a node.</li> <li>Node ID: A unique string of text that identifies exactly which node you are talking about (e.g., <code>clip:123456</code>).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/#3-frames-and-formats","title":"3. Frames and Formats","text":"<ul> <li>Frame: A single image or a small piece of audio. When you ask Wiretap for a frame, it gives you a \"Buffer\" (a chunk of raw data).</li> <li>Frame Format: The \"Translation Guide\" for the data. It tells the computer if the frame is an <code>RGB</code> image, a <code>YUV</code> image, or an <code>AIFF</code> audio clip.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/#4-metadata","title":"4. Metadata","text":"<p>Metadata is \"Data about Data.\" In Wiretap, it is usually a text file (XML or EDL) that describes a clip. It tells you things like the timecode, the name of the clip, and what effects are applied to it.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_terminology/#5-key-takeaway-for-beginners","title":"5. Key Takeaway for Beginners","text":"<p>To use Wiretap, you just need to know the Node ID of what you want and the Server where it lives. Once you have those two things, you can ask for the Metadata (to see what it is) or the Frames (to see the actual video).</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/","title":"Insight: Reading and Writing Video Media","text":"<p>This document explains the two ways you can pull images (frames) out of Flame using the Wiretap API.</p> <p>Target Audience: Novice programmers interested in image processing and performance.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/#1-two-ways-to-get-frames","title":"1. Two Ways to Get Frames","text":"<p>When you want to look at a frame of video from a server, you have two choices:</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/#option-a-read-through-the-server-the-easy-way","title":"Option A: Read through the Server (The \"Easy\" Way)","text":"<p>You ask the Wiretap Server to give you the frame. - How it works: The server reads the file from the hard drive, converts it into raw RGB pixels, and sends it to your script. - Pros: Very simple. Your script doesn't need to know if the file is a DPX, JPEG, or ProRes. The server does all the \"Translation\" for you. - Cons: It puts a heavy load on the server's CPU.</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/#option-b-read-from-storage-the-fast-way","title":"Option B: Read from Storage (The \"Fast\" Way)","text":"<p>You ask the server for the \"Address\" of the file, then your script reads the file directly from the hard drive. - How it works: Wiretap gives you a path like <code>/Volumes/Media/shot.001.dpx</code>. Your script opens that file. - Pros: Much faster! It doesn't use the server's CPU, and there's no extra \"Network Hop.\" - Cons: More complex. Your script must know how to \"Speak the Language\" of the file (e.g., you need a library to read DPX or EXR files).</p>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/#2-choosing-the-right-handle","title":"2. Choosing the Right Handle","text":"<ul> <li><code>WireTapNodeHandle</code>: Use this if you have a Clip ID and an index (e.g., \"Give me Frame 10 of Clip A\"). This is the standard way.</li> <li><code>WireTapServerHandle</code>: Use this only if you have a \"Frame ID\" but don't know which clip it belongs to. This is rare and mostly for advanced timeline tools.</li> </ul>"},{"location":"insight/wiretap_sdk/insight-wiretap_video_io/#3-key-takeaway-for-beginners","title":"3. Key Takeaway for Beginners","text":"<p>Start with Option A (Reading through the server). It's the most \"Programmer-Friendly\" because you get raw pixels that are ready to use. Only switch to Option B if you are moving millions of frames and need to save time and server power.</p>"},{"location":"insight/wiretap_sdk/insight-workflow_samples/","title":"Insight: Workflow, Samples and Tools","text":"<p>This document acts as a \"Master Map\" to help you find the right example code for common studio tasks.</p> <p>Target Audience: Novice developers looking for a \"Quick Start\" guide.</p>"},{"location":"insight/wiretap_sdk/insight-workflow_samples/#1-finding-the-right-sample","title":"1. Finding the Right Sample","text":"<p>If you have a task in mind, look at this list to see which file in the <code>samples/</code> folder you should study first:</p> <ul> <li>\"List every machine in the building\": Study <code>listAllServers.py</code>.</li> <li>\"Explore a project tree\": Study <code>listChildren.py</code>.</li> <li>\"Rename or Copy a clip\": Study <code>duplicateNode.py</code>.</li> <li>\"Send a job to the render farm\": Study <code>submitJob.C</code> (or the Python equivalent).</li> </ul>"},{"location":"insight/wiretap_sdk/insight-workflow_samples/#2-comparing-with-command-line-tools","title":"2. Comparing with Command Line Tools","text":"<p>If you aren't sure if your script is working correctly, you can compare its results with the professional tools Autodesk included in the SDK:</p> Your Task The Python Sample The \"Official\" Tool Scanning Network <code>listAllServers.py</code> <code>wiretap_server_dump</code> Browsing Nodes <code>listChildren.py</code> <code>wiretap_get_children</code> Reading Metadata <code>dir(wiretap)</code> <code>wiretap_get_metadata</code>"},{"location":"insight/wiretap_sdk/insight-workflow_samples/#3-why-is-this-useful","title":"3. Why is this useful?","text":"<p>This map saves you from \"Re-inventing the wheel.\"  - Step 1: Run the \"Official\" tool to see what the data should look like. - Step 2: Open the matching Python sample to see how the code was written. - Step 3: Copy that code and change it to fit your studio's needs.</p>"},{"location":"insight/wiretap_sdk/insight-workflow_samples/#4-key-takeaway-for-beginners","title":"4. Key Takeaway for Beginners","text":"<p>The samples and tools are \"Interactive Documentation.\" Instead of just reading about how to do something, you can run the sample and see it happen in real-time. This is the fastest way to master the Wiretap SDK!</p>"},{"location":"research/understanding-AI_acronyms/","title":"Understanding AI: A Guide to Modern Acronyms","text":"<p>This guide is designed for developers who are new to the AI space. It breaks down the \"alphabet soup\" of AI into logical categories, using simple analogies and code examples.</p>"},{"location":"research/understanding-AI_acronyms/#1-core-architectures-the-frameworks","title":"1. Core Architectures (The Frameworks)","text":""},{"location":"research/understanding-AI_acronyms/#mcp-model-context-protocol","title":"MCP (Model Context Protocol)","text":"<ul> <li>Analogy: \"USB for AI.\"</li> <li>What it is: A standard way for AI models to connect to your local tools and data without writing custom code for every single app.</li> <li>Novice Perspective: Imagine if every mouse needed a different plug for every computer. That was AI before MCP. MCP makes the \"plugs\" universal.</li> <li> <p>Code Pattern:     ```python     # Using FastMCP to define a tool the AI can \"plug into\"     mcp = FastMCP(\"MyToolServer\")</p> <p>@mcp.tool() def get_weather(city: str) -&gt; str:     return f\"The weather in {city} is sunny.\" ```</p> </li> </ul>"},{"location":"research/understanding-AI_acronyms/#rag-retrieval-augmented-generation","title":"RAG (Retrieval-Augmented Generation)","text":"<ul> <li>Analogy: \"The Open-Book Exam.\"</li> <li>What it is: Giving an AI a specific set of documents to look at before it answers a question.</li> <li>Novice Perspective: Standard AI (like ChatGPT) answers from memory. RAG lets the AI look at your specific files (like this codebase) to give accurate, non-hallucinated answers.</li> <li>Code Pattern: <code>python     # A simplified RAG retrieval call     response = rag.retrieval_query(         text=\"How do I use the Flame API?\",         rag_resources=[\"projects/my-project/corpora/flame-docs\"]     )</code></li> </ul>"},{"location":"research/understanding-AI_acronyms/#agent","title":"Agent","text":"<ul> <li>Analogy: \"An Employee, not just a Consultant.\"</li> <li>What it is: An AI that doesn't just talk, but does things. It can use tools, run scripts, and correct its own mistakes.</li> <li>Novice Perspective: A chatbot tells you how to fix a bug; an Agent actually writes the fix, runs the test, and tries again if the test fails.</li> </ul>"},{"location":"research/understanding-AI_acronyms/#2-model-types-the-brains","title":"2. Model Types (The Brains)","text":"<ul> <li>LLM (Large Language Model): The big engine (e.g., GPT-4, Gemini) trained on the whole internet.</li> <li>SLM (Small Language Model): A \"mini\" version designed to run on your phone or local laptop. Faster and cheaper, but less \"worldly.\"</li> <li>MoE (Mixture of Experts): A model made of several \"specialists.\" When you ask a math question, it only wakes up the \"math specialist\" part of the brain to save energy and time.</li> <li>VLM (Vision Language Model): An AI that can \"see.\" You can show it a screenshot of a bug, and it can explain what's wrong.</li> </ul>"},{"location":"research/understanding-AI_acronyms/#3-reasoning-patterns-the-thinking","title":"3. Reasoning Patterns (The Thinking)","text":"<ul> <li>CoT (Chain of Thought): \"Show your work.\" Asking the AI to explain its logic step-by-step. This drastically improves accuracy for complex math or coding.</li> <li>ReAct (Reason + Act): The loop Agents use. <ol> <li>Reason: \"I need to find the file.\" </li> <li>Act: Run <code>ls</code> command. </li> <li>Observe: \"I see the file.\" </li> <li>Repeat.</li> </ol> </li> </ul>"},{"location":"research/understanding-AI_acronyms/#4-modalities-the-senses","title":"4. Modalities (The Senses)","text":"<ul> <li>TTS (Text-to-Speech): AI turning text into a human-sounding voice.</li> <li>STT (Speech-to-Text): AI \"listening\" to you and typing it out (Transcription).</li> <li>OCR (Optical Character Recognition): Reading text from an image or a PDF.</li> </ul>"},{"location":"research/understanding-AI_acronyms/#5-training-adaptation-the-learning","title":"5. Training &amp; Adaptation (The Learning)","text":"<ul> <li>RLHF (Reinforcement Learning from Human Feedback): Humans ranking AI answers to teach it \"manners\" and helpfulness.</li> <li>LoRA (Low-Rank Adaptation): \"The Quick-Study Method.\" A way to teach a model a very specific skill (like \"Write Autodesk Flame scripts\") without needing to retrain the whole giant model.</li> </ul>"},{"location":"research/understanding-AI_acronyms/#6-deployment-concepts-the-safety","title":"6. Deployment Concepts (The Safety)","text":"<ul> <li>HITL (Human-in-the-Loop): A system where the AI does the work, but a human must click \"Approve\" before anything actually happens (common in this CLI!).</li> <li>Evals (Evaluations): Automated tests to see how \"smart\" the AI is at a specific task. If you change your code, you run Evals to make sure the AI didn't get dumber.</li> </ul>"},{"location":"research/understanding-AI_core_architectures/","title":"Understanding AI Core Architectures","text":"<p>In the world of AI, \"Architecture\" refers to how different systems are connected to solve complex problems. For a programmer, this is the high-level design pattern of an AI application.</p>"},{"location":"research/understanding-AI_core_architectures/#1-mcp-model-context-protocol","title":"1. MCP (Model Context Protocol)","text":"<p>The Universal Connector</p> <ul> <li>The Problem: Every time a developer wanted an AI (like Claude or Gemini) to use a tool (like Google Search or a Local Database), they had to write unique, fragile code for that specific combination.</li> <li>The Solution: MCP is a standardized \"handshake.\" If you build an MCP server for your data, any MCP-compliant AI can immediately understand how to read and use it.</li> <li>Analogy: The USB Port. Before USB, printers, keyboards, and mice all had different, weird plugs. USB standardized the connection so everything \"just works.\"</li> <li>Simple Code (Conceptual): <code>python     # Defining an MCP tool that the AI can call     @mcp.tool()     def search_local_logs(query: str):         \"\"\"Searches through project logs for a specific error.\"\"\"         # The AI will decide when to call this based on the user's request         return run_grep_command(query)</code></li> </ul>"},{"location":"research/understanding-AI_core_architectures/#2-rag-retrieval-augmented-generation","title":"2. RAG (Retrieval-Augmented Generation)","text":"<p>The Open-Book Exam</p> <ul> <li>What it is: Instead of relying on the AI's training (which might be old), we \"hand\" the AI specific documents relevant to the user's question right before it answers.</li> <li>Analogy: A Librarian. If you ask a librarian a question, they don't just guess from memory; they go to the shelf, find the right book, read the relevant page, and then summarize the answer for you.</li> <li>Why use it? It prevents \"hallucinations\" (making things up) and allows the AI to talk about private data it was never trained on.</li> <li> <p>Simple Code (Conceptual):     ```python     # 1. Get the user's question     question = \"How do I setup the Flame Listener?\"</p> </li> </ul>"},{"location":"research/understanding-AI_core_architectures/#2-retrieve-relevant-snippets-from-our-docs","title":"2. 'Retrieve' relevant snippets from our docs","text":"<p>context = search_my_docs_folder(question)</p>"},{"location":"research/understanding-AI_core_architectures/#3-augment-the-prompt","title":"3. 'Augment' the prompt","text":"<p>final_prompt = f\"Using these notes: {context}, answer this: {question}\"</p>"},{"location":"research/understanding-AI_core_architectures/#4-generate-the-answer","title":"4. 'Generate' the answer","text":"<p>ai_response = model.generate(final_prompt) ```</p>"},{"location":"research/understanding-AI_core_architectures/#3-agents","title":"3. Agents","text":"<p>The Autonomous Employee</p> <ul> <li>What it is: An AI system that can break a big goal into small steps, execute those steps using tools, and fix its own mistakes.</li> <li>Analogy: A Junior Developer. If you tell a chatbot \"Fix this bug,\" it might explain how. If you tell an Agent \"Fix this bug,\" it will:<ol> <li>Read the code.</li> <li>Identify the error.</li> <li>Write a fix.</li> <li>Run the test.</li> <li>If the test fails, try a different fix.</li> </ol> </li> <li>The ReAct Loop: Agents follow a pattern called Reason + Act.<ul> <li>Reason: \"I see the test failed because of a SyntaxError.\"</li> <li>Act: \"I will edit line 42 to add the missing colon.\"</li> <li>Observe: \"The test now passes.\"</li> </ul> </li> </ul>"},{"location":"research/understanding-AI_deployment_concepts/","title":"Understanding AI Deployment Concepts","text":"<p>Once an AI is built and trained, how do we actually \"use\" it in the real world? These concepts cover the bridge between the AI model and the user.</p>"},{"location":"research/understanding-AI_deployment_concepts/#1-inference","title":"1. Inference","text":"<p>The AI in Action</p> <ul> <li>What it is: The process of the AI actually running and generating an answer. When you ask a question and wait for the response, you are waiting for \"Inference.\"</li> <li>Analogy: The Performance. Training is like the months of rehearsal; Inference is the actual night of the play when the actors are on stage performing.</li> </ul>"},{"location":"research/understanding-AI_deployment_concepts/#2-hitl-human-in-the-loop","title":"2. HITL (Human-in-the-Loop)","text":"<p>The Safety Switch</p> <ul> <li>What it is: A workflow where the AI does most of the work, but a human must review or approve the result before it's finalized.</li> <li>Why it matters: In high-stakes environments (like editing a multi-million dollar commercial in Flame), we don't want the AI making permanent changes without a human saying \"Yes, that looks right.\"</li> </ul>"},{"location":"research/understanding-AI_deployment_concepts/#3-evals-evaluations","title":"3. Evals (Evaluations)","text":"<p>The AI Report Card</p> <ul> <li>What it is: A set of automated tests used to measure how good an AI is at a specific task.</li> <li>Example: If we update our Flame helper, we run an \"Eval\" that asks the AI 100 questions about the Flame API. If it gets 95 right, we know it's ready. If it only gets 60 right, we know we broke something.</li> </ul>"},{"location":"research/understanding-AI_deployment_concepts/#4-tokens-context-window","title":"4. Tokens &amp; Context Window","text":"<p>Memory Limits</p> <ul> <li>Tokens: Think of these as \"syllables\" for AI. A model doesn't see words; it sees tokens.</li> <li>Context Window: The \"short-term memory\" of the AI. It's the maximum number of tokens the AI can \"keep in its head\" at one time. If your conversation or file is too long, the AI will start to \"forget\" the beginning.</li> </ul>"},{"location":"research/understanding-AI_deployment_concepts/#5-guardrails","title":"5. Guardrails","text":"<p>The Safety Rails</p> <ul> <li>What it is: Software that sits around the AI to make sure it doesn't say anything dangerous, leaked secrets, or hallucinate.</li> <li>Analogy: A Bouncer. The AI might want to answer a question it shouldn't, but the Guardrail blocks the response before the user ever sees it.</li> </ul>"},{"location":"research/understanding-AI_modalities/","title":"Understanding AI Modalities","text":"<p>\"Modality\" refers to the type of data the AI can understand or create. Early AI was mostly \"Single-Modal\" (just text). Modern AI is \"Multi-Modal.\"</p>"},{"location":"research/understanding-AI_modalities/#1-text-the-foundation","title":"1. Text (The Foundation)","text":"<p>The most common modality. AI \"sees\" text as Tokens (chunks of characters) rather than whole words.</p>"},{"location":"research/understanding-AI_modalities/#2-vision-image-video","title":"2. Vision (Image &amp; Video)","text":"<ul> <li>Image Understanding: Identifying objects, reading text in photos (OCR), or describing the \"vibe\" of a picture.</li> <li>Video Understanding: Seeing how things change over time. This is critical for tools interacting with the Autodesk Flame UI.</li> </ul>"},{"location":"research/understanding-AI_modalities/#3-audio-sound-speech","title":"3. Audio (Sound &amp; Speech)","text":"<ul> <li>STT (Speech-to-Text): Also known as Transcription. Turning a spoken meeting into a text summary.</li> <li>TTS (Text-to-Speech): Turning a script into a natural-sounding voice.</li> <li>Audio-to-Audio: Some new models can \"listen\" to a voice and respond with a voice without turning it into text in the middle, preserving the emotion and tone.</li> </ul>"},{"location":"research/understanding-AI_modalities/#4-multimodal-interplay","title":"4. Multimodal Interplay","text":"<p>The Real Power</p> <p>The most advanced AIs can \"connect\" these senses.  *   Example: You can show an AI a video of a software crash and say out loud, \"Why did that happen?\" The AI processes the video (Vision) and your voice (Audio) together to give you a text answer.</p>"},{"location":"research/understanding-AI_modalities/#5-ocr-optical-character-recognition","title":"5. OCR (Optical Character Recognition)","text":"<p>Reading the Unreadable</p> <ul> <li>What it is: The specific skill of looking at an image (like a scan of a receipt or a screenshot of a menu) and pulling out the text characters.</li> <li>In this Repo: We might use OCR to \"read\" values from the Flame UI that aren't available through the standard API.</li> </ul>"},{"location":"research/understanding-AI_model_types/","title":"Understanding AI Model Types","text":"<p>Not all AI models are created equal. Depending on the task\u2014whether it's writing code, summarizing a book, or identifying a cat in a photo\u2014you might use a different \"flavor\" of model.</p>"},{"location":"research/understanding-AI_model_types/#1-llm-large-language-model","title":"1. LLM (Large Language Model)","text":"<p>The Heavyweight Champion</p> <ul> <li>What it is: The giant models (like GPT-4, Claude 3.5, Gemini Pro) trained on nearly the entire public internet.</li> <li>Best for: Deep reasoning, complex coding, and creative writing.</li> <li>Analogy: The University Professor. They know a lot about almost everything, but they are \"heavy\" (expensive and slower to run).</li> </ul>"},{"location":"research/understanding-AI_model_types/#2-slm-small-language-model","title":"2. SLM (Small Language Model)","text":"<p>The Local Specialist</p> <ul> <li>What it is: Models designed to be small enough to run on your laptop, phone, or even inside a single app (like Llama-3-8B or Phi-3).</li> <li>Best for: Simple tasks, privacy-focused apps, and running without an internet connection.</li> <li>Analogy: The Pocket Dictionary. It doesn't know everything, but it's fast, portable, and gets the basic job done.</li> </ul>"},{"location":"research/understanding-AI_model_types/#3-moe-mixture-of-experts","title":"3. MoE (Mixture of Experts)","text":"<p>The Team of Specialists</p> <ul> <li>What it is: A model that is actually made of many smaller \"experts.\" When you ask a question, the model only \"wakes up\" the 2 or 3 experts that are relevant to your topic.</li> <li>Why it matters: It gives you the intelligence of a giant model with the speed and efficiency of a smaller one.</li> <li>Analogy: A Hospital. You don't need the whole hospital to treat a broken arm; you just need the X-ray tech and the Orthopedist. MoE routing ensures only the right \"doctors\" are called.</li> </ul>"},{"location":"research/understanding-AI_model_types/#4-vlm-vision-language-model","title":"4. VLM (Vision Language Model)","text":"<p>The AI with Eyes</p> <ul> <li>What it is: A model that can process both text and images (or video) at the same time.</li> <li>Best for: Describing screenshots, explaining UI layouts, or \"watching\" a video to find a specific moment.</li> <li>Simple Code (Conceptual): <code>python     # Sending an image to a VLM     response = model.generate(         prompt=\"Look at this Flame UI screenshot. Is the Batch button active?\",         image=\"screenshot_01.png\"     )</code></li> </ul>"},{"location":"research/understanding-AI_reasoning_patterns/","title":"Understanding AI Reasoning Patterns","text":"<p>How an AI \"thinks\" depends on the instructions we give it. Just like a human, an AI is more accurate when it takes its time and follows a logical process.</p>"},{"location":"research/understanding-AI_reasoning_patterns/#1-cot-chain-of-thought","title":"1. CoT (Chain of Thought)","text":"<p>\"Show Your Work\"</p> <ul> <li>What it is: Forcing the AI to write out its step-by-step logic before giving the final answer.</li> <li>Why it matters: LLMs are \"prediction engines.\" If they jump straight to the answer, they often guess wrong. If they walk through the logic, they catch their own errors.</li> <li>Analogy: A Math Student. A student who writes down every step of an equation is much less likely to make a mistake than one who tries to do it all in their head.</li> </ul>"},{"location":"research/understanding-AI_reasoning_patterns/#2-react-reason-act","title":"2. ReAct (Reason + Act)","text":"<p>The Agent's Heartbeat</p> <ul> <li>What it is: A loop where the AI Reasons about its situation, takes an Action (using a tool), and then Observes the result before deciding what to do next.</li> <li>Simple Logic:<ol> <li>Thought: I need to know the current Flame project name.</li> <li>Action: Run <code>print_project_name.py</code>.</li> <li>Observation: The script output \"Commercial_Project_v2\".</li> <li>Final Thought: The project is \"Commercial_Project_v2\".</li> </ol> </li> </ul>"},{"location":"research/understanding-AI_reasoning_patterns/#3-zero-shot-vs-few-shot","title":"3. Zero-Shot vs. Few-Shot","text":"<p>Learning on the Fly</p> <ul> <li>Zero-Shot: Asking the AI to do something without giving it any examples. <ul> <li>Example: \"Translate 'Hello' to French.\"</li> </ul> </li> <li>Few-Shot: Giving the AI 2 or 3 examples of how you want the task done before asking it to perform.<ul> <li>Analogy: Training a New Intern. You don't just say \"Do the filing.\" You show them two folders you've already filed so they understand your specific system.</li> <li>Simple Prompt: <code>text     Input: \"The movie was great!\" -&gt; Sentiment: Positive     Input: \"I hated the food.\" -&gt; Sentiment: Negative     Input: \"The service was okay.\" -&gt; Sentiment:</code></li> </ul> </li> </ul>"},{"location":"research/understanding-AI_reasoning_patterns/#4-multi-hop-reasoning","title":"4. Multi-Hop Reasoning","text":"<p>Connecting the Dots</p> <ul> <li>What it is: Solving a problem that requires finding Answer A, then using Answer A to find Answer B.</li> <li>Example: \"Who is the CEO of the company that made the first movie John Doe starred in?\"<ol> <li>Hop 1: Find John Doe's first movie.</li> <li>Hop 2: Find the company that made it.</li> <li>Hop 3: Find that company's CEO.</li> </ol> </li> </ul>"},{"location":"research/understanding-AI_training_and_adaptation/","title":"Understanding AI Training &amp; Adaptation","text":"<p>How do we take a \"raw\" AI model and make it useful for a specific job, like writing Autodesk Flame Python scripts? </p>"},{"location":"research/understanding-AI_training_and_adaptation/#1-pre-training","title":"1. Pre-training","text":"<p>General Education</p> <ul> <li>What it is: The initial phase where a model reads the entire internet to learn how language, logic, and basic facts work.</li> <li>Analogy: Grade School. Everyone learns the same basics: how to read, write, and do math.</li> </ul>"},{"location":"research/understanding-AI_training_and_adaptation/#2-fine-tuning","title":"2. Fine-Tuning","text":"<p>Specialized Training</p> <ul> <li>What it is: Taking a pre-trained model and giving it a \"deep dive\" into a specific topic (like medical records or Python code).</li> <li>Analogy: Medical School. You take someone who already knows how to read and write and teach them specifically how to be a doctor.</li> </ul>"},{"location":"research/understanding-AI_training_and_adaptation/#3-rlhf-reinforcement-learning-from-human-feedback","title":"3. RLHF (Reinforcement Learning from Human Feedback)","text":"<p>Polishing the Behavior</p> <ul> <li>What it is: Humans sit down with the AI and rank its answers. \"This answer was helpful and safe; that answer was rude and confusing.\"</li> <li>Why it matters: This is what makes AI feel \"human\" and easy to talk to, rather than just a robotic text-completer.</li> </ul>"},{"location":"research/understanding-AI_training_and_adaptation/#4-lora-low-rank-adaptation","title":"4. LoRA (Low-Rank Adaptation)","text":"<p>The \"Quick-Study\" Cheat Code</p> <ul> <li>What it is: Instead of retraining the whole massive model (which costs millions of dollars), we only train a tiny \"adapter\" layer that sits on top.</li> <li>Why it matters: It allows small teams to make highly specialized models (like an \"Autodesk Flame Expert\") very cheaply.</li> <li>Analogy: A Specialized Lens. You don't build a new camera to take a macro photo; you just put a macro lens on the camera you already have.</li> </ul>"},{"location":"research/understanding-AI_training_and_adaptation/#5-quantization","title":"5. Quantization","text":"<p>Shrinking the Brain</p> <ul> <li>What it is: Reducing the precision of the model's numbers so it takes up less memory.</li> <li>The Trade-off: The model becomes slightly less \"smart\" but becomes much faster and can run on cheaper hardware (like your local laptop).</li> </ul>"},{"location":"research/understanding-ComfyUI/","title":"Understanding ComfyUI","text":""},{"location":"research/understanding-ComfyUI/#overview","title":"Overview","text":"<p>ComfyUI is an open-source, node-based graphical user interface (GUI) and backend inference engine designed for Stable Diffusion and other generative AI models. Unlike traditional UIs that provide a linear set of options (like Automatic1111), ComfyUI allows users to build complex, modular workflows using a visual graph-based approach.</p>"},{"location":"research/understanding-ComfyUI/#core-architecture","title":"Core Architecture","text":"<ul> <li>Directed Acyclic Graph (DAG): Workflows are constructed by connecting \"nodes\" (individual functional units) into a graph. This defines the flow of data from model loading to image generation and post-processing.</li> <li>Python-Based: The backend is written in Python, making it highly extensible and compatible with the broader AI research ecosystem.</li> <li>Optimized Inference: <ul> <li>Re-execution: It only re-calculates parts of the graph that have changed, significantly speeding up iterative testing.</li> <li>Smart Memory Management: Highly efficient with VRAM, capable of running large models (like SDXL or Flux) on consumer GPUs with as little as 1GB-4GB of VRAM.</li> </ul> </li> <li>Stateless API: The internal execution logic is separate from the UI, allowing the same workflows to be run programmatically via a JSON-based API.</li> </ul>"},{"location":"research/understanding-ComfyUI/#key-features","title":"Key Features","text":"<ul> <li>Broad Model Support: Supports SD1.x, SD2.x, SDXL, Stable Cascade, SD3/3.5, and the newer Flux models.</li> <li>Multi-Modal: Beyond images, it supports video (Stable Video Diffusion), audio (Stable Audio), and 3D generation.</li> <li>Advanced Control: Native support for LoRAs, ControlNets, IP-Adapters, Hypernetworks, and various upscalers (ESRGAN, SwinIR).</li> <li>Custom Nodes: A vast ecosystem of community-developed nodes (via ComfyUI Manager) adds features like image editing, custom logic, and integration with other tools (e.g., Photoshop, Blender).</li> <li>Workflow Portability: Workflows are saved as JSON files and can be embedded directly into generated images (PNG/WebP), allowing others to \"load\" the exact settings by dragging the image into the UI.</li> </ul>"},{"location":"research/understanding-ComfyUI/#programmatic-interaction-api","title":"Programmatic Interaction (API)","text":"<p>ComfyUI's greatest strength for developers is its API-first design. - Workflow JSON: The UI is essentially a frontend for a JSON configuration. Any workflow built visually can be exported as an \"API Format\" JSON. - WebSocket/HTTP: Developers can interact with ComfyUI via HTTP (to upload images/submit prompts) and WebSockets (to receive real-time execution status and progress updates). - Automation: This makes it ideal for building automated pipelines, discord bots, or integrating generative AI into professional software (like Autodesk Flame).</p>"},{"location":"research/understanding-ComfyUI/#why-comfyui-for-flame-utilities","title":"Why ComfyUI for FLAME-UTILITIES?","text":"<p>Given its modular nature and API-first approach, ComfyUI is the perfect candidate for integrating generative AI into Autodesk Flame. 1. Precise Control: Node-based logic matches the \"Batch\" philosophy of Flame. 2. API Integration: <code>fu_whisper</code> could potentially trigger ComfyUI workflows to generate textures, backgrounds, or clean plates directly from Flame. 3. Efficiency: It can run alongside Flame on the same workstation without consuming all system resources when idle.</p> <p>Research conducted on 2026-02-01.</p>"},{"location":"research/understanding-OTIO-flame-timewarps/","title":"understanding OTIO flame timewarps","text":"<p>You\u2019re speaking my language now\u2014this is exactly where OTIO stops being \u201cjust an EDL\u201d and becomes a carrier for real pipeline semantics.</p> <p>Let\u2019s treat this as three layers:</p> <ol> <li>How to structurally represent Flame-style timewarps in OTIO (with metadata). </li> <li>How to design a schema for retime curves, modes, and options. </li> <li>How to round-trip Flame Timewarp nodes via a custom OTIO adapter.</li> </ol>"},{"location":"research/understanding-OTIO-flame-timewarps/#1-what-otio-gives-you-out-of-the-box","title":"1. What OTIO gives you out of the box","text":"<p>OTIO\u2019s core model is deliberately minimal: it has <code>TimeEffect</code> and <code>LinearTimeWarp</code> for constant retimes, plus a rich metadata system and plugin-based adapters.</p> <p>So for Flame-style timewarps, you lean on:</p> <ul> <li><code>TimeEffect</code> / <code>LinearTimeWarp</code> for simple, constant retimes.</li> <li><code>metadata</code> on the <code>Clip</code> or <code>TimeEffect</code> to carry Flame-specific detail.</li> <li>Adapters to translate between Flame\u2019s internal representation and your OTIO schema.</li> </ul> <p>Think of OTIO as:</p> <ul> <li>\u201cAuthoritative structure\u201d for: clips, tracks, transitions, basic retimes.  </li> <li>\u201cEnvelope\u201d for: Flame\u2019s full timewarp node graph, curves, and options.</li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#2-where-to-hang-flame-timewarp-metadata","title":"2. Where to hang Flame timewarp metadata","text":"<p>You\u2019ve got two good attachment points:</p> <ul> <li>On the <code>Clip</code>: if the timewarp is conceptually part of the clip\u2019s playback.  </li> <li>On a <code>TimeEffect</code> attached to the <code>Clip</code>: if you want a clear semantic \u201cthis is a retime effect\u201d object.</li> </ul> <p>I\u2019d strongly recommend:</p> <ul> <li>Use <code>LinearTimeWarp</code> when the Flame timewarp is effectively constant speed.  </li> <li>Use a generic <code>TimeEffect</code> plus metadata when it\u2019s variable or complex.</li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#example-otio-object-layout","title":"Example: OTIO object layout","text":"<pre><code>import opentimelineio as otio\n\nclip = otio.schema.Clip(\n    name=\"Shot_010\",\n    media_reference=otio.schema.ExternalReference(\n        target_url=\"file:///path/to/shot_010.exr\",\n        available_range=otio.opentime.TimeRange(\n            start_time=otio.opentime.RationalTime(0, 24),\n            duration=otio.opentime.RationalTime(240, 24),\n        ),\n    ),\n)\n\ntimewarp = otio.schema.TimeEffect(\n    name=\"FlameTimewarp\",\n    effect_name=\"FlameTimewarp\",  # free-form string\n)\n\nclip.effects.append(timewarp)\n</code></pre> <p>Now the interesting part is the metadata payload.</p>"},{"location":"research/understanding-OTIO-flame-timewarps/#3-designing-a-flame-timewarp-metadata-schema","title":"3. Designing a Flame timewarp metadata schema","text":"<p>You want something:</p> <ul> <li>Explicit (no guessing what a field means).  </li> <li>Stable (versioned, so you can evolve it).  </li> <li>Serializable (JSON-friendly, no Flame-only binary blobs unless absolutely necessary).</li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#suggested-top-level-structure","title":"Suggested top-level structure","text":"<p>Attach this under a dedicated namespace, e.g. <code>metadata[\"flame\"][\"timewarp\"]</code>:</p> <pre><code>timewarp.metadata[\"flame\"] = {\n    \"timewarp\": {\n        \"schema_version\": 1,\n        \"node_name\": \"Timewarp1\",\n        \"mode\": \"curve\",          # \"constant\", \"curve\", \"freeze\", \"expression\", \"optical_flow\"\n        \"input_fps\": 24.0,\n        \"output_fps\": 24.0,\n        \"reverse\": False,\n        \"segments\": [\n            # optional segmentation of behavior\n        ],\n        \"curve\": {\n            \"time_domain\": \"timeline\",  # \"timeline\" or \"source\"\n            \"keyframes\": [\n                # see below\n            ],\n        },\n        \"freeze\": {\n            \"enabled\": False,\n            \"frame\": 100.0,\n        },\n        \"optical_flow\": {\n            \"enabled\": False,\n            \"quality\": \"high\",\n            \"smoothing\": 0.5,\n        },\n        \"expression\": {\n            \"enabled\": False,\n            \"language\": \"flame_expr\",\n            \"source\": \"t * 0.5\",\n        },\n        \"raw_flame_data\": {\n            # optional: original Flame node dump, if you want full fidelity\n        },\n    }\n}\n</code></pre>"},{"location":"research/understanding-OTIO-flame-timewarps/#keyframe-representation-for-retime-curves","title":"Keyframe representation for retime curves","text":"<p>You need a mapping between timeline time and source time (or vice versa). Flame\u2019s Timewarp is essentially a function:</p> <p>[ t_\\text{source} = f(t_\\text{timeline}) ]</p> <p>Represent that as keyframes:</p> <pre><code>timewarp.metadata[\"flame\"][\"timewarp\"][\"curve\"][\"keyframes\"] = [\n    {\n        \"timeline_time\": 0.0,      # in frames or seconds, but be explicit\n        \"source_time\": 0.0,\n        \"interp\": \"linear\",        # \"linear\", \"bezier\", \"constant\", etc.\n        \"bezier\": {\n            \"in_tangent\":  [0.0, 0.0],\n            \"out_tangent\": [0.0, 0.0],\n        },\n    },\n    {\n        \"timeline_time\": 50.0,\n        \"source_time\": 25.0,\n        \"interp\": \"linear\",\n    },\n    {\n        \"timeline_time\": 100.0,\n        \"source_time\": 100.0,\n        \"interp\": \"linear\",\n    },\n]\n</code></pre> <p>You can choose:</p> <ul> <li>Units: frames at a given FPS, or seconds. Just be consistent and store the FPS.  </li> <li>Direction: timeline\u2192source or source\u2192timeline. I\u2019d pick timeline\u2192source, since that\u2019s how playback works.</li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#4-encoding-specific-flame-behaviors","title":"4. Encoding specific Flame behaviors","text":"<p>Let\u2019s map some common Flame Timewarp patterns into this schema.</p>"},{"location":"research/understanding-OTIO-flame-timewarps/#41-constant-speed-simple-retime","title":"4.1 Constant speed (simple retime)","text":"<p>If Flame\u2019s Timewarp is just 50% speed:</p> <ul> <li>Use <code>LinearTimeWarp</code> for OTIO-native behavior.  </li> <li>Also store the Flame node metadata for round-trip fidelity.</li> </ul> <pre><code>ltw = otio.schema.LinearTimeWarp(\n    name=\"FlameTimewarp_50pct\",\n    time_scalar=0.5,\n    time_offset=0.0,\n)\n\nltw.metadata[\"flame\"] = {\n    \"timewarp\": {\n        \"schema_version\": 1,\n        \"mode\": \"constant\",\n        \"speed\": 0.5,\n        \"input_fps\": 24.0,\n        \"output_fps\": 24.0,\n    }\n}\n\nclip.effects.append(ltw)\n</code></pre> <p>On export back to Flame, your adapter can:</p> <ul> <li>Detect <code>LinearTimeWarp</code>.  </li> <li>Create a Flame Timewarp node with constant speed 0.5.  </li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#42-freeze-frame","title":"4.2 Freeze frame","text":"<p>Flame freeze at frame 100:</p> <pre><code>timewarp.metadata[\"flame\"][\"timewarp\"].update({\n    \"mode\": \"freeze\",\n    \"freeze\": {\n        \"enabled\": True,\n        \"frame\": 100.0,\n    },\n})\n</code></pre> <p>You can also encode this as a curve:</p> <pre><code>\"curve\": {\n    \"time_domain\": \"timeline\",\n    \"keyframes\": [\n        {\"timeline_time\": 0.0, \"source_time\": 100.0, \"interp\": \"constant\"},\n        {\"timeline_time\": 200.0, \"source_time\": 100.0, \"interp\": \"constant\"},\n    ],\n}\n</code></pre>"},{"location":"research/understanding-OTIO-flame-timewarps/#43-variable-speed-ramp","title":"4.3 Variable speed ramp","text":"<p>Say Flame has a ramp:</p> <ul> <li>0\u201350 timeline frames: 50% speed  </li> <li>50\u2013100 timeline frames: ramp to 200% speed  </li> </ul> <p>You can bake this into keyframes:</p> <pre><code>\"curve\": {\n    \"time_domain\": \"timeline\",\n    \"keyframes\": [\n        {\"timeline_time\": 0.0, \"source_time\": 0.0, \"interp\": \"linear\"},\n        {\"timeline_time\": 50.0, \"source_time\": 25.0, \"interp\": \"linear\"},\n        {\"timeline_time\": 100.0, \"source_time\": 125.0, \"interp\": \"linear\"},\n    ],\n}\n</code></pre> <p>Your adapter can reconstruct Flame\u2019s curve from these points (or at least approximate it).</p>"},{"location":"research/understanding-OTIO-flame-timewarps/#44-optical-flow-motion-estimation","title":"4.4 Optical flow / motion estimation","text":"<p>OTIO will never \u201cunderstand\u201d optical flow, but it can carry the intent:</p> <pre><code>\"optical_flow\": {\n    \"enabled\": True,\n    \"mode\": \"motion_estimation\",\n    \"quality\": \"high\",\n    \"smoothing\": 0.75,\n}\n</code></pre> <p>On import:</p> <ul> <li> <p>You read Flame\u2019s node settings and populate these fields. On export:</p> </li> <li> <p>You recreate the Flame node with the same options.</p> </li> </ul> <p>Playback tools that don\u2019t know Flame can ignore this block.</p>"},{"location":"research/understanding-OTIO-flame-timewarps/#5-round-tripping-flame-timewarps-with-a-custom-adapter","title":"5. Round-tripping Flame timewarps with a custom adapter","text":"<p>OTIO\u2019s adapter system is exactly for this: a plugin that knows how to talk Flame\u2019s language.</p> <p>Conceptually, your Flame OTIO adapter will:</p> <ol> <li>Flame \u2192 OTIO (read) </li> <li>Inspect the Flame timeline / Batch setup.  </li> <li> <p>For each clip with a Timewarp node:</p> <ul> <li>Extract: mode, speed, curve points, freeze frame, optical flow settings, etc.</li> <li>Create an OTIO <code>Clip</code> (or reference existing one).</li> <li>Attach a <code>TimeEffect</code> or <code>LinearTimeWarp</code>.</li> <li>Populate <code>metadata[\"flame\"][\"timewarp\"]</code> with your schema.</li> </ul> </li> <li> <p>OTIO \u2192 Flame (write) </p> </li> <li>Walk the OTIO timeline.  </li> <li> <p>For each <code>Clip</code> with a <code>TimeEffect</code> or <code>LinearTimeWarp</code>:</p> <ul> <li>If <code>LinearTimeWarp</code> and <code>mode == \"constant\"</code>:  </li> <li>Create a Flame Timewarp node with constant speed.  </li> <li>If <code>mode == \"curve\"</code>:  </li> <li>Rebuild Flame\u2019s curve from <code>curve[\"keyframes\"]</code>.  </li> <li>If <code>freeze.enabled</code>:  </li> <li>Configure Flame\u2019s freeze frame.  </li> <li>If <code>optical_flow.enabled</code>:  </li> <li>Re-enable motion estimation / optical flow with stored options.</li> </ul> </li> <li> <p>Preserve unknowns </p> </li> <li>If Flame adds new options later, you can stash them in <code>raw_flame_data</code> and just round-trip them without interpretation.</li> </ol>"},{"location":"research/understanding-OTIO-flame-timewarps/#adapter-skeleton-python-side-otio-plugin","title":"Adapter skeleton (Python-side OTIO plugin)","text":"<p>OTIO adapters are just Python modules that implement <code>read_from_file</code> and <code>write_to_file</code>.</p> <p>Very rough sketch:</p> <pre><code># flame_otio_adapter.py\nimport opentimelineio as otio\n\ndef read_from_file(filepath, **kwargs):\n    # 1. Use Flame\u2019s Python API or an exported format (e.g. XML/JSON)\n    # 2. Parse timeline, clips, and timewarp nodes\n    # 3. Build an OTIO Timeline\n\n    timeline = otio.schema.Timeline(name=\"FlameTimeline\")\n\n    # pseudo-code:\n    # for each flame_clip in flame_timeline:\n    #     clip = build_otio_clip(flame_clip)\n    #     if flame_clip.has_timewarp():\n    #         effect = build_otio_timewarp(flame_clip.timewarp)\n    #         clip.effects.append(effect)\n    #     add clip to track\n\n    return timeline\n\n\ndef write_to_file(input_otio, filepath, **kwargs):\n    # 1. Walk OTIO timeline\n    # 2. For each clip/effect, create Flame nodes\n    # 3. Save or apply to Flame\n\n    # pseudo-code:\n    # for clip in input_otio.each_clip():\n    #     flame_clip = create_flame_clip(clip)\n    #     for effect in clip.effects:\n    #         if isinstance(effect, otio.schema.LinearTimeWarp):\n    #             apply_constant_timewarp(flame_clip, effect)\n    #         elif isinstance(effect, otio.schema.TimeEffect):\n    #             apply_flame_timewarp_from_metadata(flame_clip, effect.metadata)\n\n    # write out via Flame API or export format\n    pass\n</code></pre> <p>You\u2019d register this as an OTIO adapter plugin so you can do:</p> <pre><code>otio cat flame_timeline.flame --adapter flame_otio\n</code></pre> <p>or in Python:</p> <pre><code>timeline = otio.adapters.read_from_file(\"flame_timeline.flame\", adapter_name=\"flame_otio\")\n</code></pre>"},{"location":"research/understanding-OTIO-flame-timewarps/#6-practical-constraints-and-nice-to-haves","title":"6. Practical constraints and nice-to-haves","text":"<p>A few realities to keep in mind:</p> <ul> <li> <p>Precision vs. simplicity:   You can choose to approximate Flame\u2019s curve with fewer keyframes, or go full 1:1 sampling.</p> </li> <li> <p>Versioning:   Always include <code>schema_version</code> in your <code>metadata[\"flame\"][\"timewarp\"]</code> so you can evolve the schema without breaking old timelines.</p> </li> <li> <p>Interoperability:   Other tools (Nuke Studio, Resolve, RV, etc.) can read the OTIO file and:</p> </li> <li>Use <code>LinearTimeWarp</code> directly where applicable.  </li> <li>Ignore <code>flame</code> metadata if they don\u2019t care.  </li> <li> <p>Or implement their own mapping from your schema to their retime system.</p> </li> <li> <p>AYON / pipeline integration:   If you\u2019re already using AYON/Flame hooks (like the OpenTimelineIO install hook), this schema can live as a documented contract between your Flame integration and the rest of the pipeline.</p> </li> </ul>"},{"location":"research/understanding-OTIO-flame-timewarps/#7-if-you-want-to-go-deeper","title":"7. If you want to go deeper","text":"<p>I\u2019d love to do one of these next with you:</p> <ul> <li>Design a concrete JSON example of a real Flame Timewarp node you\u2019ve used (e.g., a hero ramp) and encode it fully in OTIO metadata.  </li> <li>Sketch the Flame-side Python that reads this metadata and rebuilds the node graph.  </li> <li>Define a mini spec for <code>flame.timewarp</code> that you can drop into LOGIK-PROJEKT docs.</li> </ul> <p>If you\u2019ve got a specific Flame Timewarp setup in mind (e.g., \u201cramp from 100% to 400% over 2 seconds with freeze at the end\u201d), describe it and we\u2019ll encode it end-to-end.</p>"},{"location":"research/understanding-SHARP/","title":"Understanding Apple SHARP (Single-Image to 3D)","text":""},{"location":"research/understanding-SHARP/#overview","title":"Overview","text":"<p>SHARP (Sharp Monocular View Synthesis) is a research project by Apple that enables the reconstruction of photorealistic 3D scenes from a single 2D image in under a second.</p>"},{"location":"research/understanding-SHARP/#architecture","title":"Architecture","text":"<ul> <li>Technology: 3D Gaussian Splatting (3DGS).</li> <li>Inference Engine: PyTorch-based, utilizing a feed-forward transformer architecture to predict Gaussian parameters.</li> <li>Hardware Support: Native support for Apple Silicon (MPS) and CUDA.</li> </ul>"},{"location":"research/understanding-SHARP/#command-line-interface-cli","title":"Command Line Interface (CLI)","text":"<p>The primary way to interact with the model is via the <code>sharp</code> command:</p> <pre><code>sharp predict -i &lt;input_image&gt; -o &lt;output_directory&gt; --render\n</code></pre> <ul> <li><code>-i</code>: Path to input image (e.g., .exr, .jpg, .png).</li> <li><code>-o</code>: Directory where the 3D data (.ply) and renders will be stored.</li> <li><code>--render</code>: Triggers a rasterization pass to generate turntable or multiview images.</li> </ul>"},{"location":"research/understanding-SHARP/#integration-potential-for-flame","title":"Integration Potential for Flame","text":"<ul> <li>Input: Flame can provide 16-bit Float EXR frames.</li> <li>Output: The resulting <code>.ply</code> files can be converted or interpreted by Flame's Action node as point clouds.</li> <li>Speed: Sub-second inference makes it suitable for interactive Batch workflows.</li> </ul>"},{"location":"research/understanding-SHARP/#technical-requirements","title":"Technical Requirements","text":"<ul> <li>Python: 3.10+ (Recommended 3.13 for our suite).</li> <li>PyTorch: 2.3.1.</li> <li>Dependencies: <code>torchvision</code>, <code>pillow</code>, <code>numpy</code>, and likely <code>diff-gaussian-rasterization</code> for the <code>--render</code> pass.</li> </ul> <p>Research conducted on 2026-02-01.</p>"},{"location":"setup/deploy/","title":"Deploying FLAME-UTILITIES","text":"<p>This document describes how to deploy the FLAME-UTILITIES toolkit into Autodesk Flame using the consolidated directory strategy.</p>"},{"location":"setup/deploy/#1-configure-the-project","title":"1. Configure the Project","text":"<p>Ensure your <code>fu_eavesdrop.json</code> is configured in <code>flame-utilities/config/</code>. This file tells our scripts where to find your Flame project setups.</p> <pre><code>{\n  \"scriptsDir\": \"/path/to/flame/projects/&lt;project_name&gt;/setups/python/\",\n  \"listener\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 5555\n  }\n}\n</code></pre>"},{"location":"setup/deploy/#2-set-up-authentication-optional-but-recommended","title":"2. Set Up Authentication (Optional but Recommended)","text":"<p>Create a <code>fu_secrets.json</code> in <code>flame-utilities/config/</code> (or a <code>.flame.secrets.json</code> in the repo root) containing your listener token:</p> <pre><code>{ \"token\": \"your-secure-token\" }\n</code></pre>"},{"location":"setup/deploy/#3-deploy-the-toolkit","title":"3. Deploy the Toolkit","text":"<p>The easiest way to deploy is using the provided <code>Makefile</code> target:</p> <pre><code>make flame-deploy\n</code></pre> <p>What this does: 1.  Copies the entire <code>flame-utilities/</code> directory into your project's <code>setups/python/</code> folder. 2.  Installs the <code>fu_activate.py</code> entry point into the <code>python/</code> root. 3.  Optimizes the installation by removing redundant scripts from sub-directories.</p>"},{"location":"setup/deploy/#4-launch-flame","title":"4. Launch Flame","text":"<p>Launch Flame for your project. Watch the console or logs for the confirmation:</p> <pre><code>fu_eavesdrop_init.py version 0.0.1 (Ignited)\nFU_Eavesdrop startup hook started in background thread\nfu_eavesdrop listening on 127.0.0.1:5555\n</code></pre>"},{"location":"setup/deploy/#why-this-strategy","title":"Why this strategy?","text":"<p>By archiving the entire <code>flame-utilities/</code> directory within your Flame project, you ensure that the automation tools remain functional even if the workstation is updated or the project is moved to a different system. The <code>fu_activate.py</code> script acts as a clean, single-point entry that prevents Flame's auto-hook mechanism from loading internal scripts prematurely.</p>"},{"location":"tasks/TODO/","title":"TODO \u2014 short term (high priority)","text":"<ol> <li>Install <code>debugpy</code> into Flame and verify attach</li> <li>Add <code>scripts/install_debugpy.py</code> that can locate Flame's Python or accept a path and run <code>pip install debugpy</code>.</li> <li>Deploy <code>debugpy</code> and restart Flame, then run <code>Flame: Start debug server</code> and attach from VS Code to confirm.</li> <li> <p>Document UI freeze caveats and recommend non-blocking workflows for debugging.</p> </li> <li> <p>Harden listener</p> </li> <li>Add timeouts and cancellation for long-running scripts.</li> <li> <p>Add better error responses and logging.</p> </li> <li> <p>Tests &amp; CI</p> </li> <li>Add automated tests for <code>ping</code>, <code>execute</code>, and token auth (mock + optional real-Flame tests guarded by env var).</li> <li> <p>Add GitHub Actions workflow to run unit tests and linting.</p> </li> <li> <p>UX &amp; polish</p> </li> <li>Add extension snippets and ship <code>.pyi</code> stubs in <code>extension/stubs/</code>.</li> <li>Add file-sync/auto-reload helper (optional feature).</li> <li>Prepare extension packaging and Marketplace publish flow.</li> </ol>"},{"location":"tasks/TODO/#todo-lower-priority-future","title":"TODO \u2014 lower priority / future","text":"<ul> <li>Add a <code>debug</code> mode for the listener that captures stack traces and execution metrics.</li> <li>Explore a safer main-thread execution API or request Flame upstream add a command port API.</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/","title":"Tasks: FU_Bridge_ComfyUI Development","text":"<p>This list tracks the implementation of the <code>fu_bridge_comfyui.py</code> PyBox handler, which serves as the bridge between Autodesk Flame and ComfyUI.</p>"},{"location":"tasks/flame-comfyui-bridge-tasks/#1-core-handler-foundation","title":"1. Core Handler Foundation","text":"<ul> <li>[x] SDK Setup: Import <code>fu_pybox_v3_13</code> and initialize the <code>ComfyUIBridge</code> class.</li> <li>[x] Socket Definition: Configure <code>Front</code>, <code>Matte</code>, and <code>Result</code> sockets using 16-bit Float EXR format.</li> <li>[x] Lifecycle Hooks: Implement <code>initialize()</code>, <code>setup_ui()</code>, and <code>execute()</code> methods.</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/#2-dynamic-ui-implementation","title":"2. Dynamic UI Implementation","text":"<ul> <li>[x] Workflow Selector: Create a popup menu to choose from available ComfyUI workflow templates (.json).</li> <li>[x] Server Config: Add a text field for the ComfyUI server address (defaults to 127.0.0.1:8188).</li> <li>[x] Trigger Button: Implement a \"Generate\" toggle button (Global Element) to initiate the AI pass.</li> <li>[x] Status Bar: Use a read-only text field or <code>set_notice_msg</code> to display execution status (Queueing, Executing, Done).</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/#3-communication-logic-backend","title":"3. Communication Logic (Backend)","text":"<ul> <li>[x] Client Integration: Integrate <code>fu-comfyui/fu_comfyui.py</code> logic within the handler.</li> <li>[x] Workflow Mapping: Write logic to read a workflow JSON and inject the Flame frame paths into the correct nodes.</li> <li>[x] WebSocket Monitoring: Implement a non-blocking check (during <code>execute</code>) to monitor the ComfyUI progress.</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/#4-image-pipeline-data-exchange","title":"4. Image Pipeline (Data Exchange)","text":"<ul> <li>[x] Path Handling: Ensure <code>pathlib</code> is used to manage the \"Drop Zone\" directory between Flame and ComfyUI.</li> <li>[x] Result Verification: Verify that the output image exists and is valid before returning control to Flame.</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/#5-metadata-error-handling","title":"5. Metadata &amp; Error Handling","text":"<ul> <li>[x] Metadata Tagging: Pass Flame's <code>shot_name</code> and <code>frame</code> number to the ComfyUI result filename for better tracking.</li> <li>[x] Graceful Failure: Implement detailed error messages if the server is unreachable or the workflow fails.</li> </ul>"},{"location":"tasks/flame-comfyui-bridge-tasks/#6-verification","title":"6. Verification","text":"<ul> <li>[x] Dry Run: Test the handler using a simulated JSON payload from the terminal.</li> <li>[ ] Flame Integration: Load the handler into a live PyBox node and verify the 16-bit EXR round-trip.</li> </ul>"},{"location":"tasks/flame-mcp-bridge-tasks/","title":"Tasks: FU_Whisper (Flame MCP Bridge) Implementation","text":"<p>This document tracks the technical steps required to implement the Model Context Protocol (MCP) bridge for Autodesk Flame.</p>"},{"location":"tasks/flame-mcp-bridge-tasks/#phase-1-environment-scaffolding","title":"Phase 1: Environment &amp; Scaffolding","text":"<ul> <li>[x] Create <code>flame-mcp/</code> directory structure.</li> <li>[x] Initialize <code>requirements.txt</code> for the MCP server (e.g., <code>fastmcp</code>, <code>requests</code>, <code>pydantic</code>).</li> <li>[x] Set up a basic <code>fu_whisper.py</code> (formerly <code>server.py</code>) using <code>fastmcp</code>.</li> <li>[x] Create a README in <code>flame-mcp/</code> explaining how to start the server.</li> </ul>"},{"location":"tasks/flame-mcp-bridge-tasks/#phase-2-core-communication-layer","title":"Phase 2: Core Communication Layer","text":"<ul> <li>[x] Implement the <code>fu_relay</code> client: a module to handle network communication with the existing <code>fu_eavesdrop.py</code> (port 5555).</li> <li>[x] Standardize the error handling for relay failures (e.g., Flame is not running, Listener is down).</li> <li>[x] Implement a \"Ping\" tool to verify the end-to-end connection: <code>AI -&gt; fu_whisper -&gt; fu_relay -&gt; fu_eavesdrop -&gt; Flame</code>.</li> </ul>"},{"location":"tasks/flame-mcp-bridge-tasks/#phase-3-core-ai-tools","title":"Phase 3: Core AI Tools","text":"<ul> <li>[x] Tool: <code>execute_python</code><ul> <li>[x] Basic execution of strings.</li> <li>[x] Return stdout and stderr to the AI.</li> </ul> </li> <li>[x] Tool: <code>get_flame_context</code><ul> <li>[x] Return JSON containing: Current Project, User, Workspace, and Version.</li> </ul> </li> <li>[x] Tool: <code>list_desktop_clips</code><ul> <li>[x] Query Flame for all clips on the current Desktop.</li> </ul> </li> <li>[x] Tool: <code>inspect_symbol</code><ul> <li>[x] Use Python's <code>dir()</code> and <code>help()</code> inside Flame to give the AI real-time documentation for any Flame object.</li> </ul> </li> </ul>"},{"location":"tasks/flame-mcp-bridge-tasks/#phase-4-integration-security","title":"Phase 4: Integration &amp; Security","text":"<ul> <li>[ ] Test the bridge with an MCP-compliant client (e.g., Claude Desktop or Cursor).</li> <li>[x] Implement basic logging of all AI-generated commands for auditability.</li> <li>[x] (Optional) Add a \"Read-Only\" mode toggle to prevent accidental modifications during inspection.</li> </ul>"},{"location":"tasks/flame-mcp-bridge-tasks/#phase-5-documentation-examples","title":"Phase 5: Documentation &amp; Examples","text":"<ul> <li>[x] Write a \"Getting Started\" guide for users to connect their LLM to the FU_Whisper bridge.</li> <li>[x] Create a folder <code>flame-mcp/prompts/</code> with system prompt templates that help the AI understand how to use the Flame tools effectively.</li> <li>[ ] Record a demo of an AI autonomously interacting with the Flame Desktop.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/","title":"Tasks: FU_ML_Sharp Development","text":"<p>This list tracks the implementation of the <code>fu_ml_sharp.py</code> PyBox handler and its underlying AI worker.</p>"},{"location":"tasks/flame-sharp-3d-tasks/#1-environment-research","title":"1. Environment &amp; Research","text":"<ul> <li>[x] Dependency Audit: Verify requirements for the <code>apple/ml-sharp</code> repository (Torch 2.3.1).</li> <li>[x] SDK Indexing: Index SHARP documentation into <code>docs/research/understanding-SHARP.md</code> for RAG support.</li> <li>[ ] Virtual Env Setup: Create a specialized <code>.venv_sharp</code> to isolate AI dependencies.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/#2-technical-bridge-worker","title":"2. Technical Bridge (Worker)","text":"<ul> <li>[x] <code>fu_ml_sharp_client.py</code>: Implement the class that loads the SHARP model and weights.</li> <li>[x] Inference Logic: Create a function that takes a single EXR and returns a 3D Splat/Cloud.</li> <li>[x] Rasterization Pass: Implement a lightweight renderer to output Depth and Multiview frames.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/#3-pybox-handler-fu_ml_sharppy","title":"3. PyBox Handler (<code>fu_ml_sharp.py</code>)","text":"<ul> <li>[x] Initial Foundation: Inherit from <code>fu_pybox_v3_13.BaseClass</code>.</li> <li>[x] Socket Setup: Configure Front (Input) and Result (Output) sockets for EXR/PLY data.</li> <li>[x] Dynamic UI:<ul> <li>[x] <code>Output Type</code>: Popup (Depth Map, PLY Cloud, Turntable Render).</li> <li>[x] <code>Resolution</code>: Popup (512, 1024, 2048).</li> <li>[x] <code>Generate 3D</code>: Trigger button.</li> </ul> </li> <li>[x] Lifecycle Execution: Implement the logic to hand off the EXR path to the SHARP worker and wait for the result.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/#4-image-data-pipeline","title":"4. Image &amp; Data Pipeline","text":"<ul> <li>[ ] EXR Handling: Ensure the 16-bit Float dynamic range is preserved during the Torch tensor conversion.</li> <li>[x] PLY Export: Write logic to convert Gaussian Splat points into a PLY format readable by Flame's Action node.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/#5-verification","title":"5. Verification","text":"<ul> <li>[x] Standalone Test: Run inference on an EXR via the terminal (Verified via dry_run_sharp_bridge.py).</li> <li>[ ] Flame Integration: Load the handler in Batch and verify the 3D-to-2D depth alignment.</li> </ul>"},{"location":"tasks/flame-sharp-3d-tasks/#6-secure-splat-viewer-integration","title":"6. Secure Splat Viewer Integration","text":"<ul> <li>[ ] <code>fu_splat_viewer.py</code>: Implement a specialized visualization handler.</li> <li>[ ] Local Hosting: Add logic to serve splat data via a temporary local HTTP server for SuperSplat.</li> <li>[ ] Browser Orchestration: Use <code>webbrowser</code> to launch the sandboxed viewer.</li> <li>[ ] Blender Pathway: Architect the tool to support launching Blender with the KIRI add-on via CLI.</li> </ul>"},{"location":"tasks/grand-consolidation-tasks/","title":"Tasks: The Grand Consolidation","text":""},{"location":"tasks/grand-consolidation-tasks/#phase-1-file-migration","title":"Phase 1: File Migration","text":"<ul> <li>[x] Move <code>flame-listener/fu_eavesdrop.py</code> -&gt; <code>flame-utilities/fu_eavesdrop.py</code>.</li> <li>[x] Move <code>flame-listener/fu_eavesdrop_init.py</code> -&gt; <code>flame-utilities/fu_eavesdrop_init.py</code>.</li> <li>[x] Move <code>flame-listener/generate_stubs.py</code> -&gt; <code>flame-utilities/scripts/fu_generate_stubs.py</code>.</li> <li>[x] Move <code>flame-mcp/</code> (entire folder) -&gt; <code>fu-whisper/</code>.</li> <li>[x] Clean up: Remove <code>flame-listener/</code> and <code>flame-mcp/</code> root directories.</li> </ul>"},{"location":"tasks/grand-consolidation-tasks/#phase-2-script-logic-updates","title":"Phase 2: Script &amp; Logic Updates","text":"<ul> <li>[x] Deployment Scripts: Update <code>scripts/deploy_to_flame_project.py</code> with new <code>flame-utilities/</code> source paths.</li> <li>[x] Version Management: Update <code>scripts/bump_flame_versions.py</code> to track files in the new location.</li> <li>[x] Relay Logic: Update <code>fu-whisper/fu_relay.py</code> to correctly locate secrets within the new hierarchy.</li> <li>[x] Bridge Imports: Update <code>fu-whisper/fu_whisper.py</code> to import from the new relative paths.</li> <li>[x] Startup Logic: Update <code>flame-utilities/fu_eavesdrop_init.py</code> to handle being inside the consolidated folder.</li> </ul>"},{"location":"tasks/grand-consolidation-tasks/#phase-3-test-suite-repair","title":"Phase 3: Test Suite Repair","text":"<ul> <li>[x] Update <code>tests/deploy_test.py</code> paths.</li> <li>[x] Update <code>tests/test_listener_robustness.py</code> paths.</li> <li>[x] Update <code>tests/test_listener_more.py</code> paths.</li> <li>[x] Run full test suite to verify no path-related regressions.</li> </ul>"},{"location":"tasks/grand-consolidation-tasks/#phase-4-documentation-refresh","title":"Phase 4: Documentation Refresh","text":"<ul> <li>[x] Update <code>README.md</code> (root).</li> <li>[x] Update <code>GEMINI.md</code>.</li> <li>[x] Update <code>fu-whisper/GETTING_STARTED.md</code>.</li> <li>[x] Update <code>docs/deploy.md</code>, <code>docs/architecture.md</code>, <code>docs/HOWTO_GENERATE_API_REPORTS.md</code>.</li> <li>[x] Update <code>docs/goals/flame-utilities-rebrand.md</code> and <code>docs/goals/flame-mcp-creation.md</code> to use the new folder names.</li> </ul>"},{"location":"tasks/grand-consolidation-tasks/#phase-5-verification-loader","title":"Phase 5: Verification &amp; Loader","text":"<ul> <li>[x] Create <code>flame-utilities/fu_loader.py</code>.</li> <li>[x] Verify end-to-end connection: <code>AI -&gt; fu-whisper -&gt; relay -&gt; eavesdrop -&gt; Flame</code>.</li> <li>[x] Update <code>CHANGELOG.md</code> with the consolidation milestone.</li> </ul>"}]}